{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_renttherunway_predition_submit.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIfRjYy4hpEp",
        "colab_type": "text"
      },
      "source": [
        "**Prediction for Renttherunway and ModCloth Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdPOpQwHhKOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import required libraries for your algorithm \n",
        "import tensorflow as tf\n",
        "import json\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcImaSQoiO_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9d36b28-f0f4-40cb-9772-f7ac8d623c91"
      },
      "source": [
        "#import drive to load the data \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM1Tyf10iRtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/drive/My Drive/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQpUOxBcMJUH",
        "colab_type": "text"
      },
      "source": [
        "**Reading Renttherunway dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szY4FWIdiTYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "00571cd4-74d5-4714-bd42-a1a359098818"
      },
      "source": [
        "#load renttherunway data\n",
        "cloth_data = pd.read_json(file_path+ 'renttherunway_final_data.json', lines=True)\n",
        "cloth_data.head(5)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bust size</th>\n",
              "      <th>item_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>rating</th>\n",
              "      <th>rented for</th>\n",
              "      <th>review_text</th>\n",
              "      <th>body type</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>category</th>\n",
              "      <th>height</th>\n",
              "      <th>size</th>\n",
              "      <th>age</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fit</td>\n",
              "      <td>420272</td>\n",
              "      <td>34d</td>\n",
              "      <td>2260466</td>\n",
              "      <td>137lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>vacation</td>\n",
              "      <td>An adorable romper! Belt and zipper were a lit...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>So many compliments!</td>\n",
              "      <td>romper</td>\n",
              "      <td>5' 8\"</td>\n",
              "      <td>14</td>\n",
              "      <td>28.0</td>\n",
              "      <td>April 20, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fit</td>\n",
              "      <td>273551</td>\n",
              "      <td>34b</td>\n",
              "      <td>153475</td>\n",
              "      <td>132lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>other</td>\n",
              "      <td>I rented this dress for a photo shoot. The the...</td>\n",
              "      <td>straight &amp; narrow</td>\n",
              "      <td>I felt so glamourous!!!</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 6\"</td>\n",
              "      <td>12</td>\n",
              "      <td>36.0</td>\n",
              "      <td>June 18, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fit</td>\n",
              "      <td>360448</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1063761</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>party</td>\n",
              "      <td>This hugged in all the right places! It was a ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It was a great time to celebrate the (almost) ...</td>\n",
              "      <td>sheath</td>\n",
              "      <td>5' 4\"</td>\n",
              "      <td>4</td>\n",
              "      <td>116.0</td>\n",
              "      <td>December 14, 2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fit</td>\n",
              "      <td>909926</td>\n",
              "      <td>34c</td>\n",
              "      <td>126335</td>\n",
              "      <td>135lbs</td>\n",
              "      <td>8.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>I rented this for my company's black tie award...</td>\n",
              "      <td>pear</td>\n",
              "      <td>Dress arrived on time and in perfect condition.</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 5\"</td>\n",
              "      <td>8</td>\n",
              "      <td>34.0</td>\n",
              "      <td>February 12, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fit</td>\n",
              "      <td>151944</td>\n",
              "      <td>34b</td>\n",
              "      <td>616682</td>\n",
              "      <td>145lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>I have always been petite in my upper body and...</td>\n",
              "      <td>athletic</td>\n",
              "      <td>Was in love with this dress !!!</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 9\"</td>\n",
              "      <td>12</td>\n",
              "      <td>27.0</td>\n",
              "      <td>September 26, 2016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit  user_id bust size  item_id  ... height  size    age         review_date\n",
              "0  fit   420272       34d  2260466  ...  5' 8\"    14   28.0      April 20, 2016\n",
              "1  fit   273551       34b   153475  ...  5' 6\"    12   36.0       June 18, 2013\n",
              "2  fit   360448       NaN  1063761  ...  5' 4\"     4  116.0   December 14, 2015\n",
              "3  fit   909926       34c   126335  ...  5' 5\"     8   34.0   February 12, 2014\n",
              "4  fit   151944       34b   616682  ...  5' 9\"    12   27.0  September 26, 2016\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAFIm1hr48af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#change the names of the column in order to get rid of spaces\n",
        "cloth_data.columns = ['fit','user_id', 'bra_size', 'item_id' , 'weight', 'rating', 'rented_for', 'review_text','body_type', 'review_summary', 'category','height', 'size','age', 'review_date']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQNGfiNplDVw",
        "colab_type": "text"
      },
      "source": [
        "**Execute the below 4 steps for using renttherunway unbaised data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si66qvXZiVyd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "aa9d4c4f-4b30-476e-ebde-77a070dc1a1f"
      },
      "source": [
        "#for extracting un-biased data\n",
        "data = cloth_data[cloth_data.fit  == 'fit']\n",
        "data = data.head(25000) #will consder only some amount of data that is fit to make data un-biased \n",
        "data.head(1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>item_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>rating</th>\n",
              "      <th>rented_for</th>\n",
              "      <th>review_text</th>\n",
              "      <th>body_type</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>category</th>\n",
              "      <th>height</th>\n",
              "      <th>size</th>\n",
              "      <th>age</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fit</td>\n",
              "      <td>420272</td>\n",
              "      <td>34d</td>\n",
              "      <td>2260466</td>\n",
              "      <td>137lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>vacation</td>\n",
              "      <td>An adorable romper! Belt and zipper were a lit...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>So many compliments!</td>\n",
              "      <td>romper</td>\n",
              "      <td>5' 8\"</td>\n",
              "      <td>14</td>\n",
              "      <td>28.0</td>\n",
              "      <td>April 20, 2016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit  user_id bra_size  item_id  ... height  size   age     review_date\n",
              "0  fit   420272      34d  2260466  ...  5' 8\"    14  28.0  April 20, 2016\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRIHXtBMknC3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "7c4e152a-2749-480b-e295-72d3fd712c7e"
      },
      "source": [
        "data_small = cloth_data[cloth_data.fit  == 'small'] \n",
        "data_small.head(1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>item_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>rating</th>\n",
              "      <th>rented_for</th>\n",
              "      <th>review_text</th>\n",
              "      <th>body_type</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>category</th>\n",
              "      <th>height</th>\n",
              "      <th>size</th>\n",
              "      <th>age</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>small</td>\n",
              "      <td>185966</td>\n",
              "      <td>34b</td>\n",
              "      <td>1077123</td>\n",
              "      <td>135lbs</td>\n",
              "      <td>8.0</td>\n",
              "      <td>party</td>\n",
              "      <td>The dress arrived with a small hole in the bea...</td>\n",
              "      <td>athletic</td>\n",
              "      <td>It was fun to wear a dress I wouldn't normally...</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 3\"</td>\n",
              "      <td>12</td>\n",
              "      <td>33.0</td>\n",
              "      <td>January 2, 2018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      fit  user_id bra_size  item_id  ... height  size   age      review_date\n",
              "10  small   185966      34b  1077123  ...  5' 3\"    12  33.0  January 2, 2018\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uonmtQahjOwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "a11a3675-fb75-447d-98f2-a582b1dfd8d9"
      },
      "source": [
        "data_large = cloth_data[cloth_data.fit  == 'large']\n",
        "data_large.head(1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>item_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>rating</th>\n",
              "      <th>rented_for</th>\n",
              "      <th>review_text</th>\n",
              "      <th>body_type</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>category</th>\n",
              "      <th>height</th>\n",
              "      <th>size</th>\n",
              "      <th>age</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>large</td>\n",
              "      <td>533900</td>\n",
              "      <td>34b</td>\n",
              "      <td>130259</td>\n",
              "      <td>135lbs</td>\n",
              "      <td>8.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>This dress was absolutely gorgeous and I recei...</td>\n",
              "      <td>pear</td>\n",
              "      <td>Stunning dress, perfect for a New Year's Eve w...</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 6\"</td>\n",
              "      <td>8</td>\n",
              "      <td>30.0</td>\n",
              "      <td>January 7, 2013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      fit  user_id bra_size  item_id  ... height  size   age      review_date\n",
              "11  large   533900      34b   130259  ...  5' 6\"     8  30.0  January 7, 2013\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVd6L77Gk1YX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "3e798e0d-8e07-4e26-eaa7-514169dcda5b"
      },
      "source": [
        "cloth_data = pd.concat([data,data_small,data_large])\n",
        "cloth_data.head(1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>item_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>rating</th>\n",
              "      <th>rented_for</th>\n",
              "      <th>review_text</th>\n",
              "      <th>body_type</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>category</th>\n",
              "      <th>height</th>\n",
              "      <th>size</th>\n",
              "      <th>age</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fit</td>\n",
              "      <td>420272</td>\n",
              "      <td>34d</td>\n",
              "      <td>2260466</td>\n",
              "      <td>137lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>vacation</td>\n",
              "      <td>An adorable romper! Belt and zipper were a lit...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>So many compliments!</td>\n",
              "      <td>romper</td>\n",
              "      <td>5' 8\"</td>\n",
              "      <td>14</td>\n",
              "      <td>28.0</td>\n",
              "      <td>April 20, 2016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fit  user_id bra_size  item_id  ... height  size   age     review_date\n",
              "0  fit   420272      34d  2260466  ...  5' 8\"    14  28.0  April 20, 2016\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PwegylWlhvr",
        "colab_type": "text"
      },
      "source": [
        "**Preprocessing of renttherunway data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeMUNcgB5hXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Code to calculate TF*IDF for the text in “review_text”\n",
        "#import pandas as pd\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#from sklearn.metrics.pairwise import linear_kernel \n",
        "#ds = pd.read_json(\"renttherunway_final_data.json\",lines = True)\n",
        "#ds['review_text'].head()\n",
        "#tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\n",
        "#tfidf_matrix = tf.fit_transform(ds['review_text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKqPfZq24wKe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "05b34347-5deb-4304-dcd1-42e129c0e144"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "cloth_data = shuffle(cloth_data) #shuffle the data\n",
        "cloth_data.head(20)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>item_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>rating</th>\n",
              "      <th>rented_for</th>\n",
              "      <th>review_text</th>\n",
              "      <th>body_type</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>category</th>\n",
              "      <th>height</th>\n",
              "      <th>size</th>\n",
              "      <th>age</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31707</th>\n",
              "      <td>large</td>\n",
              "      <td>222286</td>\n",
              "      <td>NaN</td>\n",
              "      <td>134849</td>\n",
              "      <td>135lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>followed reviewers advice and sized down for b...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>really clean lines, pretty dress AND comfortab...</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 4\"</td>\n",
              "      <td>12</td>\n",
              "      <td>44.0</td>\n",
              "      <td>November 19, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64978</th>\n",
              "      <td>fit</td>\n",
              "      <td>239140</td>\n",
              "      <td>36c</td>\n",
              "      <td>770712</td>\n",
              "      <td>185lbs</td>\n",
              "      <td>8.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>It is true to size, the color is more burgundy...</td>\n",
              "      <td>pear</td>\n",
              "      <td>I used this outfit for formal family photos.  ...</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 5\"</td>\n",
              "      <td>28</td>\n",
              "      <td>40.0</td>\n",
              "      <td>April 11, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99684</th>\n",
              "      <td>small</td>\n",
              "      <td>280782</td>\n",
              "      <td>34b</td>\n",
              "      <td>2511676</td>\n",
              "      <td>118lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>vacation</td>\n",
              "      <td>Great jacket to dress up jeans or dress down a...</td>\n",
              "      <td>athletic</td>\n",
              "      <td>Perfect!</td>\n",
              "      <td>jacket</td>\n",
              "      <td>5' 4\"</td>\n",
              "      <td>8</td>\n",
              "      <td>64.0</td>\n",
              "      <td>May 15, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103627</th>\n",
              "      <td>large</td>\n",
              "      <td>513187</td>\n",
              "      <td>36c</td>\n",
              "      <td>806803</td>\n",
              "      <td>125lbs</td>\n",
              "      <td>8.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>This dress fit maybe a little big. I normally ...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Beautiful lace dress that flattered all the ri...</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 4\"</td>\n",
              "      <td>8</td>\n",
              "      <td>40.0</td>\n",
              "      <td>November 28, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126534</th>\n",
              "      <td>fit</td>\n",
              "      <td>171829</td>\n",
              "      <td>34c</td>\n",
              "      <td>1980086</td>\n",
              "      <td>130lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>Incredibly comfortable and forgiving dress.  I...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Great night, great dress, great charity event.</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 6\"</td>\n",
              "      <td>12</td>\n",
              "      <td>54.0</td>\n",
              "      <td>February 16, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154478</th>\n",
              "      <td>fit</td>\n",
              "      <td>776484</td>\n",
              "      <td>36c</td>\n",
              "      <td>2600623</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>everyday</td>\n",
              "      <td>I wore this several times while I had it rente...</td>\n",
              "      <td>full bust</td>\n",
              "      <td>Perfect for work or casual wear!</td>\n",
              "      <td>top</td>\n",
              "      <td>5' 3\"</td>\n",
              "      <td>16</td>\n",
              "      <td>40.0</td>\n",
              "      <td>September 18, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128874</th>\n",
              "      <td>fit</td>\n",
              "      <td>116555</td>\n",
              "      <td>36d+</td>\n",
              "      <td>132738</td>\n",
              "      <td>150lbs</td>\n",
              "      <td>8.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>This gown is REALLY sparkly!  You will definit...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Beautiful gown!</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 3\"</td>\n",
              "      <td>20</td>\n",
              "      <td>46.0</td>\n",
              "      <td>October 22, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148347</th>\n",
              "      <td>fit</td>\n",
              "      <td>850301</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1003076</td>\n",
              "      <td>125lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>I ordered a 2 and 4 and ended up wearing the 2...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dresses arrived on time and both looked brand ...</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 7\"</td>\n",
              "      <td>4</td>\n",
              "      <td>36.0</td>\n",
              "      <td>November 7, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31603</th>\n",
              "      <td>fit</td>\n",
              "      <td>619769</td>\n",
              "      <td>32c</td>\n",
              "      <td>169961</td>\n",
              "      <td>134lbs</td>\n",
              "      <td>8.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>This dress was amazing! It was tight and close...</td>\n",
              "      <td>athletic</td>\n",
              "      <td>Git like a glove</td>\n",
              "      <td>sheath</td>\n",
              "      <td>5' 7\"</td>\n",
              "      <td>8</td>\n",
              "      <td>33.0</td>\n",
              "      <td>May 29, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89411</th>\n",
              "      <td>fit</td>\n",
              "      <td>385028</td>\n",
              "      <td>38d</td>\n",
              "      <td>820057</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>It does fit a little tight in the hips/midsect...</td>\n",
              "      <td>full bust</td>\n",
              "      <td>I got so many compliments on this dress! Wore ...</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 7\"</td>\n",
              "      <td>28</td>\n",
              "      <td>25.0</td>\n",
              "      <td>February 14, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6758</th>\n",
              "      <td>fit</td>\n",
              "      <td>921065</td>\n",
              "      <td>34d</td>\n",
              "      <td>154002</td>\n",
              "      <td>161lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>other</td>\n",
              "      <td>The first dress I picked could not be sent but...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>I was Queen of a Mardi Gras event and this dre...</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 4\"</td>\n",
              "      <td>20</td>\n",
              "      <td>46.0</td>\n",
              "      <td>July 31, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66387</th>\n",
              "      <td>fit</td>\n",
              "      <td>654956</td>\n",
              "      <td>34c</td>\n",
              "      <td>1165054</td>\n",
              "      <td>130lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>The dress is beautiful and fit very well.  It ...</td>\n",
              "      <td>athletic</td>\n",
              "      <td>Wore this for a black tie event in late february</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 11\"</td>\n",
              "      <td>8</td>\n",
              "      <td>39.0</td>\n",
              "      <td>April 30, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131732</th>\n",
              "      <td>fit</td>\n",
              "      <td>962072</td>\n",
              "      <td>34b</td>\n",
              "      <td>1675905</td>\n",
              "      <td>137lbs</td>\n",
              "      <td>6.0</td>\n",
              "      <td>other</td>\n",
              "      <td>I rented this as a backup for my bridal shower...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Very pretty but not a huge fan of the way it l...</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 4\"</td>\n",
              "      <td>12</td>\n",
              "      <td>27.0</td>\n",
              "      <td>August 19, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152391</th>\n",
              "      <td>fit</td>\n",
              "      <td>76139</td>\n",
              "      <td>36c</td>\n",
              "      <td>1869056</td>\n",
              "      <td>145lbs</td>\n",
              "      <td>8.0</td>\n",
              "      <td>vacation</td>\n",
              "      <td>I rented this dress to wear to the rehearsal o...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Nice dress</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 5\"</td>\n",
              "      <td>8</td>\n",
              "      <td>32.0</td>\n",
              "      <td>December 14, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140308</th>\n",
              "      <td>fit</td>\n",
              "      <td>658735</td>\n",
              "      <td>34b</td>\n",
              "      <td>1042783</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>other</td>\n",
              "      <td>The dress is more blue than black as you can s...</td>\n",
              "      <td>pear</td>\n",
              "      <td>I rented this dress for an awards gala in New ...</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 6\"</td>\n",
              "      <td>12</td>\n",
              "      <td>28.0</td>\n",
              "      <td>June 9, 2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141786</th>\n",
              "      <td>small</td>\n",
              "      <td>958654</td>\n",
              "      <td>34a</td>\n",
              "      <td>1057664</td>\n",
              "      <td>138lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>I'm athletic built with broad shoulder and was...</td>\n",
              "      <td>athletic</td>\n",
              "      <td>Great fit, color, and style!</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 7\"</td>\n",
              "      <td>12</td>\n",
              "      <td>26.0</td>\n",
              "      <td>March 28, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41145</th>\n",
              "      <td>fit</td>\n",
              "      <td>511773</td>\n",
              "      <td>32d</td>\n",
              "      <td>147440</td>\n",
              "      <td>137lbs</td>\n",
              "      <td>8.0</td>\n",
              "      <td>party</td>\n",
              "      <td>Narrow arms and a wee snug around the hips, bu...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Narrow sleeves so if you tend to have bigger a...</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 6\"</td>\n",
              "      <td>12</td>\n",
              "      <td>44.0</td>\n",
              "      <td>October 25, 2012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58241</th>\n",
              "      <td>fit</td>\n",
              "      <td>29961</td>\n",
              "      <td>32c</td>\n",
              "      <td>193179</td>\n",
              "      <td>130lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>Only thing i didn't like is the waist line was...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Fabulous color</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 7\"</td>\n",
              "      <td>4</td>\n",
              "      <td>35.0</td>\n",
              "      <td>May 26, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149667</th>\n",
              "      <td>fit</td>\n",
              "      <td>358752</td>\n",
              "      <td>34d</td>\n",
              "      <td>128959</td>\n",
              "      <td>130lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>This dress was flattering in all the right are...</td>\n",
              "      <td>full bust</td>\n",
              "      <td>Stunning &amp; a Showstopper!</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 4\"</td>\n",
              "      <td>8</td>\n",
              "      <td>41.0</td>\n",
              "      <td>April 27, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70266</th>\n",
              "      <td>fit</td>\n",
              "      <td>884002</td>\n",
              "      <td>32b</td>\n",
              "      <td>1308013</td>\n",
              "      <td>115lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>Pro: It was an amazing fit, I got so many comp...</td>\n",
              "      <td>straight &amp; narrow</td>\n",
              "      <td>This dress was amazing! I felt great in it, I ...</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 7\"</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>November 13, 2017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          fit  user_id bra_size  ...  size   age         review_date\n",
              "31707   large   222286      NaN  ...    12  44.0   November 19, 2013\n",
              "64978     fit   239140      36c  ...    28  40.0      April 11, 2017\n",
              "99684   small   280782      34b  ...     8  64.0        May 15, 2016\n",
              "103627  large   513187      36c  ...     8  40.0   November 28, 2014\n",
              "126534    fit   171829      34c  ...    12  54.0   February 16, 2017\n",
              "154478    fit   776484      36c  ...    16  40.0  September 18, 2017\n",
              "128874    fit   116555     36d+  ...    20  46.0    October 22, 2013\n",
              "148347    fit   850301      NaN  ...     4  36.0    November 7, 2016\n",
              "31603     fit   619769      32c  ...     8  33.0        May 29, 2014\n",
              "89411     fit   385028      38d  ...    28  25.0   February 14, 2017\n",
              "6758      fit   921065      34d  ...    20  46.0       July 31, 2014\n",
              "66387     fit   654956      34c  ...     8  39.0      April 30, 2017\n",
              "131732    fit   962072      34b  ...    12  27.0     August 19, 2016\n",
              "152391    fit    76139      36c  ...     8  32.0   December 14, 2016\n",
              "140308    fit   658735      34b  ...    12  28.0        June 9, 2015\n",
              "141786  small   958654      34a  ...    12  26.0      March 28, 2017\n",
              "41145     fit   511773      32d  ...    12  44.0    October 25, 2012\n",
              "58241     fit    29961      32c  ...     4  35.0        May 26, 2014\n",
              "149667    fit   358752      34d  ...     8  41.0      April 27, 2014\n",
              "70266     fit   884002      32b  ...     1  22.0   November 13, 2017\n",
              "\n",
              "[20 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFOu77iGk5p7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "721cd18e-355d-4712-f7d3-b9d3b20e4f14"
      },
      "source": [
        "cloth_data.info()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 192544 entries, 31707 to 132409\n",
            "Data columns (total 15 columns):\n",
            "fit               192544 non-null object\n",
            "user_id           192544 non-null int64\n",
            "bra_size          174133 non-null object\n",
            "item_id           192544 non-null int64\n",
            "weight            162562 non-null object\n",
            "rating            192462 non-null float64\n",
            "rented_for        192534 non-null object\n",
            "review_text       192544 non-null object\n",
            "body_type         177907 non-null object\n",
            "review_summary    192544 non-null object\n",
            "category          192544 non-null object\n",
            "height            191867 non-null object\n",
            "size              192544 non-null int64\n",
            "age               191584 non-null float64\n",
            "review_date       192544 non-null object\n",
            "dtypes: float64(2), int64(3), object(10)\n",
            "memory usage: 23.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8koESM31S-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f600eaa-d57f-4f3c-bf8d-b3cf165bc312"
      },
      "source": [
        "cloth_data.bra_size.fillna('Unknown', inplace=True)  #bra_size contains missing value so will replace with unknown for later categorical conversion.\n",
        "#cloth_data.cup_size = cloth_data.cup_size.astype('category').cat.as_ordered()\n",
        "cloth_data.head(20)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>item_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>rating</th>\n",
              "      <th>rented_for</th>\n",
              "      <th>review_text</th>\n",
              "      <th>body_type</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>category</th>\n",
              "      <th>height</th>\n",
              "      <th>size</th>\n",
              "      <th>age</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31707</th>\n",
              "      <td>large</td>\n",
              "      <td>222286</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>134849</td>\n",
              "      <td>135lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>followed reviewers advice and sized down for b...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>really clean lines, pretty dress AND comfortab...</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 4\"</td>\n",
              "      <td>12</td>\n",
              "      <td>44.0</td>\n",
              "      <td>November 19, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64978</th>\n",
              "      <td>fit</td>\n",
              "      <td>239140</td>\n",
              "      <td>36c</td>\n",
              "      <td>770712</td>\n",
              "      <td>185lbs</td>\n",
              "      <td>8.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>It is true to size, the color is more burgundy...</td>\n",
              "      <td>pear</td>\n",
              "      <td>I used this outfit for formal family photos.  ...</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 5\"</td>\n",
              "      <td>28</td>\n",
              "      <td>40.0</td>\n",
              "      <td>April 11, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99684</th>\n",
              "      <td>small</td>\n",
              "      <td>280782</td>\n",
              "      <td>34b</td>\n",
              "      <td>2511676</td>\n",
              "      <td>118lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>vacation</td>\n",
              "      <td>Great jacket to dress up jeans or dress down a...</td>\n",
              "      <td>athletic</td>\n",
              "      <td>Perfect!</td>\n",
              "      <td>jacket</td>\n",
              "      <td>5' 4\"</td>\n",
              "      <td>8</td>\n",
              "      <td>64.0</td>\n",
              "      <td>May 15, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103627</th>\n",
              "      <td>large</td>\n",
              "      <td>513187</td>\n",
              "      <td>36c</td>\n",
              "      <td>806803</td>\n",
              "      <td>125lbs</td>\n",
              "      <td>8.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>This dress fit maybe a little big. I normally ...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Beautiful lace dress that flattered all the ri...</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 4\"</td>\n",
              "      <td>8</td>\n",
              "      <td>40.0</td>\n",
              "      <td>November 28, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126534</th>\n",
              "      <td>fit</td>\n",
              "      <td>171829</td>\n",
              "      <td>34c</td>\n",
              "      <td>1980086</td>\n",
              "      <td>130lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>Incredibly comfortable and forgiving dress.  I...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Great night, great dress, great charity event.</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 6\"</td>\n",
              "      <td>12</td>\n",
              "      <td>54.0</td>\n",
              "      <td>February 16, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154478</th>\n",
              "      <td>fit</td>\n",
              "      <td>776484</td>\n",
              "      <td>36c</td>\n",
              "      <td>2600623</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>everyday</td>\n",
              "      <td>I wore this several times while I had it rente...</td>\n",
              "      <td>full bust</td>\n",
              "      <td>Perfect for work or casual wear!</td>\n",
              "      <td>top</td>\n",
              "      <td>5' 3\"</td>\n",
              "      <td>16</td>\n",
              "      <td>40.0</td>\n",
              "      <td>September 18, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128874</th>\n",
              "      <td>fit</td>\n",
              "      <td>116555</td>\n",
              "      <td>36d+</td>\n",
              "      <td>132738</td>\n",
              "      <td>150lbs</td>\n",
              "      <td>8.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>This gown is REALLY sparkly!  You will definit...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Beautiful gown!</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 3\"</td>\n",
              "      <td>20</td>\n",
              "      <td>46.0</td>\n",
              "      <td>October 22, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148347</th>\n",
              "      <td>fit</td>\n",
              "      <td>850301</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>1003076</td>\n",
              "      <td>125lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>I ordered a 2 and 4 and ended up wearing the 2...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dresses arrived on time and both looked brand ...</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 7\"</td>\n",
              "      <td>4</td>\n",
              "      <td>36.0</td>\n",
              "      <td>November 7, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31603</th>\n",
              "      <td>fit</td>\n",
              "      <td>619769</td>\n",
              "      <td>32c</td>\n",
              "      <td>169961</td>\n",
              "      <td>134lbs</td>\n",
              "      <td>8.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>This dress was amazing! It was tight and close...</td>\n",
              "      <td>athletic</td>\n",
              "      <td>Git like a glove</td>\n",
              "      <td>sheath</td>\n",
              "      <td>5' 7\"</td>\n",
              "      <td>8</td>\n",
              "      <td>33.0</td>\n",
              "      <td>May 29, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89411</th>\n",
              "      <td>fit</td>\n",
              "      <td>385028</td>\n",
              "      <td>38d</td>\n",
              "      <td>820057</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>It does fit a little tight in the hips/midsect...</td>\n",
              "      <td>full bust</td>\n",
              "      <td>I got so many compliments on this dress! Wore ...</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 7\"</td>\n",
              "      <td>28</td>\n",
              "      <td>25.0</td>\n",
              "      <td>February 14, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6758</th>\n",
              "      <td>fit</td>\n",
              "      <td>921065</td>\n",
              "      <td>34d</td>\n",
              "      <td>154002</td>\n",
              "      <td>161lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>other</td>\n",
              "      <td>The first dress I picked could not be sent but...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>I was Queen of a Mardi Gras event and this dre...</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 4\"</td>\n",
              "      <td>20</td>\n",
              "      <td>46.0</td>\n",
              "      <td>July 31, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66387</th>\n",
              "      <td>fit</td>\n",
              "      <td>654956</td>\n",
              "      <td>34c</td>\n",
              "      <td>1165054</td>\n",
              "      <td>130lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>The dress is beautiful and fit very well.  It ...</td>\n",
              "      <td>athletic</td>\n",
              "      <td>Wore this for a black tie event in late february</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 11\"</td>\n",
              "      <td>8</td>\n",
              "      <td>39.0</td>\n",
              "      <td>April 30, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131732</th>\n",
              "      <td>fit</td>\n",
              "      <td>962072</td>\n",
              "      <td>34b</td>\n",
              "      <td>1675905</td>\n",
              "      <td>137lbs</td>\n",
              "      <td>6.0</td>\n",
              "      <td>other</td>\n",
              "      <td>I rented this as a backup for my bridal shower...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Very pretty but not a huge fan of the way it l...</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 4\"</td>\n",
              "      <td>12</td>\n",
              "      <td>27.0</td>\n",
              "      <td>August 19, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152391</th>\n",
              "      <td>fit</td>\n",
              "      <td>76139</td>\n",
              "      <td>36c</td>\n",
              "      <td>1869056</td>\n",
              "      <td>145lbs</td>\n",
              "      <td>8.0</td>\n",
              "      <td>vacation</td>\n",
              "      <td>I rented this dress to wear to the rehearsal o...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Nice dress</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 5\"</td>\n",
              "      <td>8</td>\n",
              "      <td>32.0</td>\n",
              "      <td>December 14, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140308</th>\n",
              "      <td>fit</td>\n",
              "      <td>658735</td>\n",
              "      <td>34b</td>\n",
              "      <td>1042783</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>other</td>\n",
              "      <td>The dress is more blue than black as you can s...</td>\n",
              "      <td>pear</td>\n",
              "      <td>I rented this dress for an awards gala in New ...</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 6\"</td>\n",
              "      <td>12</td>\n",
              "      <td>28.0</td>\n",
              "      <td>June 9, 2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141786</th>\n",
              "      <td>small</td>\n",
              "      <td>958654</td>\n",
              "      <td>34a</td>\n",
              "      <td>1057664</td>\n",
              "      <td>138lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>I'm athletic built with broad shoulder and was...</td>\n",
              "      <td>athletic</td>\n",
              "      <td>Great fit, color, and style!</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 7\"</td>\n",
              "      <td>12</td>\n",
              "      <td>26.0</td>\n",
              "      <td>March 28, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41145</th>\n",
              "      <td>fit</td>\n",
              "      <td>511773</td>\n",
              "      <td>32d</td>\n",
              "      <td>147440</td>\n",
              "      <td>137lbs</td>\n",
              "      <td>8.0</td>\n",
              "      <td>party</td>\n",
              "      <td>Narrow arms and a wee snug around the hips, bu...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Narrow sleeves so if you tend to have bigger a...</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 6\"</td>\n",
              "      <td>12</td>\n",
              "      <td>44.0</td>\n",
              "      <td>October 25, 2012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58241</th>\n",
              "      <td>fit</td>\n",
              "      <td>29961</td>\n",
              "      <td>32c</td>\n",
              "      <td>193179</td>\n",
              "      <td>130lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>Only thing i didn't like is the waist line was...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Fabulous color</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 7\"</td>\n",
              "      <td>4</td>\n",
              "      <td>35.0</td>\n",
              "      <td>May 26, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149667</th>\n",
              "      <td>fit</td>\n",
              "      <td>358752</td>\n",
              "      <td>34d</td>\n",
              "      <td>128959</td>\n",
              "      <td>130lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>This dress was flattering in all the right are...</td>\n",
              "      <td>full bust</td>\n",
              "      <td>Stunning &amp; a Showstopper!</td>\n",
              "      <td>gown</td>\n",
              "      <td>5' 4\"</td>\n",
              "      <td>8</td>\n",
              "      <td>41.0</td>\n",
              "      <td>April 27, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70266</th>\n",
              "      <td>fit</td>\n",
              "      <td>884002</td>\n",
              "      <td>32b</td>\n",
              "      <td>1308013</td>\n",
              "      <td>115lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>Pro: It was an amazing fit, I got so many comp...</td>\n",
              "      <td>straight &amp; narrow</td>\n",
              "      <td>This dress was amazing! I felt great in it, I ...</td>\n",
              "      <td>dress</td>\n",
              "      <td>5' 7\"</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>November 13, 2017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          fit  user_id bra_size  ...  size   age         review_date\n",
              "31707   large   222286  Unknown  ...    12  44.0   November 19, 2013\n",
              "64978     fit   239140      36c  ...    28  40.0      April 11, 2017\n",
              "99684   small   280782      34b  ...     8  64.0        May 15, 2016\n",
              "103627  large   513187      36c  ...     8  40.0   November 28, 2014\n",
              "126534    fit   171829      34c  ...    12  54.0   February 16, 2017\n",
              "154478    fit   776484      36c  ...    16  40.0  September 18, 2017\n",
              "128874    fit   116555     36d+  ...    20  46.0    October 22, 2013\n",
              "148347    fit   850301  Unknown  ...     4  36.0    November 7, 2016\n",
              "31603     fit   619769      32c  ...     8  33.0        May 29, 2014\n",
              "89411     fit   385028      38d  ...    28  25.0   February 14, 2017\n",
              "6758      fit   921065      34d  ...    20  46.0       July 31, 2014\n",
              "66387     fit   654956      34c  ...     8  39.0      April 30, 2017\n",
              "131732    fit   962072      34b  ...    12  27.0     August 19, 2016\n",
              "152391    fit    76139      36c  ...     8  32.0   December 14, 2016\n",
              "140308    fit   658735      34b  ...    12  28.0        June 9, 2015\n",
              "141786  small   958654      34a  ...    12  26.0      March 28, 2017\n",
              "41145     fit   511773      32d  ...    12  44.0    October 25, 2012\n",
              "58241     fit    29961      32c  ...     4  35.0        May 26, 2014\n",
              "149667    fit   358752      34d  ...     8  41.0      April 27, 2014\n",
              "70266     fit   884002      32b  ...     1  22.0   November 13, 2017\n",
              "\n",
              "[20 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7zyS5g21WqC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "f3c24260-4267-43d2-a1da-e268896a3f60"
      },
      "source": [
        "#convertng height from feet and inches into cm\n",
        "def convert_to_cms(x):\n",
        "  if type(x) == type(1.0):\n",
        "    return\n",
        "  try:\n",
        "    return (int(x[0])*30.48) + (int(x[3:-1])*2.54)\n",
        "  except:\n",
        "    return (int(x[0])*30.48)\n",
        "\n",
        "cloth_data.height = cloth_data.height.apply(convert_to_cms)\n",
        "cloth_data.head()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>item_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>rating</th>\n",
              "      <th>rented_for</th>\n",
              "      <th>review_text</th>\n",
              "      <th>body_type</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>category</th>\n",
              "      <th>height</th>\n",
              "      <th>size</th>\n",
              "      <th>age</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31707</th>\n",
              "      <td>large</td>\n",
              "      <td>222286</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>134849</td>\n",
              "      <td>135lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>followed reviewers advice and sized down for b...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>really clean lines, pretty dress AND comfortab...</td>\n",
              "      <td>gown</td>\n",
              "      <td>162.56</td>\n",
              "      <td>12</td>\n",
              "      <td>44.0</td>\n",
              "      <td>November 19, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64978</th>\n",
              "      <td>fit</td>\n",
              "      <td>239140</td>\n",
              "      <td>36c</td>\n",
              "      <td>770712</td>\n",
              "      <td>185lbs</td>\n",
              "      <td>8.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>It is true to size, the color is more burgundy...</td>\n",
              "      <td>pear</td>\n",
              "      <td>I used this outfit for formal family photos.  ...</td>\n",
              "      <td>dress</td>\n",
              "      <td>165.10</td>\n",
              "      <td>28</td>\n",
              "      <td>40.0</td>\n",
              "      <td>April 11, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99684</th>\n",
              "      <td>small</td>\n",
              "      <td>280782</td>\n",
              "      <td>34b</td>\n",
              "      <td>2511676</td>\n",
              "      <td>118lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>vacation</td>\n",
              "      <td>Great jacket to dress up jeans or dress down a...</td>\n",
              "      <td>athletic</td>\n",
              "      <td>Perfect!</td>\n",
              "      <td>jacket</td>\n",
              "      <td>162.56</td>\n",
              "      <td>8</td>\n",
              "      <td>64.0</td>\n",
              "      <td>May 15, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103627</th>\n",
              "      <td>large</td>\n",
              "      <td>513187</td>\n",
              "      <td>36c</td>\n",
              "      <td>806803</td>\n",
              "      <td>125lbs</td>\n",
              "      <td>8.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>This dress fit maybe a little big. I normally ...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Beautiful lace dress that flattered all the ri...</td>\n",
              "      <td>dress</td>\n",
              "      <td>162.56</td>\n",
              "      <td>8</td>\n",
              "      <td>40.0</td>\n",
              "      <td>November 28, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126534</th>\n",
              "      <td>fit</td>\n",
              "      <td>171829</td>\n",
              "      <td>34c</td>\n",
              "      <td>1980086</td>\n",
              "      <td>130lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>Incredibly comfortable and forgiving dress.  I...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Great night, great dress, great charity event.</td>\n",
              "      <td>gown</td>\n",
              "      <td>167.64</td>\n",
              "      <td>12</td>\n",
              "      <td>54.0</td>\n",
              "      <td>February 16, 2017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          fit  user_id bra_size  item_id  ...  height  size   age        review_date\n",
              "31707   large   222286  Unknown   134849  ...  162.56    12  44.0  November 19, 2013\n",
              "64978     fit   239140      36c   770712  ...  165.10    28  40.0     April 11, 2017\n",
              "99684   small   280782      34b  2511676  ...  162.56     8  64.0       May 15, 2016\n",
              "103627  large   513187      36c   806803  ...  162.56     8  40.0  November 28, 2014\n",
              "126534    fit   171829      34c  1980086  ...  167.64    12  54.0  February 16, 2017\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6iIDK-I1k-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "83a4f351-f593-48ed-8278-93459b072a39"
      },
      "source": [
        "#get the missing values from the code\n",
        "missing_data = pd.DataFrame({'total_missing': cloth_data.isnull().sum(), 'perc_missing': (cloth_data.isnull().sum()/82790)*100})\n",
        "missing_data"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_missing</th>\n",
              "      <th>perc_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>fit</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_id</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bra_size</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>item_id</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight</th>\n",
              "      <td>29982</td>\n",
              "      <td>36.214519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <td>82</td>\n",
              "      <td>0.099046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rented_for</th>\n",
              "      <td>10</td>\n",
              "      <td>0.012079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_text</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>body_type</th>\n",
              "      <td>14637</td>\n",
              "      <td>17.679671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_summary</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>height</th>\n",
              "      <td>677</td>\n",
              "      <td>0.817732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>size</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>960</td>\n",
              "      <td>1.159560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_date</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                total_missing  perc_missing\n",
              "fit                         0      0.000000\n",
              "user_id                     0      0.000000\n",
              "bra_size                    0      0.000000\n",
              "item_id                     0      0.000000\n",
              "weight                  29982     36.214519\n",
              "rating                     82      0.099046\n",
              "rented_for                 10      0.012079\n",
              "review_text                 0      0.000000\n",
              "body_type               14637     17.679671\n",
              "review_summary              0      0.000000\n",
              "category                    0      0.000000\n",
              "height                    677      0.817732\n",
              "size                        0      0.000000\n",
              "age                       960      1.159560\n",
              "review_date                 0      0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5uadH131sy5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "60f3f1ce-47d1-4cc3-91dd-0ae177367069"
      },
      "source": [
        "# In the following code sections, tried to change unknown into data by filling negative values.\n",
        "cloth_data.body_type.fillna('NA', inplace=True)\n",
        "cloth_data.head(1)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>item_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>rating</th>\n",
              "      <th>rented_for</th>\n",
              "      <th>review_text</th>\n",
              "      <th>body_type</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>category</th>\n",
              "      <th>height</th>\n",
              "      <th>size</th>\n",
              "      <th>age</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31707</th>\n",
              "      <td>large</td>\n",
              "      <td>222286</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>134849</td>\n",
              "      <td>135lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>followed reviewers advice and sized down for b...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>really clean lines, pretty dress AND comfortab...</td>\n",
              "      <td>gown</td>\n",
              "      <td>162.56</td>\n",
              "      <td>12</td>\n",
              "      <td>44.0</td>\n",
              "      <td>November 19, 2013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         fit  user_id bra_size  item_id  ...  height  size   age        review_date\n",
              "31707  large   222286  Unknown   134849  ...  162.56    12  44.0  November 19, 2013\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJovtxEd1u4O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "4a2e5ed9-676b-4739-e148-0756d7f6ca01"
      },
      "source": [
        "cloth_data.rating.fillna(-1.0, inplace=True)\n",
        "cloth_data.head(1)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>item_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>rating</th>\n",
              "      <th>rented_for</th>\n",
              "      <th>review_text</th>\n",
              "      <th>body_type</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>category</th>\n",
              "      <th>height</th>\n",
              "      <th>size</th>\n",
              "      <th>age</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31707</th>\n",
              "      <td>large</td>\n",
              "      <td>222286</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>134849</td>\n",
              "      <td>135lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>followed reviewers advice and sized down for b...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>really clean lines, pretty dress AND comfortab...</td>\n",
              "      <td>gown</td>\n",
              "      <td>162.56</td>\n",
              "      <td>12</td>\n",
              "      <td>44.0</td>\n",
              "      <td>November 19, 2013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         fit  user_id bra_size  item_id  ...  height  size   age        review_date\n",
              "31707  large   222286  Unknown   134849  ...  162.56    12  44.0  November 19, 2013\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNU833Lo1xdV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "55f10b99-0268-4b31-876f-d61ee3c10884"
      },
      "source": [
        "cloth_data.height.fillna(-1.0, inplace=True)\n",
        "cloth_data.head(1)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>item_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>rating</th>\n",
              "      <th>rented_for</th>\n",
              "      <th>review_text</th>\n",
              "      <th>body_type</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>category</th>\n",
              "      <th>height</th>\n",
              "      <th>size</th>\n",
              "      <th>age</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31707</th>\n",
              "      <td>large</td>\n",
              "      <td>222286</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>134849</td>\n",
              "      <td>135lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>followed reviewers advice and sized down for b...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>really clean lines, pretty dress AND comfortab...</td>\n",
              "      <td>gown</td>\n",
              "      <td>162.56</td>\n",
              "      <td>12</td>\n",
              "      <td>44.0</td>\n",
              "      <td>November 19, 2013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         fit  user_id bra_size  item_id  ...  height  size   age        review_date\n",
              "31707  large   222286  Unknown   134849  ...  162.56    12  44.0  November 19, 2013\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QoHFGE81z-5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "7545ddf4-5a24-4a80-b5be-978d3da6e8fa"
      },
      "source": [
        "cloth_data.age.fillna(-1.0, inplace=True)\n",
        "cloth_data.head(1)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>item_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>rating</th>\n",
              "      <th>rented_for</th>\n",
              "      <th>review_text</th>\n",
              "      <th>body_type</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>category</th>\n",
              "      <th>height</th>\n",
              "      <th>size</th>\n",
              "      <th>age</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31707</th>\n",
              "      <td>large</td>\n",
              "      <td>222286</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>134849</td>\n",
              "      <td>135lbs</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>followed reviewers advice and sized down for b...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>really clean lines, pretty dress AND comfortab...</td>\n",
              "      <td>gown</td>\n",
              "      <td>162.56</td>\n",
              "      <td>12</td>\n",
              "      <td>44.0</td>\n",
              "      <td>November 19, 2013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         fit  user_id bra_size  item_id  ...  height  size   age        review_date\n",
              "31707  large   222286  Unknown   134849  ...  162.56    12  44.0  November 19, 2013\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0euzPVy35ou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "c83745eb-6606-43bf-eea1-e8711bc017b6"
      },
      "source": [
        "#removing the lbs from the weight\n",
        "cloth_data['weight'] = cloth_data['weight'].map(lambda x: str(x)[:-3])\n",
        "cloth_data.head(10)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>item_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>rating</th>\n",
              "      <th>rented_for</th>\n",
              "      <th>review_text</th>\n",
              "      <th>body_type</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>category</th>\n",
              "      <th>height</th>\n",
              "      <th>size</th>\n",
              "      <th>age</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31707</th>\n",
              "      <td>large</td>\n",
              "      <td>222286</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>134849</td>\n",
              "      <td>135</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>followed reviewers advice and sized down for b...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>really clean lines, pretty dress AND comfortab...</td>\n",
              "      <td>gown</td>\n",
              "      <td>162.56</td>\n",
              "      <td>12</td>\n",
              "      <td>44.0</td>\n",
              "      <td>November 19, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64978</th>\n",
              "      <td>fit</td>\n",
              "      <td>239140</td>\n",
              "      <td>36c</td>\n",
              "      <td>770712</td>\n",
              "      <td>185</td>\n",
              "      <td>8.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>It is true to size, the color is more burgundy...</td>\n",
              "      <td>pear</td>\n",
              "      <td>I used this outfit for formal family photos.  ...</td>\n",
              "      <td>dress</td>\n",
              "      <td>165.10</td>\n",
              "      <td>28</td>\n",
              "      <td>40.0</td>\n",
              "      <td>April 11, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99684</th>\n",
              "      <td>small</td>\n",
              "      <td>280782</td>\n",
              "      <td>34b</td>\n",
              "      <td>2511676</td>\n",
              "      <td>118</td>\n",
              "      <td>10.0</td>\n",
              "      <td>vacation</td>\n",
              "      <td>Great jacket to dress up jeans or dress down a...</td>\n",
              "      <td>athletic</td>\n",
              "      <td>Perfect!</td>\n",
              "      <td>jacket</td>\n",
              "      <td>162.56</td>\n",
              "      <td>8</td>\n",
              "      <td>64.0</td>\n",
              "      <td>May 15, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103627</th>\n",
              "      <td>large</td>\n",
              "      <td>513187</td>\n",
              "      <td>36c</td>\n",
              "      <td>806803</td>\n",
              "      <td>125</td>\n",
              "      <td>8.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>This dress fit maybe a little big. I normally ...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Beautiful lace dress that flattered all the ri...</td>\n",
              "      <td>dress</td>\n",
              "      <td>162.56</td>\n",
              "      <td>8</td>\n",
              "      <td>40.0</td>\n",
              "      <td>November 28, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126534</th>\n",
              "      <td>fit</td>\n",
              "      <td>171829</td>\n",
              "      <td>34c</td>\n",
              "      <td>1980086</td>\n",
              "      <td>130</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>Incredibly comfortable and forgiving dress.  I...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Great night, great dress, great charity event.</td>\n",
              "      <td>gown</td>\n",
              "      <td>167.64</td>\n",
              "      <td>12</td>\n",
              "      <td>54.0</td>\n",
              "      <td>February 16, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154478</th>\n",
              "      <td>fit</td>\n",
              "      <td>776484</td>\n",
              "      <td>36c</td>\n",
              "      <td>2600623</td>\n",
              "      <td></td>\n",
              "      <td>10.0</td>\n",
              "      <td>everyday</td>\n",
              "      <td>I wore this several times while I had it rente...</td>\n",
              "      <td>full bust</td>\n",
              "      <td>Perfect for work or casual wear!</td>\n",
              "      <td>top</td>\n",
              "      <td>160.02</td>\n",
              "      <td>16</td>\n",
              "      <td>40.0</td>\n",
              "      <td>September 18, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128874</th>\n",
              "      <td>fit</td>\n",
              "      <td>116555</td>\n",
              "      <td>36d+</td>\n",
              "      <td>132738</td>\n",
              "      <td>150</td>\n",
              "      <td>8.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>This gown is REALLY sparkly!  You will definit...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Beautiful gown!</td>\n",
              "      <td>gown</td>\n",
              "      <td>160.02</td>\n",
              "      <td>20</td>\n",
              "      <td>46.0</td>\n",
              "      <td>October 22, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148347</th>\n",
              "      <td>fit</td>\n",
              "      <td>850301</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>1003076</td>\n",
              "      <td>125</td>\n",
              "      <td>10.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>I ordered a 2 and 4 and ended up wearing the 2...</td>\n",
              "      <td>NA</td>\n",
              "      <td>Dresses arrived on time and both looked brand ...</td>\n",
              "      <td>dress</td>\n",
              "      <td>170.18</td>\n",
              "      <td>4</td>\n",
              "      <td>36.0</td>\n",
              "      <td>November 7, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31603</th>\n",
              "      <td>fit</td>\n",
              "      <td>619769</td>\n",
              "      <td>32c</td>\n",
              "      <td>169961</td>\n",
              "      <td>134</td>\n",
              "      <td>8.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>This dress was amazing! It was tight and close...</td>\n",
              "      <td>athletic</td>\n",
              "      <td>Git like a glove</td>\n",
              "      <td>sheath</td>\n",
              "      <td>170.18</td>\n",
              "      <td>8</td>\n",
              "      <td>33.0</td>\n",
              "      <td>May 29, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89411</th>\n",
              "      <td>fit</td>\n",
              "      <td>385028</td>\n",
              "      <td>38d</td>\n",
              "      <td>820057</td>\n",
              "      <td></td>\n",
              "      <td>8.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>It does fit a little tight in the hips/midsect...</td>\n",
              "      <td>full bust</td>\n",
              "      <td>I got so many compliments on this dress! Wore ...</td>\n",
              "      <td>gown</td>\n",
              "      <td>170.18</td>\n",
              "      <td>28</td>\n",
              "      <td>25.0</td>\n",
              "      <td>February 14, 2017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          fit  user_id bra_size  ...  size   age         review_date\n",
              "31707   large   222286  Unknown  ...    12  44.0   November 19, 2013\n",
              "64978     fit   239140      36c  ...    28  40.0      April 11, 2017\n",
              "99684   small   280782      34b  ...     8  64.0        May 15, 2016\n",
              "103627  large   513187      36c  ...     8  40.0   November 28, 2014\n",
              "126534    fit   171829      34c  ...    12  54.0   February 16, 2017\n",
              "154478    fit   776484      36c  ...    16  40.0  September 18, 2017\n",
              "128874    fit   116555     36d+  ...    20  46.0    October 22, 2013\n",
              "148347    fit   850301  Unknown  ...     4  36.0    November 7, 2016\n",
              "31603     fit   619769      32c  ...     8  33.0        May 29, 2014\n",
              "89411     fit   385028      38d  ...    28  25.0   February 14, 2017\n",
              "\n",
              "[10 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOJkgLym4HEu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "e7ec9d23-13c5-4f7c-ae5f-3a8f874e75ce"
      },
      "source": [
        "#remove blank spaces from the weight column and add nan to it\n",
        "import numpy as np\n",
        "\n",
        "cloth_data=cloth_data.replace(r'^\\s*$', np.nan, regex=True)\n",
        "cloth_data.weight.fillna('-1', inplace=True)\n",
        "cloth_data.head(5)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>item_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>rating</th>\n",
              "      <th>rented_for</th>\n",
              "      <th>review_text</th>\n",
              "      <th>body_type</th>\n",
              "      <th>review_summary</th>\n",
              "      <th>category</th>\n",
              "      <th>height</th>\n",
              "      <th>size</th>\n",
              "      <th>age</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31707</th>\n",
              "      <td>large</td>\n",
              "      <td>222286</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>134849</td>\n",
              "      <td>135</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>followed reviewers advice and sized down for b...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>really clean lines, pretty dress AND comfortab...</td>\n",
              "      <td>gown</td>\n",
              "      <td>162.56</td>\n",
              "      <td>12</td>\n",
              "      <td>44.0</td>\n",
              "      <td>November 19, 2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64978</th>\n",
              "      <td>fit</td>\n",
              "      <td>239140</td>\n",
              "      <td>36c</td>\n",
              "      <td>770712</td>\n",
              "      <td>185</td>\n",
              "      <td>8.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>It is true to size, the color is more burgundy...</td>\n",
              "      <td>pear</td>\n",
              "      <td>I used this outfit for formal family photos.  ...</td>\n",
              "      <td>dress</td>\n",
              "      <td>165.10</td>\n",
              "      <td>28</td>\n",
              "      <td>40.0</td>\n",
              "      <td>April 11, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99684</th>\n",
              "      <td>small</td>\n",
              "      <td>280782</td>\n",
              "      <td>34b</td>\n",
              "      <td>2511676</td>\n",
              "      <td>118</td>\n",
              "      <td>10.0</td>\n",
              "      <td>vacation</td>\n",
              "      <td>Great jacket to dress up jeans or dress down a...</td>\n",
              "      <td>athletic</td>\n",
              "      <td>Perfect!</td>\n",
              "      <td>jacket</td>\n",
              "      <td>162.56</td>\n",
              "      <td>8</td>\n",
              "      <td>64.0</td>\n",
              "      <td>May 15, 2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103627</th>\n",
              "      <td>large</td>\n",
              "      <td>513187</td>\n",
              "      <td>36c</td>\n",
              "      <td>806803</td>\n",
              "      <td>125</td>\n",
              "      <td>8.0</td>\n",
              "      <td>wedding</td>\n",
              "      <td>This dress fit maybe a little big. I normally ...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Beautiful lace dress that flattered all the ri...</td>\n",
              "      <td>dress</td>\n",
              "      <td>162.56</td>\n",
              "      <td>8</td>\n",
              "      <td>40.0</td>\n",
              "      <td>November 28, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126534</th>\n",
              "      <td>fit</td>\n",
              "      <td>171829</td>\n",
              "      <td>34c</td>\n",
              "      <td>1980086</td>\n",
              "      <td>130</td>\n",
              "      <td>10.0</td>\n",
              "      <td>formal affair</td>\n",
              "      <td>Incredibly comfortable and forgiving dress.  I...</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>Great night, great dress, great charity event.</td>\n",
              "      <td>gown</td>\n",
              "      <td>167.64</td>\n",
              "      <td>12</td>\n",
              "      <td>54.0</td>\n",
              "      <td>February 16, 2017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          fit  user_id bra_size  item_id  ...  height  size   age        review_date\n",
              "31707   large   222286  Unknown   134849  ...  162.56    12  44.0  November 19, 2013\n",
              "64978     fit   239140      36c   770712  ...  165.10    28  40.0     April 11, 2017\n",
              "99684   small   280782      34b  2511676  ...  162.56     8  64.0       May 15, 2016\n",
              "103627  large   513187      36c   806803  ...  162.56     8  40.0  November 28, 2014\n",
              "126534    fit   171829      34c  1980086  ...  167.64    12  54.0  February 16, 2017\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anzNjGVW11H6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "27d2d3fd-82f1-49b8-beec-f0646486b528"
      },
      "source": [
        "missing_data = pd.DataFrame({'total_missing': cloth_data.isnull().sum(), 'perc_missing': (cloth_data.isnull().sum()/82790)*100})\n",
        "missing_data"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_missing</th>\n",
              "      <th>perc_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>fit</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_id</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bra_size</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>item_id</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weight</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rented_for</th>\n",
              "      <td>10</td>\n",
              "      <td>0.012079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_text</th>\n",
              "      <td>2</td>\n",
              "      <td>0.002416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>body_type</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_summary</th>\n",
              "      <td>16</td>\n",
              "      <td>0.019326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>height</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>size</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_date</th>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                total_missing  perc_missing\n",
              "fit                         0      0.000000\n",
              "user_id                     0      0.000000\n",
              "bra_size                    0      0.000000\n",
              "item_id                     0      0.000000\n",
              "weight                      0      0.000000\n",
              "rating                      0      0.000000\n",
              "rented_for                 10      0.012079\n",
              "review_text                 2      0.002416\n",
              "body_type                   0      0.000000\n",
              "review_summary             16      0.019326\n",
              "category                    0      0.000000\n",
              "height                      0      0.000000\n",
              "size                        0      0.000000\n",
              "age                         0      0.000000\n",
              "review_date                 0      0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBIjyUe83SXN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "30c445df-b76b-469a-a5d3-c70738647a06"
      },
      "source": [
        "#dropping unnecessary data\n",
        "cloth_data = cloth_data.drop(['rented_for', 'review_text', 'review_summary', 'category', 'review_date'], axis=1)\n",
        "cloth_data.head()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>item_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>rating</th>\n",
              "      <th>body_type</th>\n",
              "      <th>height</th>\n",
              "      <th>size</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31707</th>\n",
              "      <td>large</td>\n",
              "      <td>222286</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>134849</td>\n",
              "      <td>135</td>\n",
              "      <td>10.0</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>162.56</td>\n",
              "      <td>12</td>\n",
              "      <td>44.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64978</th>\n",
              "      <td>fit</td>\n",
              "      <td>239140</td>\n",
              "      <td>36c</td>\n",
              "      <td>770712</td>\n",
              "      <td>185</td>\n",
              "      <td>8.0</td>\n",
              "      <td>pear</td>\n",
              "      <td>165.10</td>\n",
              "      <td>28</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99684</th>\n",
              "      <td>small</td>\n",
              "      <td>280782</td>\n",
              "      <td>34b</td>\n",
              "      <td>2511676</td>\n",
              "      <td>118</td>\n",
              "      <td>10.0</td>\n",
              "      <td>athletic</td>\n",
              "      <td>162.56</td>\n",
              "      <td>8</td>\n",
              "      <td>64.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103627</th>\n",
              "      <td>large</td>\n",
              "      <td>513187</td>\n",
              "      <td>36c</td>\n",
              "      <td>806803</td>\n",
              "      <td>125</td>\n",
              "      <td>8.0</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>162.56</td>\n",
              "      <td>8</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126534</th>\n",
              "      <td>fit</td>\n",
              "      <td>171829</td>\n",
              "      <td>34c</td>\n",
              "      <td>1980086</td>\n",
              "      <td>130</td>\n",
              "      <td>10.0</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>167.64</td>\n",
              "      <td>12</td>\n",
              "      <td>54.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          fit  user_id bra_size  item_id  ...  body_type  height size   age\n",
              "31707   large   222286  Unknown   134849  ...  hourglass  162.56   12  44.0\n",
              "64978     fit   239140      36c   770712  ...       pear  165.10   28  40.0\n",
              "99684   small   280782      34b  2511676  ...   athletic  162.56    8  64.0\n",
              "103627  large   513187      36c   806803  ...  hourglass  162.56    8  40.0\n",
              "126534    fit   171829      34c  1980086  ...  hourglass  167.64   12  54.0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3qJC3qz3hEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Changing the data type in order to consider as a valid feature in tensor flow.\n",
        "cloth_data['body_type'] = cloth_data['body_type'].astype(str)\n",
        "cloth_data['bra_size'] = cloth_data['bra_size'].astype(str)\n",
        "cloth_data['weight'] = cloth_data['weight'].astype(float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtSalTWZ30IC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "c453748c-4ae1-49b6-987e-e7cfa3336692"
      },
      "source": [
        "cloth_data.head(1)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>item_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>rating</th>\n",
              "      <th>body_type</th>\n",
              "      <th>height</th>\n",
              "      <th>size</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>161190</th>\n",
              "      <td>fit</td>\n",
              "      <td>491957</td>\n",
              "      <td>36d</td>\n",
              "      <td>1697202</td>\n",
              "      <td>135.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>154.94</td>\n",
              "      <td>20</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        fit  user_id bra_size  item_id  ...  body_type  height size   age\n",
              "161190  fit   491957      36d  1697202  ...  hourglass  154.94   20  46.0\n",
              "\n",
              "[1 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6A-P0rM31_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "6cfd8a25-17fd-46dc-d410-39a636a252a1"
      },
      "source": [
        "# for two algorithms DNN classifier and Logistic regressing will convert fit into interger values \n",
        "cloth_data['fit'] = cloth_data.fit.replace('small' , 0)\n",
        "cloth_data['fit'] = cloth_data.fit.replace(\"fit\" , 1)\n",
        "cloth_data['fit'] = cloth_data.fit.replace(\"large\" , 2)\n",
        "cloth_data.head(1)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fit</th>\n",
              "      <th>user_id</th>\n",
              "      <th>bra_size</th>\n",
              "      <th>item_id</th>\n",
              "      <th>weight</th>\n",
              "      <th>rating</th>\n",
              "      <th>body_type</th>\n",
              "      <th>height</th>\n",
              "      <th>size</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>161190</th>\n",
              "      <td>1</td>\n",
              "      <td>491957</td>\n",
              "      <td>36d</td>\n",
              "      <td>1697202</td>\n",
              "      <td>135.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>hourglass</td>\n",
              "      <td>154.94</td>\n",
              "      <td>20</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        fit  user_id bra_size  item_id  ...  body_type  height size   age\n",
              "161190    1   491957      36d  1697202  ...  hourglass  154.94   20  46.0\n",
              "\n",
              "[1 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKRMs6IoXsOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for keras sequencial algorithn we wil convet it to one hot encoding in order to predict other features like tp, tr etc\n",
        "cloth_data['fit_one_hot'] = cloth_data['fit'].str.get_dummies().values.tolist()\n",
        "cloth_data = cloth_data.drop('fit',axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxjtepJ_5bV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "50ee6bbc-b498-4efa-bcf8-6dca0f52d262"
      },
      "source": [
        "cloth_data.info()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 192544 entries, 161190 to 1833\n",
            "Data columns (total 10 columns):\n",
            "fit          192544 non-null int64\n",
            "user_id      192544 non-null int64\n",
            "bra_size     192544 non-null object\n",
            "item_id      192544 non-null int64\n",
            "weight       192544 non-null float64\n",
            "rating       192544 non-null float64\n",
            "body_type    192544 non-null object\n",
            "height       192544 non-null float64\n",
            "size         192544 non-null int64\n",
            "age          192544 non-null float64\n",
            "dtypes: float64(4), int64(4), object(2)\n",
            "memory usage: 16.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0toZpHO5k4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.decomposition import PCA\n",
        "# import numpy as np\n",
        "# pca = PCA(n_components=len(cloth_data))\n",
        "# pca.fit(cloth_data)\n",
        "# cloth_data = np.matmul(cloth_data, pca.components_.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6yUBods55Pu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAJpO4veOQQP",
        "colab_type": "text"
      },
      "source": [
        "**Converting preprocessed data from pandas to tensorflow for multiclass classification.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AidcQ-Fa5kBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import tensorflow libraries for multi class classification\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h5DmxXm5nSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split the data into training and testing\n",
        "train, test = train_test_split(cloth_data, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ0MOQ9M5pF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split the training data into training and validation\n",
        "train, val = train_test_split(train, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nIK7Jg95rsK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ac7612af-9346-4d85-dcd4-cc0ba2df1722"
      },
      "source": [
        "print(len(train))\n",
        "print(len(test))\n",
        "print(len(val))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "123228\n",
            "38509\n",
            "30807\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2U7SFYj6ckk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_columns = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8lRJZW_6fXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# consider the below features as numerical \n",
        "feature_columns.append(feature_column.numeric_column(\"weight\"))\n",
        "feature_columns.append(feature_column.numeric_column(\"rating\"))\n",
        "feature_columns.append(feature_column.numeric_column(\"height\"))\n",
        "feature_columns.append(feature_column.numeric_column(\"age\"))\n",
        "feature_columns.append(feature_column.numeric_column(\"size\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7p1BEna6ixr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# consider the below features as categorical\n",
        "bra_size = feature_column.categorical_column_with_vocabulary_list(\n",
        "      'bra_size', cloth_data.bra_size.unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouNP2-dS6mbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bra_size_one_hot = feature_column.indicator_column(bra_size)\n",
        "feature_columns.append(bra_size_one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBpl2bE86oI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "item_id = feature_column.categorical_column_with_vocabulary_list(\n",
        "      'item_id', cloth_data.item_id.unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvV4NOz_6pdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "item_id_one_hot = feature_column.indicator_column(item_id)\n",
        "feature_columns.append(item_id_one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJFlu2Am6qtY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "body_type = feature_column.categorical_column_with_vocabulary_list(\n",
        "      'body_type', cloth_data.body_type.unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRC88UY66sHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "body_type_one_hot = feature_column.indicator_column(body_type)\n",
        "feature_columns.append(body_type_one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT5oby27CPUs",
        "colab_type": "text"
      },
      "source": [
        "Execute the below steps for classifiying labels from features using **tensorflow's DNN Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwidV6xnDBKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pop the fit label for train as well as validation\n",
        "y_train = train.pop('fit')\n",
        "y_val = val.pop('fit')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgQSxBfZCWje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_fn(features, labels, training=True, batch_size=512):\n",
        "    # Converting into tensorflow Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "    # shuffle if in training mode.\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(1000).repeat()\n",
        "    \n",
        "    return dataset.batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ5ScujOCZL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_input_fn = input_fn(train, y_train)\n",
        "# eval_input_fn = input_fn(val, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdDeeZmoCnpm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "21bea656-1dac-4ec0-af95-8b3fc1ede529"
      },
      "source": [
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=feature_columns,\n",
        "    # Setting the nodes to 30 and 10 for hidden layes.\n",
        "    hidden_units=[30, 10],\n",
        "    # Choose from 3 classes i.e. fit, small and large\n",
        "    n_classes=3)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp29slv7yk\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp29slv7yk', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7fd13f11d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BLCI_4VCtDF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e0b0cd15-a9b4-4b65-e141-3b56fff7fa81"
      },
      "source": [
        "classifier.train(\n",
        "    input_fn=lambda: input_fn(train, y_train, training=True),\n",
        "    steps=5000)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp29slv7yk/model.ckpt.\n",
            "INFO:tensorflow:loss = 6105.871, step = 1\n",
            "INFO:tensorflow:global_step/sec: 20.1333\n",
            "INFO:tensorflow:loss = 382.19476, step = 101 (4.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.0913\n",
            "INFO:tensorflow:loss = 388.76733, step = 201 (4.737 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.1868\n",
            "INFO:tensorflow:loss = 345.4885, step = 301 (4.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.3161\n",
            "INFO:tensorflow:loss = 385.5658, step = 401 (4.693 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.4341\n",
            "INFO:tensorflow:loss = 382.7843, step = 501 (4.667 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.0769\n",
            "INFO:tensorflow:loss = 406.51447, step = 601 (4.742 sec)\n",
            "INFO:tensorflow:global_step/sec: 20.9958\n",
            "INFO:tensorflow:loss = 376.99768, step = 701 (4.763 sec)\n",
            "INFO:tensorflow:global_step/sec: 20.9829\n",
            "INFO:tensorflow:loss = 406.6423, step = 801 (4.766 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.0712\n",
            "INFO:tensorflow:loss = 357.04053, step = 901 (4.746 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.5533\n",
            "INFO:tensorflow:loss = 368.2385, step = 1001 (5.389 sec)\n",
            "INFO:tensorflow:global_step/sec: 20.9282\n",
            "INFO:tensorflow:loss = 380.75818, step = 1101 (4.778 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.1766\n",
            "INFO:tensorflow:loss = 371.65762, step = 1201 (4.727 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.1441\n",
            "INFO:tensorflow:loss = 353.5031, step = 1301 (4.728 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.3002\n",
            "INFO:tensorflow:loss = 377.80563, step = 1401 (4.694 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.201\n",
            "INFO:tensorflow:loss = 361.3239, step = 1501 (4.716 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.146\n",
            "INFO:tensorflow:loss = 360.4387, step = 1601 (4.728 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.158\n",
            "INFO:tensorflow:loss = 347.411, step = 1701 (4.727 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.3144\n",
            "INFO:tensorflow:loss = 345.04608, step = 1801 (4.695 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.0931\n",
            "INFO:tensorflow:loss = 362.4859, step = 1901 (4.737 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.0109\n",
            "INFO:tensorflow:loss = 392.22562, step = 2001 (4.760 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.0821\n",
            "INFO:tensorflow:loss = 378.04236, step = 2101 (4.748 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.0399\n",
            "INFO:tensorflow:loss = 382.43286, step = 2201 (4.747 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.3409\n",
            "INFO:tensorflow:loss = 348.73993, step = 2301 (4.686 sec)\n",
            "INFO:tensorflow:global_step/sec: 20.9854\n",
            "INFO:tensorflow:loss = 353.8252, step = 2401 (4.771 sec)\n",
            "INFO:tensorflow:global_step/sec: 20.739\n",
            "INFO:tensorflow:loss = 365.35727, step = 2501 (4.816 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.0678\n",
            "INFO:tensorflow:loss = 348.53967, step = 2601 (4.747 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.223\n",
            "INFO:tensorflow:loss = 364.79578, step = 2701 (4.712 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.177\n",
            "INFO:tensorflow:loss = 371.4746, step = 2801 (4.722 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.5261\n",
            "INFO:tensorflow:loss = 336.27417, step = 2901 (4.646 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.333\n",
            "INFO:tensorflow:loss = 320.33917, step = 3001 (4.690 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.4278\n",
            "INFO:tensorflow:loss = 344.8446, step = 3101 (4.663 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.2995\n",
            "INFO:tensorflow:loss = 343.87335, step = 3201 (4.695 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.2764\n",
            "INFO:tensorflow:loss = 388.8957, step = 3301 (4.702 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.4922\n",
            "INFO:tensorflow:loss = 386.22964, step = 3401 (4.651 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.4019\n",
            "INFO:tensorflow:loss = 345.2874, step = 3501 (4.673 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.6623\n",
            "INFO:tensorflow:loss = 361.7139, step = 3601 (4.616 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.6978\n",
            "INFO:tensorflow:loss = 358.0369, step = 3701 (4.612 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.5471\n",
            "INFO:tensorflow:loss = 347.10312, step = 3801 (4.638 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.7943\n",
            "INFO:tensorflow:loss = 355.5774, step = 3901 (4.589 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.6158\n",
            "INFO:tensorflow:loss = 348.84808, step = 4001 (4.633 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.8077\n",
            "INFO:tensorflow:loss = 351.30545, step = 4101 (4.579 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.7179\n",
            "INFO:tensorflow:loss = 353.2239, step = 4201 (4.605 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.7373\n",
            "INFO:tensorflow:loss = 327.213, step = 4301 (4.599 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.7777\n",
            "INFO:tensorflow:loss = 356.89117, step = 4401 (4.593 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.8345\n",
            "INFO:tensorflow:loss = 357.7105, step = 4501 (4.579 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.5127\n",
            "INFO:tensorflow:loss = 341.50244, step = 4601 (4.648 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.9372\n",
            "INFO:tensorflow:loss = 360.23724, step = 4701 (4.558 sec)\n",
            "INFO:tensorflow:global_step/sec: 21.7024\n",
            "INFO:tensorflow:loss = 362.5089, step = 4801 (4.607 sec)\n",
            "INFO:tensorflow:global_step/sec: 22.2246\n",
            "INFO:tensorflow:loss = 340.36768, step = 4901 (4.499 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmp29slv7yk/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 346.2915.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x7f7fd2de1128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OEjk0O1C3SU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "847f3333-60b1-4678-89a7-b2fe8e9da140"
      },
      "source": [
        "#evaluate based on the trained model\n",
        "eval_result = classifier.evaluate(\n",
        "    input_fn=lambda: input_fn(val, y_val, training=False))\n",
        "\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-11-21T05:56:22Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp29slv7yk/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-11-21-05:56:25\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.7416496, average_loss = 0.6941242, global_step = 5000, loss = 350.55548\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmp29slv7yk/model.ckpt-5000\n",
            "\n",
            "Test set accuracy: 0.742\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbm7TbA4Eu3F",
        "colab_type": "text"
      },
      "source": [
        "Execute the below steps for classifiying labels from features using **tensorflow's Linear Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZI7c95EFF9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def make_input_fn(data_df, num_epochs=200, shuffle=True, batch_size=512):\n",
        "  def input_function():\n",
        "    # pop the fit for label and assign it to a variable \n",
        "    label_df = data_df.pop('fit')\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
        "    #shuffle if in training mode.\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    return ds\n",
        "  return input_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZaxyBlpFzn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#take train data and fit it into function defined.\n",
        "train_input_fn = make_input_fn(train)\n",
        "eval_input_fn = make_input_fn(val, num_epochs=1, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEZhzN-8FNK8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "861e1e0f-15f9-45fe-8083-7d7a58a6889b"
      },
      "source": [
        "#train the model using linear classifier\n",
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns, n_classes=3)\n",
        "linear_est.train(train_input_fn)\n",
        "result = linear_est.evaluate(eval_input_fn)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpqv_i4zmv\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpqv_i4zmv', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7fd10b82b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:305: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpqv_i4zmv/model.ckpt.\n",
            "INFO:tensorflow:loss = 562.4896, step = 1\n",
            "INFO:tensorflow:global_step/sec: 25.7993\n",
            "INFO:tensorflow:loss = 1075.888, step = 101 (3.879 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.154\n",
            "INFO:tensorflow:loss = 793.2363, step = 201 (3.681 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.6885\n",
            "INFO:tensorflow:loss = 505.56845, step = 301 (3.748 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.7662\n",
            "INFO:tensorflow:loss = 494.5725, step = 401 (3.740 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.7971\n",
            "INFO:tensorflow:loss = 469.06903, step = 501 (3.729 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.086\n",
            "INFO:tensorflow:loss = 445.22424, step = 601 (3.690 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.263\n",
            "INFO:tensorflow:loss = 396.06485, step = 701 (3.667 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5302\n",
            "INFO:tensorflow:loss = 281.98053, step = 801 (3.635 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.7878\n",
            "INFO:tensorflow:loss = 534.8207, step = 901 (3.731 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2474\n",
            "INFO:tensorflow:loss = 393.508, step = 1001 (3.674 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1118\n",
            "INFO:tensorflow:loss = 377.5384, step = 1101 (3.684 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1059\n",
            "INFO:tensorflow:loss = 322.2235, step = 1201 (3.690 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7775\n",
            "INFO:tensorflow:loss = 402.022, step = 1301 (3.600 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6133\n",
            "INFO:tensorflow:loss = 316.14368, step = 1401 (3.621 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6337\n",
            "INFO:tensorflow:loss = 337.2005, step = 1501 (3.622 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5718\n",
            "INFO:tensorflow:loss = 382.06934, step = 1601 (3.624 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4461\n",
            "INFO:tensorflow:loss = 295.555, step = 1701 (3.643 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5554\n",
            "INFO:tensorflow:loss = 272.61206, step = 1801 (3.630 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5677\n",
            "INFO:tensorflow:loss = 325.34103, step = 1901 (3.626 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4414\n",
            "INFO:tensorflow:loss = 301.55847, step = 2001 (3.650 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5033\n",
            "INFO:tensorflow:loss = 365.35956, step = 2101 (3.635 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8675\n",
            "INFO:tensorflow:loss = 315.73413, step = 2201 (3.585 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1688\n",
            "INFO:tensorflow:loss = 343.9132, step = 2301 (3.681 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4368\n",
            "INFO:tensorflow:loss = 300.75925, step = 2401 (3.644 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9505\n",
            "INFO:tensorflow:loss = 318.47736, step = 2501 (3.577 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4574\n",
            "INFO:tensorflow:loss = 301.6966, step = 2601 (3.642 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0494\n",
            "INFO:tensorflow:loss = 288.13092, step = 2701 (3.566 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5026\n",
            "INFO:tensorflow:loss = 298.84155, step = 2801 (3.635 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5151\n",
            "INFO:tensorflow:loss = 248.23628, step = 2901 (3.634 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5929\n",
            "INFO:tensorflow:loss = 304.17133, step = 3001 (3.624 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.657\n",
            "INFO:tensorflow:loss = 298.2501, step = 3101 (3.616 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7584\n",
            "INFO:tensorflow:loss = 354.84222, step = 3201 (3.602 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.719\n",
            "INFO:tensorflow:loss = 301.68494, step = 3301 (3.608 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6193\n",
            "INFO:tensorflow:loss = 289.48926, step = 3401 (3.623 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6973\n",
            "INFO:tensorflow:loss = 304.25293, step = 3501 (3.609 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3996\n",
            "INFO:tensorflow:loss = 310.4317, step = 3601 (3.649 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1158\n",
            "INFO:tensorflow:loss = 327.5791, step = 3701 (3.688 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6141\n",
            "INFO:tensorflow:loss = 291.46094, step = 3801 (3.622 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7552\n",
            "INFO:tensorflow:loss = 284.40213, step = 3901 (3.602 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4332\n",
            "INFO:tensorflow:loss = 303.7697, step = 4001 (3.648 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8547\n",
            "INFO:tensorflow:loss = 304.84845, step = 4101 (3.587 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6712\n",
            "INFO:tensorflow:loss = 284.86975, step = 4201 (3.617 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.601\n",
            "INFO:tensorflow:loss = 280.0795, step = 4301 (3.623 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7451\n",
            "INFO:tensorflow:loss = 307.3515, step = 4401 (3.602 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5651\n",
            "INFO:tensorflow:loss = 313.19293, step = 4501 (3.627 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5597\n",
            "INFO:tensorflow:loss = 291.2298, step = 4601 (3.629 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8114\n",
            "INFO:tensorflow:loss = 304.6116, step = 4701 (3.595 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0366\n",
            "INFO:tensorflow:loss = 313.96222, step = 4801 (3.567 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7296\n",
            "INFO:tensorflow:loss = 267.02472, step = 4901 (3.607 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.3114\n",
            "INFO:tensorflow:loss = 268.91357, step = 5001 (3.531 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7657\n",
            "INFO:tensorflow:loss = 312.6975, step = 5101 (3.606 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9209\n",
            "INFO:tensorflow:loss = 291.23328, step = 5201 (3.577 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6816\n",
            "INFO:tensorflow:loss = 298.3056, step = 5301 (3.617 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.579\n",
            "INFO:tensorflow:loss = 294.57477, step = 5401 (3.623 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8862\n",
            "INFO:tensorflow:loss = 303.50177, step = 5501 (3.585 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.1478\n",
            "INFO:tensorflow:loss = 246.67413, step = 5601 (3.557 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4959\n",
            "INFO:tensorflow:loss = 287.90012, step = 5701 (3.633 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9978\n",
            "INFO:tensorflow:loss = 288.0912, step = 5801 (3.571 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8934\n",
            "INFO:tensorflow:loss = 270.039, step = 5901 (3.589 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.1006\n",
            "INFO:tensorflow:loss = 272.6301, step = 6001 (3.555 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0387\n",
            "INFO:tensorflow:loss = 287.67255, step = 6101 (3.569 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9216\n",
            "INFO:tensorflow:loss = 299.82373, step = 6201 (3.580 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8339\n",
            "INFO:tensorflow:loss = 306.70184, step = 6301 (3.592 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.1284\n",
            "INFO:tensorflow:loss = 308.79837, step = 6401 (3.560 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8997\n",
            "INFO:tensorflow:loss = 272.90308, step = 6501 (3.584 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0303\n",
            "INFO:tensorflow:loss = 264.86053, step = 6601 (3.563 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.3225\n",
            "INFO:tensorflow:loss = 317.38556, step = 6701 (3.531 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9313\n",
            "INFO:tensorflow:loss = 281.30743, step = 6801 (3.580 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4895\n",
            "INFO:tensorflow:loss = 294.48685, step = 6901 (3.640 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4016\n",
            "INFO:tensorflow:loss = 305.98914, step = 7001 (3.647 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1745\n",
            "INFO:tensorflow:loss = 288.51248, step = 7101 (3.679 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3743\n",
            "INFO:tensorflow:loss = 293.755, step = 7201 (3.653 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6652\n",
            "INFO:tensorflow:loss = 284.471, step = 7301 (3.615 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.0603\n",
            "INFO:tensorflow:loss = 321.90506, step = 7401 (3.700 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4157\n",
            "INFO:tensorflow:loss = 287.06494, step = 7501 (3.643 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5617\n",
            "INFO:tensorflow:loss = 250.79048, step = 7601 (3.628 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.671\n",
            "INFO:tensorflow:loss = 268.0721, step = 7701 (3.614 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6782\n",
            "INFO:tensorflow:loss = 278.88647, step = 7801 (3.613 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2452\n",
            "INFO:tensorflow:loss = 327.02313, step = 7901 (3.671 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.9232\n",
            "INFO:tensorflow:loss = 276.81638, step = 8001 (3.715 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.0888\n",
            "INFO:tensorflow:loss = 305.54083, step = 8101 (3.691 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4832\n",
            "INFO:tensorflow:loss = 281.36014, step = 8201 (3.639 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4381\n",
            "INFO:tensorflow:loss = 280.77762, step = 8301 (3.644 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6262\n",
            "INFO:tensorflow:loss = 288.06677, step = 8401 (3.621 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3553\n",
            "INFO:tensorflow:loss = 281.00525, step = 8501 (3.655 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3192\n",
            "INFO:tensorflow:loss = 302.07956, step = 8601 (3.663 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2099\n",
            "INFO:tensorflow:loss = 278.44104, step = 8701 (3.672 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.938\n",
            "INFO:tensorflow:loss = 287.2904, step = 8801 (3.713 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7059\n",
            "INFO:tensorflow:loss = 260.91333, step = 8901 (3.609 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5469\n",
            "INFO:tensorflow:loss = 330.41782, step = 9001 (3.634 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4663\n",
            "INFO:tensorflow:loss = 307.2146, step = 9101 (3.637 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.535\n",
            "INFO:tensorflow:loss = 277.40433, step = 9201 (3.636 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3577\n",
            "INFO:tensorflow:loss = 291.31744, step = 9301 (3.651 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.9066\n",
            "INFO:tensorflow:loss = 282.0691, step = 9401 (3.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5108\n",
            "INFO:tensorflow:loss = 286.00266, step = 9501 (3.635 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7666\n",
            "INFO:tensorflow:loss = 276.08435, step = 9601 (3.597 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3638\n",
            "INFO:tensorflow:loss = 297.6671, step = 9701 (3.654 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9295\n",
            "INFO:tensorflow:loss = 281.33392, step = 9801 (3.581 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7236\n",
            "INFO:tensorflow:loss = 285.62454, step = 9901 (3.606 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2796\n",
            "INFO:tensorflow:loss = 323.0276, step = 10001 (3.666 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4269\n",
            "INFO:tensorflow:loss = 283.15338, step = 10101 (3.652 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.452\n",
            "INFO:tensorflow:loss = 269.52875, step = 10201 (3.638 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5381\n",
            "INFO:tensorflow:loss = 271.52292, step = 10301 (3.630 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9005\n",
            "INFO:tensorflow:loss = 283.03943, step = 10401 (3.584 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5666\n",
            "INFO:tensorflow:loss = 277.2987, step = 10501 (3.632 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6818\n",
            "INFO:tensorflow:loss = 293.76456, step = 10601 (3.608 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6653\n",
            "INFO:tensorflow:loss = 292.88608, step = 10701 (3.617 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4528\n",
            "INFO:tensorflow:loss = 282.13184, step = 10801 (3.647 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7472\n",
            "INFO:tensorflow:loss = 270.55716, step = 10901 (3.597 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.2189\n",
            "INFO:tensorflow:loss = 292.7977, step = 11001 (3.547 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5746\n",
            "INFO:tensorflow:loss = 259.22433, step = 11101 (3.626 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.784\n",
            "INFO:tensorflow:loss = 289.29205, step = 11201 (3.599 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7849\n",
            "INFO:tensorflow:loss = 298.07312, step = 11301 (3.599 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5862\n",
            "INFO:tensorflow:loss = 270.82477, step = 11401 (3.624 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7152\n",
            "INFO:tensorflow:loss = 260.21225, step = 11501 (3.606 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7578\n",
            "INFO:tensorflow:loss = 293.85095, step = 11601 (3.603 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8072\n",
            "INFO:tensorflow:loss = 259.65552, step = 11701 (3.596 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7534\n",
            "INFO:tensorflow:loss = 292.0556, step = 11801 (3.603 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4351\n",
            "INFO:tensorflow:loss = 277.99637, step = 11901 (3.645 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5509\n",
            "INFO:tensorflow:loss = 299.5626, step = 12001 (3.629 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8186\n",
            "INFO:tensorflow:loss = 263.16016, step = 12101 (3.595 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6276\n",
            "INFO:tensorflow:loss = 282.97925, step = 12201 (3.623 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7536\n",
            "INFO:tensorflow:loss = 276.17804, step = 12301 (3.600 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9031\n",
            "INFO:tensorflow:loss = 293.3961, step = 12401 (3.584 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5495\n",
            "INFO:tensorflow:loss = 305.81836, step = 12501 (3.629 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8422\n",
            "INFO:tensorflow:loss = 267.1199, step = 12601 (3.592 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9148\n",
            "INFO:tensorflow:loss = 316.60007, step = 12701 (3.582 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4739\n",
            "INFO:tensorflow:loss = 284.16504, step = 12801 (3.640 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6784\n",
            "INFO:tensorflow:loss = 292.97757, step = 12901 (3.615 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7823\n",
            "INFO:tensorflow:loss = 255.53352, step = 13001 (3.598 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9658\n",
            "INFO:tensorflow:loss = 273.24155, step = 13101 (3.575 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9862\n",
            "INFO:tensorflow:loss = 266.812, step = 13201 (3.574 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.1302\n",
            "INFO:tensorflow:loss = 303.58347, step = 13301 (3.558 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4075\n",
            "INFO:tensorflow:loss = 283.5399, step = 13401 (3.645 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.1502\n",
            "INFO:tensorflow:loss = 289.20212, step = 13501 (3.556 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8295\n",
            "INFO:tensorflow:loss = 280.40936, step = 13601 (3.591 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0374\n",
            "INFO:tensorflow:loss = 280.16025, step = 13701 (3.565 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.3139\n",
            "INFO:tensorflow:loss = 318.04944, step = 13801 (3.532 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0276\n",
            "INFO:tensorflow:loss = 266.47925, step = 13901 (3.568 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.219\n",
            "INFO:tensorflow:loss = 299.07556, step = 14001 (3.544 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.1892\n",
            "INFO:tensorflow:loss = 282.41382, step = 14101 (3.549 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9627\n",
            "INFO:tensorflow:loss = 290.68048, step = 14201 (3.578 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.57\n",
            "INFO:tensorflow:loss = 284.75845, step = 14301 (3.497 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.3427\n",
            "INFO:tensorflow:loss = 273.41776, step = 14401 (3.528 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9785\n",
            "INFO:tensorflow:loss = 271.80002, step = 14501 (3.573 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0838\n",
            "INFO:tensorflow:loss = 274.86795, step = 14601 (3.562 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.2877\n",
            "INFO:tensorflow:loss = 175.22235, step = 14701 (3.534 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8388\n",
            "INFO:tensorflow:loss = 311.00034, step = 14801 (3.596 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.139\n",
            "INFO:tensorflow:loss = 278.1523, step = 14901 (3.550 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.2655\n",
            "INFO:tensorflow:loss = 266.40552, step = 15001 (3.537 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8357\n",
            "INFO:tensorflow:loss = 283.85135, step = 15101 (3.596 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0726\n",
            "INFO:tensorflow:loss = 274.36295, step = 15201 (3.559 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2026\n",
            "INFO:tensorflow:loss = 261.0592, step = 15301 (3.675 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.0107\n",
            "INFO:tensorflow:loss = 298.30878, step = 15401 (3.704 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4479\n",
            "INFO:tensorflow:loss = 298.27197, step = 15501 (3.642 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4453\n",
            "INFO:tensorflow:loss = 295.95447, step = 15601 (3.647 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.0095\n",
            "INFO:tensorflow:loss = 256.05548, step = 15701 (3.700 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.297\n",
            "INFO:tensorflow:loss = 291.50604, step = 15801 (3.667 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2146\n",
            "INFO:tensorflow:loss = 278.12924, step = 15901 (3.670 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6496\n",
            "INFO:tensorflow:loss = 256.38138, step = 16001 (3.618 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5476\n",
            "INFO:tensorflow:loss = 267.28897, step = 16101 (3.631 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1707\n",
            "INFO:tensorflow:loss = 255.14734, step = 16201 (3.679 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2998\n",
            "INFO:tensorflow:loss = 275.14502, step = 16301 (3.666 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.498\n",
            "INFO:tensorflow:loss = 267.74268, step = 16401 (3.634 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.0818\n",
            "INFO:tensorflow:loss = 272.13385, step = 16501 (3.693 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 16533 into /tmp/tmpqv_i4zmv/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 24.4024\n",
            "INFO:tensorflow:loss = 309.79095, step = 16601 (4.098 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.183\n",
            "INFO:tensorflow:loss = 272.4474, step = 16701 (3.684 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2127\n",
            "INFO:tensorflow:loss = 274.98682, step = 16801 (3.670 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3485\n",
            "INFO:tensorflow:loss = 303.47687, step = 16901 (3.659 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1059\n",
            "INFO:tensorflow:loss = 294.3276, step = 17001 (3.687 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.287\n",
            "INFO:tensorflow:loss = 284.3829, step = 17101 (3.666 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.267\n",
            "INFO:tensorflow:loss = 268.13507, step = 17201 (3.667 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.8114\n",
            "INFO:tensorflow:loss = 283.0459, step = 17301 (3.727 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2183\n",
            "INFO:tensorflow:loss = 246.3248, step = 17401 (3.674 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3091\n",
            "INFO:tensorflow:loss = 265.5426, step = 17501 (3.663 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6522\n",
            "INFO:tensorflow:loss = 294.56525, step = 17601 (3.615 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5018\n",
            "INFO:tensorflow:loss = 281.4071, step = 17701 (3.636 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4735\n",
            "INFO:tensorflow:loss = 280.75952, step = 17801 (3.640 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1099\n",
            "INFO:tensorflow:loss = 270.60962, step = 17901 (3.689 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5688\n",
            "INFO:tensorflow:loss = 300.20447, step = 18001 (3.627 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5263\n",
            "INFO:tensorflow:loss = 292.16296, step = 18101 (3.633 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.0638\n",
            "INFO:tensorflow:loss = 280.69058, step = 18201 (3.695 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3032\n",
            "INFO:tensorflow:loss = 266.46997, step = 18301 (3.663 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3548\n",
            "INFO:tensorflow:loss = 275.61203, step = 18401 (3.659 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2674\n",
            "INFO:tensorflow:loss = 279.05762, step = 18501 (3.663 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3721\n",
            "INFO:tensorflow:loss = 294.59537, step = 18601 (3.654 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5006\n",
            "INFO:tensorflow:loss = 272.19623, step = 18701 (3.637 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4782\n",
            "INFO:tensorflow:loss = 278.29538, step = 18801 (3.638 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4058\n",
            "INFO:tensorflow:loss = 271.37613, step = 18901 (3.649 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2532\n",
            "INFO:tensorflow:loss = 289.73016, step = 19001 (3.669 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.5422\n",
            "INFO:tensorflow:loss = 288.05286, step = 19101 (3.504 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6591\n",
            "INFO:tensorflow:loss = 283.03015, step = 19201 (3.615 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7857\n",
            "INFO:tensorflow:loss = 265.3069, step = 19301 (3.600 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8911\n",
            "INFO:tensorflow:loss = 283.9521, step = 19401 (3.585 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0334\n",
            "INFO:tensorflow:loss = 295.56644, step = 19501 (3.567 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8586\n",
            "INFO:tensorflow:loss = 243.89462, step = 19601 (3.590 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.1295\n",
            "INFO:tensorflow:loss = 282.87457, step = 19701 (3.555 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.1732\n",
            "INFO:tensorflow:loss = 284.1104, step = 19801 (3.549 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7807\n",
            "INFO:tensorflow:loss = 272.64417, step = 19901 (3.600 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9323\n",
            "INFO:tensorflow:loss = 284.97552, step = 20001 (3.580 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8559\n",
            "INFO:tensorflow:loss = 264.66455, step = 20101 (3.592 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3825\n",
            "INFO:tensorflow:loss = 288.828, step = 20201 (3.650 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7918\n",
            "INFO:tensorflow:loss = 277.27484, step = 20301 (3.598 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8136\n",
            "INFO:tensorflow:loss = 287.1753, step = 20401 (3.596 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9418\n",
            "INFO:tensorflow:loss = 256.8413, step = 20501 (3.579 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0691\n",
            "INFO:tensorflow:loss = 257.24796, step = 20601 (3.562 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9405\n",
            "INFO:tensorflow:loss = 271.23114, step = 20701 (3.580 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.109\n",
            "INFO:tensorflow:loss = 288.57074, step = 20801 (3.558 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9092\n",
            "INFO:tensorflow:loss = 297.31027, step = 20901 (3.583 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.5432\n",
            "INFO:tensorflow:loss = 300.80524, step = 21001 (3.506 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6857\n",
            "INFO:tensorflow:loss = 299.39728, step = 21101 (3.609 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0659\n",
            "INFO:tensorflow:loss = 249.63986, step = 21201 (3.563 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0529\n",
            "INFO:tensorflow:loss = 286.5101, step = 21301 (3.564 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0278\n",
            "INFO:tensorflow:loss = 283.03876, step = 21401 (3.568 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.4042\n",
            "INFO:tensorflow:loss = 289.71832, step = 21501 (3.520 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.111\n",
            "INFO:tensorflow:loss = 298.7213, step = 21601 (3.558 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.2892\n",
            "INFO:tensorflow:loss = 279.9131, step = 21701 (3.534 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.3605\n",
            "INFO:tensorflow:loss = 283.06744, step = 21801 (3.527 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0755\n",
            "INFO:tensorflow:loss = 297.65115, step = 21901 (3.562 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.2929\n",
            "INFO:tensorflow:loss = 263.12927, step = 22001 (3.534 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.5065\n",
            "INFO:tensorflow:loss = 287.60397, step = 22101 (3.509 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.3939\n",
            "INFO:tensorflow:loss = 286.5884, step = 22201 (3.523 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4572\n",
            "INFO:tensorflow:loss = 310.13354, step = 22301 (3.640 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1617\n",
            "INFO:tensorflow:loss = 282.6961, step = 22401 (3.682 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8335\n",
            "INFO:tensorflow:loss = 266.31943, step = 22501 (3.596 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8724\n",
            "INFO:tensorflow:loss = 255.06923, step = 22601 (3.588 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.817\n",
            "INFO:tensorflow:loss = 295.32874, step = 22701 (3.594 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1334\n",
            "INFO:tensorflow:loss = 278.03705, step = 22801 (3.683 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7813\n",
            "INFO:tensorflow:loss = 306.53003, step = 22901 (3.602 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.4804\n",
            "INFO:tensorflow:loss = 287.90512, step = 23001 (3.508 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.6352\n",
            "INFO:tensorflow:loss = 271.607, step = 23101 (3.492 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.6758\n",
            "INFO:tensorflow:loss = 277.224, step = 23201 (3.488 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.3068\n",
            "INFO:tensorflow:loss = 271.13312, step = 23301 (3.532 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.445\n",
            "INFO:tensorflow:loss = 308.95068, step = 23401 (3.518 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.1398\n",
            "INFO:tensorflow:loss = 270.8158, step = 23501 (3.551 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6134\n",
            "INFO:tensorflow:loss = 277.0201, step = 23601 (3.621 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4466\n",
            "INFO:tensorflow:loss = 279.8603, step = 23701 (3.643 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6462\n",
            "INFO:tensorflow:loss = 262.1877, step = 23801 (3.618 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6262\n",
            "INFO:tensorflow:loss = 283.88544, step = 23901 (3.620 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6106\n",
            "INFO:tensorflow:loss = 281.6997, step = 24001 (3.621 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6007\n",
            "INFO:tensorflow:loss = 280.70258, step = 24101 (3.626 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.671\n",
            "INFO:tensorflow:loss = 259.7853, step = 24201 (3.611 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0486\n",
            "INFO:tensorflow:loss = 282.41428, step = 24301 (3.569 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9033\n",
            "INFO:tensorflow:loss = 264.88287, step = 24401 (3.581 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6192\n",
            "INFO:tensorflow:loss = 265.06244, step = 24501 (3.619 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6286\n",
            "INFO:tensorflow:loss = 304.67615, step = 24601 (3.620 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5486\n",
            "INFO:tensorflow:loss = 301.35092, step = 24701 (3.629 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.634\n",
            "INFO:tensorflow:loss = 284.69788, step = 24801 (3.618 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8426\n",
            "INFO:tensorflow:loss = 293.49112, step = 24901 (3.593 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6833\n",
            "INFO:tensorflow:loss = 282.31433, step = 25001 (3.617 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7146\n",
            "INFO:tensorflow:loss = 249.88173, step = 25101 (3.603 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.9955\n",
            "INFO:tensorflow:loss = 275.4427, step = 25201 (3.705 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.7307\n",
            "INFO:tensorflow:loss = 279.24493, step = 25301 (3.740 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2773\n",
            "INFO:tensorflow:loss = 306.94388, step = 25401 (3.666 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7084\n",
            "INFO:tensorflow:loss = 304.6308, step = 25501 (3.610 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8003\n",
            "INFO:tensorflow:loss = 265.93002, step = 25601 (3.597 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8752\n",
            "INFO:tensorflow:loss = 248.85663, step = 25701 (3.587 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3697\n",
            "INFO:tensorflow:loss = 257.97137, step = 25801 (3.654 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6711\n",
            "INFO:tensorflow:loss = 264.63852, step = 25901 (3.614 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8743\n",
            "INFO:tensorflow:loss = 302.82083, step = 26001 (3.588 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3976\n",
            "INFO:tensorflow:loss = 257.18085, step = 26101 (3.652 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8121\n",
            "INFO:tensorflow:loss = 295.69223, step = 26201 (3.593 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7118\n",
            "INFO:tensorflow:loss = 294.5395, step = 26301 (3.608 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6372\n",
            "INFO:tensorflow:loss = 273.53564, step = 26401 (3.624 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4296\n",
            "INFO:tensorflow:loss = 248.47304, step = 26501 (3.642 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3755\n",
            "INFO:tensorflow:loss = 299.0412, step = 26601 (3.652 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1822\n",
            "INFO:tensorflow:loss = 304.80347, step = 26701 (3.681 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3206\n",
            "INFO:tensorflow:loss = 270.5309, step = 26801 (3.658 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2178\n",
            "INFO:tensorflow:loss = 272.04794, step = 26901 (3.674 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1501\n",
            "INFO:tensorflow:loss = 285.33145, step = 27001 (3.687 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3011\n",
            "INFO:tensorflow:loss = 272.81952, step = 27101 (3.663 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1805\n",
            "INFO:tensorflow:loss = 295.2626, step = 27201 (3.675 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.644\n",
            "INFO:tensorflow:loss = 273.3386, step = 27301 (3.617 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6068\n",
            "INFO:tensorflow:loss = 266.3853, step = 27401 (3.623 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.592\n",
            "INFO:tensorflow:loss = 290.01108, step = 27501 (3.623 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.109\n",
            "INFO:tensorflow:loss = 293.3196, step = 27601 (3.558 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.414\n",
            "INFO:tensorflow:loss = 257.0017, step = 27701 (3.648 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4599\n",
            "INFO:tensorflow:loss = 269.1012, step = 27801 (3.644 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7751\n",
            "INFO:tensorflow:loss = 272.28104, step = 27901 (3.598 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7943\n",
            "INFO:tensorflow:loss = 293.3084, step = 28001 (3.598 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5876\n",
            "INFO:tensorflow:loss = 292.4702, step = 28101 (3.626 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.3046\n",
            "INFO:tensorflow:loss = 290.5656, step = 28201 (3.532 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7028\n",
            "INFO:tensorflow:loss = 251.78336, step = 28301 (3.610 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6423\n",
            "INFO:tensorflow:loss = 286.60925, step = 28401 (3.618 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6665\n",
            "INFO:tensorflow:loss = 274.44263, step = 28501 (3.615 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5352\n",
            "INFO:tensorflow:loss = 301.38824, step = 28601 (3.632 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4344\n",
            "INFO:tensorflow:loss = 286.8548, step = 28701 (3.644 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.825\n",
            "INFO:tensorflow:loss = 275.78033, step = 28801 (3.595 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4992\n",
            "INFO:tensorflow:loss = 264.7591, step = 28901 (3.637 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5945\n",
            "INFO:tensorflow:loss = 256.2683, step = 29001 (3.623 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0318\n",
            "INFO:tensorflow:loss = 280.13232, step = 29101 (3.571 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5974\n",
            "INFO:tensorflow:loss = 274.03033, step = 29201 (3.623 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7777\n",
            "INFO:tensorflow:loss = 282.71085, step = 29301 (3.598 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7204\n",
            "INFO:tensorflow:loss = 283.018, step = 29401 (3.606 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6914\n",
            "INFO:tensorflow:loss = 255.24161, step = 29501 (3.613 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8013\n",
            "INFO:tensorflow:loss = 289.81213, step = 29601 (3.595 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.7401\n",
            "INFO:tensorflow:loss = 275.3746, step = 29701 (3.479 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0314\n",
            "INFO:tensorflow:loss = 275.09937, step = 29801 (3.567 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0417\n",
            "INFO:tensorflow:loss = 290.82843, step = 29901 (3.567 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0638\n",
            "INFO:tensorflow:loss = 287.08353, step = 30001 (3.563 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.1114\n",
            "INFO:tensorflow:loss = 267.5486, step = 30101 (3.557 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7365\n",
            "INFO:tensorflow:loss = 258.8816, step = 30201 (3.605 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.156\n",
            "INFO:tensorflow:loss = 265.93216, step = 30301 (3.683 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1894\n",
            "INFO:tensorflow:loss = 285.904, step = 30401 (3.679 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.401\n",
            "INFO:tensorflow:loss = 294.91437, step = 30501 (3.648 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6234\n",
            "INFO:tensorflow:loss = 288.46448, step = 30601 (3.624 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4002\n",
            "INFO:tensorflow:loss = 293.97244, step = 30701 (3.647 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2906\n",
            "INFO:tensorflow:loss = 259.5, step = 30801 (3.664 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.344\n",
            "INFO:tensorflow:loss = 266.98047, step = 30901 (3.656 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.425\n",
            "INFO:tensorflow:loss = 278.9037, step = 31001 (3.646 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7261\n",
            "INFO:tensorflow:loss = 286.22552, step = 31101 (3.607 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7692\n",
            "INFO:tensorflow:loss = 274.84082, step = 31201 (3.602 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7078\n",
            "INFO:tensorflow:loss = 296.19614, step = 31301 (3.609 sec)\n",
            "INFO:tensorflow:global_step/sec: 29.0438\n",
            "INFO:tensorflow:loss = 292.69223, step = 31401 (3.442 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0207\n",
            "INFO:tensorflow:loss = 294.49347, step = 31501 (3.569 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0701\n",
            "INFO:tensorflow:loss = 276.7891, step = 31601 (3.564 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.1809\n",
            "INFO:tensorflow:loss = 298.74637, step = 31701 (3.548 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6653\n",
            "INFO:tensorflow:loss = 271.39847, step = 31801 (3.614 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4309\n",
            "INFO:tensorflow:loss = 267.74963, step = 31901 (3.649 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.0152\n",
            "INFO:tensorflow:loss = 282.03693, step = 32001 (3.705 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.8153\n",
            "INFO:tensorflow:loss = 290.03357, step = 32101 (3.722 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4364\n",
            "INFO:tensorflow:loss = 262.42783, step = 32201 (3.645 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5075\n",
            "INFO:tensorflow:loss = 298.18246, step = 32301 (3.635 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.0065\n",
            "INFO:tensorflow:loss = 274.3803, step = 32401 (3.703 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3569\n",
            "INFO:tensorflow:loss = 309.30652, step = 32501 (3.655 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3328\n",
            "INFO:tensorflow:loss = 284.84836, step = 32601 (3.659 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5094\n",
            "INFO:tensorflow:loss = 285.75345, step = 32701 (3.636 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3725\n",
            "INFO:tensorflow:loss = 271.57388, step = 32801 (3.658 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1556\n",
            "INFO:tensorflow:loss = 255.1543, step = 32901 (3.678 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.59\n",
            "INFO:tensorflow:loss = 295.03033, step = 33001 (3.627 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5302\n",
            "INFO:tensorflow:loss = 276.35666, step = 33101 (3.633 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 33125 into /tmp/tmpqv_i4zmv/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 24.5683\n",
            "INFO:tensorflow:loss = 269.3918, step = 33201 (4.066 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.442\n",
            "INFO:tensorflow:loss = 273.5622, step = 33301 (3.644 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.467\n",
            "INFO:tensorflow:loss = 281.0544, step = 33401 (3.641 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.9118\n",
            "INFO:tensorflow:loss = 288.56714, step = 33501 (3.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.0139\n",
            "INFO:tensorflow:loss = 276.51334, step = 33601 (3.699 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.9805\n",
            "INFO:tensorflow:loss = 297.75055, step = 33701 (3.705 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.9727\n",
            "INFO:tensorflow:loss = 283.39594, step = 33801 (3.708 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.8711\n",
            "INFO:tensorflow:loss = 274.7982, step = 33901 (3.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1811\n",
            "INFO:tensorflow:loss = 285.95728, step = 34001 (3.681 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6049\n",
            "INFO:tensorflow:loss = 293.21875, step = 34101 (3.621 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3902\n",
            "INFO:tensorflow:loss = 278.83536, step = 34201 (3.651 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3452\n",
            "INFO:tensorflow:loss = 247.15184, step = 34301 (3.658 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7251\n",
            "INFO:tensorflow:loss = 271.57092, step = 34401 (3.609 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9101\n",
            "INFO:tensorflow:loss = 294.40356, step = 34501 (3.579 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.8328\n",
            "INFO:tensorflow:loss = 286.483, step = 34601 (3.728 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9368\n",
            "INFO:tensorflow:loss = 272.42188, step = 34701 (3.579 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0187\n",
            "INFO:tensorflow:loss = 285.85995, step = 34801 (3.574 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6939\n",
            "INFO:tensorflow:loss = 272.19934, step = 34901 (3.606 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8407\n",
            "INFO:tensorflow:loss = 272.99298, step = 35001 (3.592 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2931\n",
            "INFO:tensorflow:loss = 256.24503, step = 35101 (3.664 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3925\n",
            "INFO:tensorflow:loss = 279.51065, step = 35201 (3.650 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6941\n",
            "INFO:tensorflow:loss = 293.39227, step = 35301 (3.611 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6355\n",
            "INFO:tensorflow:loss = 273.33838, step = 35401 (3.622 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0551\n",
            "INFO:tensorflow:loss = 266.64105, step = 35501 (3.563 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.2023\n",
            "INFO:tensorflow:loss = 273.35822, step = 35601 (3.547 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6163\n",
            "INFO:tensorflow:loss = 306.06848, step = 35701 (3.617 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2101\n",
            "INFO:tensorflow:loss = 237.3992, step = 35801 (3.676 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2878\n",
            "INFO:tensorflow:loss = 282.6672, step = 35901 (3.664 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1995\n",
            "INFO:tensorflow:loss = 285.689, step = 36001 (3.676 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.0377\n",
            "INFO:tensorflow:loss = 310.3064, step = 36101 (3.698 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9109\n",
            "INFO:tensorflow:loss = 271.43396, step = 36201 (3.583 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6077\n",
            "INFO:tensorflow:loss = 280.23117, step = 36301 (3.622 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9308\n",
            "INFO:tensorflow:loss = 275.7303, step = 36401 (3.581 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4693\n",
            "INFO:tensorflow:loss = 288.28784, step = 36501 (3.641 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5465\n",
            "INFO:tensorflow:loss = 290.22296, step = 36601 (3.630 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7579\n",
            "INFO:tensorflow:loss = 254.96347, step = 36701 (3.603 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.9964\n",
            "INFO:tensorflow:loss = 310.87976, step = 36801 (3.704 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4848\n",
            "INFO:tensorflow:loss = 304.17844, step = 36901 (3.638 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3\n",
            "INFO:tensorflow:loss = 274.31677, step = 37001 (3.667 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4855\n",
            "INFO:tensorflow:loss = 288.18365, step = 37101 (3.634 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6457\n",
            "INFO:tensorflow:loss = 271.72278, step = 37201 (3.618 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9526\n",
            "INFO:tensorflow:loss = 271.2583, step = 37301 (3.578 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6829\n",
            "INFO:tensorflow:loss = 286.2313, step = 37401 (3.612 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6865\n",
            "INFO:tensorflow:loss = 254.182, step = 37501 (3.611 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9088\n",
            "INFO:tensorflow:loss = 287.65634, step = 37601 (3.584 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6143\n",
            "INFO:tensorflow:loss = 258.34772, step = 37701 (3.620 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8863\n",
            "INFO:tensorflow:loss = 269.86298, step = 37801 (3.586 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.3002\n",
            "INFO:tensorflow:loss = 275.4709, step = 37901 (3.534 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9918\n",
            "INFO:tensorflow:loss = 294.04596, step = 38001 (3.572 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0387\n",
            "INFO:tensorflow:loss = 291.1435, step = 38101 (3.567 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.3014\n",
            "INFO:tensorflow:loss = 296.3913, step = 38201 (3.533 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0568\n",
            "INFO:tensorflow:loss = 304.18512, step = 38301 (3.566 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0063\n",
            "INFO:tensorflow:loss = 243.70868, step = 38401 (3.569 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.86\n",
            "INFO:tensorflow:loss = 271.1388, step = 38501 (3.590 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0309\n",
            "INFO:tensorflow:loss = 266.12106, step = 38601 (3.567 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9983\n",
            "INFO:tensorflow:loss = 291.97168, step = 38701 (3.572 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.064\n",
            "INFO:tensorflow:loss = 153.53722, step = 38801 (3.563 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.2014\n",
            "INFO:tensorflow:loss = 276.4283, step = 38901 (3.552 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.8505\n",
            "INFO:tensorflow:loss = 300.2638, step = 39001 (3.460 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8482\n",
            "INFO:tensorflow:loss = 274.49545, step = 39101 (3.592 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.3324\n",
            "INFO:tensorflow:loss = 269.49988, step = 39201 (3.529 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.2655\n",
            "INFO:tensorflow:loss = 262.9419, step = 39301 (3.538 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7909\n",
            "INFO:tensorflow:loss = 260.60815, step = 39401 (3.598 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.5111\n",
            "INFO:tensorflow:loss = 260.6386, step = 39501 (3.513 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.8156\n",
            "INFO:tensorflow:loss = 298.00635, step = 39601 (3.467 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.2129\n",
            "INFO:tensorflow:loss = 284.23538, step = 39701 (3.544 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.4411\n",
            "INFO:tensorflow:loss = 281.909, step = 39801 (3.518 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.4536\n",
            "INFO:tensorflow:loss = 302.6756, step = 39901 (3.511 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.1154\n",
            "INFO:tensorflow:loss = 279.47925, step = 40001 (3.556 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8281\n",
            "INFO:tensorflow:loss = 317.83508, step = 40101 (3.597 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4602\n",
            "INFO:tensorflow:loss = 285.75, step = 40201 (3.639 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2377\n",
            "INFO:tensorflow:loss = 271.95398, step = 40301 (3.670 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4239\n",
            "INFO:tensorflow:loss = 249.86673, step = 40401 (3.646 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7271\n",
            "INFO:tensorflow:loss = 288.67645, step = 40501 (3.607 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3744\n",
            "INFO:tensorflow:loss = 290.6455, step = 40601 (3.653 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4532\n",
            "INFO:tensorflow:loss = 290.86182, step = 40701 (3.642 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1892\n",
            "INFO:tensorflow:loss = 300.2685, step = 40801 (3.680 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.511\n",
            "INFO:tensorflow:loss = 301.21875, step = 40901 (3.636 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6765\n",
            "INFO:tensorflow:loss = 307.7319, step = 41001 (3.610 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2592\n",
            "INFO:tensorflow:loss = 280.8114, step = 41101 (3.669 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4658\n",
            "INFO:tensorflow:loss = 283.89752, step = 41201 (3.643 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4448\n",
            "INFO:tensorflow:loss = 266.2719, step = 41301 (3.645 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2177\n",
            "INFO:tensorflow:loss = 268.29852, step = 41401 (3.670 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6822\n",
            "INFO:tensorflow:loss = 232.98485, step = 41501 (3.612 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6408\n",
            "INFO:tensorflow:loss = 255.94635, step = 41601 (3.622 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5346\n",
            "INFO:tensorflow:loss = 283.07578, step = 41701 (3.628 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1853\n",
            "INFO:tensorflow:loss = 277.2738, step = 41801 (3.683 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2468\n",
            "INFO:tensorflow:loss = 254.4852, step = 41901 (3.667 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.231\n",
            "INFO:tensorflow:loss = 287.72073, step = 42001 (3.671 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6213\n",
            "INFO:tensorflow:loss = 304.51053, step = 42101 (3.621 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5331\n",
            "INFO:tensorflow:loss = 282.7767, step = 42201 (3.637 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5859\n",
            "INFO:tensorflow:loss = 281.4793, step = 42301 (3.619 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1971\n",
            "INFO:tensorflow:loss = 296.49225, step = 42401 (3.682 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.6644\n",
            "INFO:tensorflow:loss = 264.15878, step = 42501 (3.746 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4561\n",
            "INFO:tensorflow:loss = 268.2295, step = 42601 (3.642 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6307\n",
            "INFO:tensorflow:loss = 271.9983, step = 42701 (3.618 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1698\n",
            "INFO:tensorflow:loss = 298.44528, step = 42801 (3.682 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8991\n",
            "INFO:tensorflow:loss = 282.4531, step = 42901 (3.583 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6557\n",
            "INFO:tensorflow:loss = 264.3301, step = 43001 (3.617 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2697\n",
            "INFO:tensorflow:loss = 282.99805, step = 43101 (3.666 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4221\n",
            "INFO:tensorflow:loss = 297.46454, step = 43201 (3.650 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7019\n",
            "INFO:tensorflow:loss = 291.86456, step = 43301 (3.606 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4765\n",
            "INFO:tensorflow:loss = 264.55066, step = 43401 (3.641 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.2111\n",
            "INFO:tensorflow:loss = 310.58353, step = 43501 (3.674 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.1559\n",
            "INFO:tensorflow:loss = 291.7433, step = 43601 (3.687 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8161\n",
            "INFO:tensorflow:loss = 244.45975, step = 43701 (3.590 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7586\n",
            "INFO:tensorflow:loss = 274.91788, step = 43801 (3.602 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6669\n",
            "INFO:tensorflow:loss = 244.23952, step = 43901 (3.615 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9027\n",
            "INFO:tensorflow:loss = 283.10547, step = 44001 (3.584 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8244\n",
            "INFO:tensorflow:loss = 291.65808, step = 44101 (3.594 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6307\n",
            "INFO:tensorflow:loss = 283.96844, step = 44201 (3.619 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6112\n",
            "INFO:tensorflow:loss = 262.649, step = 44301 (3.622 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7701\n",
            "INFO:tensorflow:loss = 287.52838, step = 44401 (3.603 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5405\n",
            "INFO:tensorflow:loss = 271.0119, step = 44501 (3.629 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7602\n",
            "INFO:tensorflow:loss = 295.55518, step = 44601 (3.602 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0344\n",
            "INFO:tensorflow:loss = 275.38635, step = 44701 (3.571 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6554\n",
            "INFO:tensorflow:loss = 268.645, step = 44801 (3.616 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.662\n",
            "INFO:tensorflow:loss = 237.2062, step = 44901 (3.611 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6503\n",
            "INFO:tensorflow:loss = 287.47833, step = 45001 (3.620 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4286\n",
            "INFO:tensorflow:loss = 267.97284, step = 45101 (3.642 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4542\n",
            "INFO:tensorflow:loss = 275.76782, step = 45201 (3.643 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.5546\n",
            "INFO:tensorflow:loss = 276.11597, step = 45301 (3.635 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9987\n",
            "INFO:tensorflow:loss = 266.4972, step = 45401 (3.572 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8677\n",
            "INFO:tensorflow:loss = 292.83902, step = 45501 (3.583 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8079\n",
            "INFO:tensorflow:loss = 288.29877, step = 45601 (3.596 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8378\n",
            "INFO:tensorflow:loss = 305.6891, step = 45701 (3.594 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9977\n",
            "INFO:tensorflow:loss = 301.34796, step = 45801 (3.569 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.6015\n",
            "INFO:tensorflow:loss = 273.46246, step = 45901 (3.624 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.8266\n",
            "INFO:tensorflow:loss = 290.7054, step = 46001 (3.593 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7646\n",
            "INFO:tensorflow:loss = 287.17844, step = 46101 (3.603 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.3728\n",
            "INFO:tensorflow:loss = 312.49112, step = 46201 (3.653 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0227\n",
            "INFO:tensorflow:loss = 291.99146, step = 46301 (3.568 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9353\n",
            "INFO:tensorflow:loss = 285.96817, step = 46401 (3.580 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.5868\n",
            "INFO:tensorflow:loss = 269.2192, step = 46501 (3.498 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.256\n",
            "INFO:tensorflow:loss = 282.15622, step = 46601 (3.539 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.101\n",
            "INFO:tensorflow:loss = 266.97504, step = 46701 (3.564 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.7872\n",
            "INFO:tensorflow:loss = 254.76016, step = 46801 (3.595 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9081\n",
            "INFO:tensorflow:loss = 277.61142, step = 46901 (3.586 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.824\n",
            "INFO:tensorflow:loss = 312.57413, step = 47001 (3.589 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0424\n",
            "INFO:tensorflow:loss = 280.86084, step = 47101 (3.566 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.3724\n",
            "INFO:tensorflow:loss = 286.52542, step = 47201 (3.525 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.2536\n",
            "INFO:tensorflow:loss = 299.35303, step = 47301 (3.539 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.3629\n",
            "INFO:tensorflow:loss = 308.01874, step = 47401 (3.526 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.869\n",
            "INFO:tensorflow:loss = 282.9463, step = 47501 (3.464 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9016\n",
            "INFO:tensorflow:loss = 277.80615, step = 47601 (3.588 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.0963\n",
            "INFO:tensorflow:loss = 275.8935, step = 47701 (3.555 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.1453\n",
            "INFO:tensorflow:loss = 293.4322, step = 47801 (3.553 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9678\n",
            "INFO:tensorflow:loss = 292.6289, step = 47901 (3.576 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.4576\n",
            "INFO:tensorflow:loss = 276.2494, step = 48001 (3.514 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.2882\n",
            "INFO:tensorflow:loss = 292.90897, step = 48101 (3.535 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 48200 into /tmp/tmpqv_i4zmv/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 187.58392.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-11-21T06:29:56Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpqv_i4zmv/model.ckpt-48200\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-11-21-06:29:58\n",
            "INFO:tensorflow:Saving dict for global step 48200: accuracy = 0.7604116, average_loss = 0.653688, global_step = 48200, loss = 330.13388\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 48200: /tmp/tmpqv_i4zmv/model.ckpt-48200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ALfIZEaF31b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f8c7ee7e-c2aa-4c26-f79f-c70992af9e55"
      },
      "source": [
        "#evaluate the data based on the trained model\n",
        "eval_test_fn = make_input_fn(test, num_epochs=1, shuffle=False)\n",
        "result_test = linear_est.evaluate(eval_test_fn)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-11-21T06:30:23Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpqv_i4zmv/model.ckpt-48200\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-11-21-06:30:25\n",
            "INFO:tensorflow:Saving dict for global step 48200: accuracy = 0.76179594, average_loss = 0.6525427, global_step = 48200, loss = 330.6417\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 48200: /tmp/tmpqv_i4zmv/model.ckpt-48200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MUhYLU__Pw",
        "colab_type": "text"
      },
      "source": [
        "Execute the below steps for classifiying labels from features using **tensorflow keras API Sequential algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmxpwwYnOqON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  # Replace 'fit_one_hot' with 'fit' when using SparseCategoricalCrossentropy\n",
        "  labels = dataframe.pop('fit_one_hot')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  #shuffle if in trainig mode\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WuskEge6sK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#insert the feature column in the dense feature layers \n",
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qv9rarE6yJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create batch and execute the function for train dataset.\n",
        "batch_size = 512\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXt235nF6y4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using regularizer for better unbiased  prediction between training and validation data\n",
        "reg = 0.001\n",
        "model = tf.keras.Sequential([\n",
        "  feature_layer,\n",
        "  layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(reg)),\n",
        "  layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(reg)),\n",
        "\n",
        "  # layers.Dense(128, activation='relu'),\n",
        "  # layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(3, activation='softmax', name='predictions')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kI8xZQf66rX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use different metrics for understanding\n",
        "METRICS = [\n",
        "      tf.keras.metrics.TruePositives(name='tp'),\n",
        "      tf.keras.metrics.FalsePositives(name='fp'),\n",
        "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
        "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
        "      tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),\n",
        "      tf.keras.metrics.AUC(name='auc'),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apu1uW1k69Vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.compile(optimizer= tf.keras.optimizers.RMSprop(learning_rate=1e-4),  \n",
        "#               # Loss function to minimize\n",
        "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "#               # List of metrics to monitor\n",
        "#               metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__dr3k5dS4rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile model by adding optimser,loss and metrices\n",
        "›model.compile(optimizer= tf.keras.optimizers.RMSprop(learning_rate=1e-4),  \n",
        "              loss= tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics= METRICS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxAQ1raP7GOY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "202546c4-c5c3-407f-db53-3a2d370d7a5a"
      },
      "source": [
        " #insert training and validation data for model training\n",
        " history = model.fit(train_ds,\n",
        "            validation_data=val_ds,\n",
        "            epochs=200)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "241/241 [==============================] - 19s 80ms/step - loss: 0.8286 - tp: 85229.0000 - fp: 31417.0000 - tn: 215039.0000 - fn: 37999.0000 - accuracy: 0.7144 - precision: 0.7307 - recall: 0.6916 - auc: 0.8244 - val_loss: 0.0000e+00 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0000e+00\n",
            "Epoch 2/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7655 - tp: 90827.0000 - fp: 32359.0000 - tn: 214097.0000 - fn: 32401.0000 - accuracy: 0.7373 - precision: 0.7373 - recall: 0.7371 - auc: 0.8474 - val_loss: 0.7559 - val_tp: 22772.0000 - val_fp: 8030.0000 - val_tn: 53584.0000 - val_fn: 8035.0000 - val_accuracy: 0.7393 - val_precision: 0.7393 - val_recall: 0.7392 - val_auc: 0.8543\n",
            "Epoch 3/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.7541 - tp: 90813.0000 - fp: 32347.0000 - tn: 214109.0000 - fn: 32415.0000 - accuracy: 0.7372 - precision: 0.7374 - recall: 0.7370 - auc: 0.8531 - val_loss: 0.7466 - val_tp: 22769.0000 - val_fp: 8027.0000 - val_tn: 53587.0000 - val_fn: 8038.0000 - val_accuracy: 0.7393 - val_precision: 0.7393 - val_recall: 0.7391 - val_auc: 0.8571\n",
            "Epoch 4/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.7448 - tp: 90742.0000 - fp: 32206.0000 - tn: 214250.0000 - fn: 32486.0000 - accuracy: 0.7372 - precision: 0.7381 - recall: 0.7364 - auc: 0.8570 - val_loss: 0.7383 - val_tp: 22752.0000 - val_fp: 7977.0000 - val_tn: 53637.0000 - val_fn: 8055.0000 - val_accuracy: 0.7393 - val_precision: 0.7404 - val_recall: 0.7385 - val_auc: 0.8603\n",
            "Epoch 5/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.7371 - tp: 90599.0000 - fp: 31854.0000 - tn: 214602.0000 - fn: 32629.0000 - accuracy: 0.7373 - precision: 0.7399 - recall: 0.7352 - auc: 0.8598 - val_loss: 0.7321 - val_tp: 22728.0000 - val_fp: 7895.0000 - val_tn: 53719.0000 - val_fn: 8079.0000 - val_accuracy: 0.7393 - val_precision: 0.7422 - val_recall: 0.7378 - val_auc: 0.8620\n",
            "Epoch 6/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.7312 - tp: 90403.0000 - fp: 31461.0000 - tn: 214995.0000 - fn: 32825.0000 - accuracy: 0.7373 - precision: 0.7418 - recall: 0.7336 - auc: 0.8613 - val_loss: 0.7274 - val_tp: 22686.0000 - val_fp: 7833.0000 - val_tn: 53781.0000 - val_fn: 8121.0000 - val_accuracy: 0.7395 - val_precision: 0.7433 - val_recall: 0.7364 - val_auc: 0.8631\n",
            "Epoch 7/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.7267 - tp: 90215.0000 - fp: 31072.0000 - tn: 215384.0000 - fn: 33013.0000 - accuracy: 0.7376 - precision: 0.7438 - recall: 0.7321 - auc: 0.8623 - val_loss: 0.7238 - val_tp: 22625.0000 - val_fp: 7743.0000 - val_tn: 53871.0000 - val_fn: 8182.0000 - val_accuracy: 0.7397 - val_precision: 0.7450 - val_recall: 0.7344 - val_auc: 0.8636\n",
            "Epoch 8/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.7231 - tp: 90010.0000 - fp: 30768.0000 - tn: 215688.0000 - fn: 33218.0000 - accuracy: 0.7379 - precision: 0.7453 - recall: 0.7304 - auc: 0.8632 - val_loss: 0.7209 - val_tp: 22586.0000 - val_fp: 7664.0000 - val_tn: 53950.0000 - val_fn: 8221.0000 - val_accuracy: 0.7403 - val_precision: 0.7466 - val_recall: 0.7331 - val_auc: 0.8643\n",
            "Epoch 9/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.7204 - tp: 89877.0000 - fp: 30563.0000 - tn: 215893.0000 - fn: 33351.0000 - accuracy: 0.7382 - precision: 0.7462 - recall: 0.7294 - auc: 0.8638 - val_loss: 0.7188 - val_tp: 22574.0000 - val_fp: 7644.0000 - val_tn: 53970.0000 - val_fn: 8233.0000 - val_accuracy: 0.7408 - val_precision: 0.7470 - val_recall: 0.7328 - val_auc: 0.8648\n",
            "Epoch 10/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.7183 - tp: 89775.0000 - fp: 30427.0000 - tn: 216029.0000 - fn: 33453.0000 - accuracy: 0.7384 - precision: 0.7469 - recall: 0.7285 - auc: 0.8643 - val_loss: 0.7171 - val_tp: 22565.0000 - val_fp: 7624.0000 - val_tn: 53990.0000 - val_fn: 8242.0000 - val_accuracy: 0.7409 - val_precision: 0.7475 - val_recall: 0.7325 - val_auc: 0.8652\n",
            "Epoch 11/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7167 - tp: 89642.0000 - fp: 30250.0000 - tn: 216206.0000 - fn: 33586.0000 - accuracy: 0.7387 - precision: 0.7477 - recall: 0.7274 - auc: 0.8648 - val_loss: 0.7157 - val_tp: 22556.0000 - val_fp: 7594.0000 - val_tn: 54020.0000 - val_fn: 8251.0000 - val_accuracy: 0.7409 - val_precision: 0.7481 - val_recall: 0.7322 - val_auc: 0.8655\n",
            "Epoch 12/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7154 - tp: 89488.0000 - fp: 30041.0000 - tn: 216415.0000 - fn: 33740.0000 - accuracy: 0.7389 - precision: 0.7487 - recall: 0.7262 - auc: 0.8652 - val_loss: 0.7147 - val_tp: 22547.0000 - val_fp: 7578.0000 - val_tn: 54036.0000 - val_fn: 8260.0000 - val_accuracy: 0.7409 - val_precision: 0.7484 - val_recall: 0.7319 - val_auc: 0.8658\n",
            "Epoch 13/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7144 - tp: 89395.0000 - fp: 29873.0000 - tn: 216583.0000 - fn: 33833.0000 - accuracy: 0.7389 - precision: 0.7495 - recall: 0.7254 - auc: 0.8655 - val_loss: 0.7138 - val_tp: 22532.0000 - val_fp: 7560.0000 - val_tn: 54054.0000 - val_fn: 8275.0000 - val_accuracy: 0.7410 - val_precision: 0.7488 - val_recall: 0.7314 - val_auc: 0.8661\n",
            "Epoch 14/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7136 - tp: 89280.0000 - fp: 29735.0000 - tn: 216721.0000 - fn: 33948.0000 - accuracy: 0.7391 - precision: 0.7502 - recall: 0.7245 - auc: 0.8658 - val_loss: 0.7132 - val_tp: 22521.0000 - val_fp: 7542.0000 - val_tn: 54072.0000 - val_fn: 8286.0000 - val_accuracy: 0.7411 - val_precision: 0.7491 - val_recall: 0.7310 - val_auc: 0.8662\n",
            "Epoch 15/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.7128 - tp: 89160.0000 - fp: 29548.0000 - tn: 216908.0000 - fn: 34068.0000 - accuracy: 0.7392 - precision: 0.7511 - recall: 0.7235 - auc: 0.8661 - val_loss: 0.7125 - val_tp: 22514.0000 - val_fp: 7522.0000 - val_tn: 54092.0000 - val_fn: 8293.0000 - val_accuracy: 0.7408 - val_precision: 0.7496 - val_recall: 0.7308 - val_auc: 0.8665\n",
            "Epoch 16/200\n",
            "241/241 [==============================] - 18s 74ms/step - loss: 0.7122 - tp: 89100.0000 - fp: 29459.0000 - tn: 216997.0000 - fn: 34128.0000 - accuracy: 0.7393 - precision: 0.7515 - recall: 0.7230 - auc: 0.8663 - val_loss: 0.7119 - val_tp: 22504.0000 - val_fp: 7506.0000 - val_tn: 54108.0000 - val_fn: 8303.0000 - val_accuracy: 0.7407 - val_precision: 0.7499 - val_recall: 0.7305 - val_auc: 0.8667\n",
            "Epoch 17/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7117 - tp: 89055.0000 - fp: 29365.0000 - tn: 217091.0000 - fn: 34173.0000 - accuracy: 0.7392 - precision: 0.7520 - recall: 0.7227 - auc: 0.8665 - val_loss: 0.7114 - val_tp: 22488.0000 - val_fp: 7487.0000 - val_tn: 54127.0000 - val_fn: 8319.0000 - val_accuracy: 0.7408 - val_precision: 0.7502 - val_recall: 0.7300 - val_auc: 0.8669\n",
            "Epoch 18/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7112 - tp: 89022.0000 - fp: 29324.0000 - tn: 217132.0000 - fn: 34206.0000 - accuracy: 0.7393 - precision: 0.7522 - recall: 0.7224 - auc: 0.8667 - val_loss: 0.7109 - val_tp: 22482.0000 - val_fp: 7483.0000 - val_tn: 54131.0000 - val_fn: 8325.0000 - val_accuracy: 0.7410 - val_precision: 0.7503 - val_recall: 0.7298 - val_auc: 0.8672\n",
            "Epoch 19/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7108 - tp: 88986.0000 - fp: 29269.0000 - tn: 217187.0000 - fn: 34242.0000 - accuracy: 0.7393 - precision: 0.7525 - recall: 0.7221 - auc: 0.8669 - val_loss: 0.7105 - val_tp: 22478.0000 - val_fp: 7473.0000 - val_tn: 54141.0000 - val_fn: 8329.0000 - val_accuracy: 0.7409 - val_precision: 0.7505 - val_recall: 0.7296 - val_auc: 0.8673\n",
            "Epoch 20/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7105 - tp: 88986.0000 - fp: 29248.0000 - tn: 217208.0000 - fn: 34242.0000 - accuracy: 0.7394 - precision: 0.7526 - recall: 0.7221 - auc: 0.8670 - val_loss: 0.7102 - val_tp: 22469.0000 - val_fp: 7461.0000 - val_tn: 54153.0000 - val_fn: 8338.0000 - val_accuracy: 0.7410 - val_precision: 0.7507 - val_recall: 0.7293 - val_auc: 0.8675\n",
            "Epoch 21/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.7101 - tp: 88962.0000 - fp: 29199.0000 - tn: 217257.0000 - fn: 34266.0000 - accuracy: 0.7395 - precision: 0.7529 - recall: 0.7219 - auc: 0.8672 - val_loss: 0.7098 - val_tp: 22451.0000 - val_fp: 7451.0000 - val_tn: 54163.0000 - val_fn: 8356.0000 - val_accuracy: 0.7411 - val_precision: 0.7508 - val_recall: 0.7288 - val_auc: 0.8677\n",
            "Epoch 22/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7098 - tp: 88941.0000 - fp: 29167.0000 - tn: 217289.0000 - fn: 34287.0000 - accuracy: 0.7396 - precision: 0.7530 - recall: 0.7218 - auc: 0.8673 - val_loss: 0.7095 - val_tp: 22444.0000 - val_fp: 7443.0000 - val_tn: 54171.0000 - val_fn: 8363.0000 - val_accuracy: 0.7411 - val_precision: 0.7510 - val_recall: 0.7285 - val_auc: 0.8678\n",
            "Epoch 23/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.7095 - tp: 88911.0000 - fp: 29136.0000 - tn: 217320.0000 - fn: 34317.0000 - accuracy: 0.7396 - precision: 0.7532 - recall: 0.7215 - auc: 0.8675 - val_loss: 0.7092 - val_tp: 22439.0000 - val_fp: 7439.0000 - val_tn: 54175.0000 - val_fn: 8368.0000 - val_accuracy: 0.7412 - val_precision: 0.7510 - val_recall: 0.7284 - val_auc: 0.8679\n",
            "Epoch 24/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.7092 - tp: 88892.0000 - fp: 29098.0000 - tn: 217358.0000 - fn: 34336.0000 - accuracy: 0.7395 - precision: 0.7534 - recall: 0.7214 - auc: 0.8676 - val_loss: 0.7089 - val_tp: 22438.0000 - val_fp: 7433.0000 - val_tn: 54181.0000 - val_fn: 8369.0000 - val_accuracy: 0.7413 - val_precision: 0.7512 - val_recall: 0.7283 - val_auc: 0.8681\n",
            "Epoch 25/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.7090 - tp: 88864.0000 - fp: 29082.0000 - tn: 217374.0000 - fn: 34364.0000 - accuracy: 0.7397 - precision: 0.7534 - recall: 0.7211 - auc: 0.8677 - val_loss: 0.7087 - val_tp: 22426.0000 - val_fp: 7421.0000 - val_tn: 54193.0000 - val_fn: 8381.0000 - val_accuracy: 0.7410 - val_precision: 0.7514 - val_recall: 0.7280 - val_auc: 0.8682\n",
            "Epoch 26/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.7088 - tp: 88848.0000 - fp: 29063.0000 - tn: 217393.0000 - fn: 34380.0000 - accuracy: 0.7397 - precision: 0.7535 - recall: 0.7210 - auc: 0.8678 - val_loss: 0.7085 - val_tp: 22428.0000 - val_fp: 7415.0000 - val_tn: 54199.0000 - val_fn: 8379.0000 - val_accuracy: 0.7411 - val_precision: 0.7515 - val_recall: 0.7280 - val_auc: 0.8683\n",
            "Epoch 27/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.7085 - tp: 88844.0000 - fp: 29046.0000 - tn: 217410.0000 - fn: 34384.0000 - accuracy: 0.7398 - precision: 0.7536 - recall: 0.7210 - auc: 0.8679 - val_loss: 0.7083 - val_tp: 22429.0000 - val_fp: 7421.0000 - val_tn: 54193.0000 - val_fn: 8378.0000 - val_accuracy: 0.7411 - val_precision: 0.7514 - val_recall: 0.7280 - val_auc: 0.8684\n",
            "Epoch 28/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.7083 - tp: 88845.0000 - fp: 29029.0000 - tn: 217427.0000 - fn: 34383.0000 - accuracy: 0.7398 - precision: 0.7537 - recall: 0.7210 - auc: 0.8680 - val_loss: 0.7080 - val_tp: 22441.0000 - val_fp: 7416.0000 - val_tn: 54198.0000 - val_fn: 8366.0000 - val_accuracy: 0.7413 - val_precision: 0.7516 - val_recall: 0.7284 - val_auc: 0.8685\n",
            "Epoch 29/200\n",
            "241/241 [==============================] - 17s 73ms/step - loss: 0.7081 - tp: 88819.0000 - fp: 29010.0000 - tn: 217446.0000 - fn: 34409.0000 - accuracy: 0.7398 - precision: 0.7538 - recall: 0.7208 - auc: 0.8681 - val_loss: 0.7078 - val_tp: 22429.0000 - val_fp: 7409.0000 - val_tn: 54205.0000 - val_fn: 8378.0000 - val_accuracy: 0.7413 - val_precision: 0.7517 - val_recall: 0.7280 - val_auc: 0.8686\n",
            "Epoch 30/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.7078 - tp: 88813.0000 - fp: 28997.0000 - tn: 217459.0000 - fn: 34415.0000 - accuracy: 0.7398 - precision: 0.7539 - recall: 0.7207 - auc: 0.8682 - val_loss: 0.7076 - val_tp: 22426.0000 - val_fp: 7404.0000 - val_tn: 54210.0000 - val_fn: 8381.0000 - val_accuracy: 0.7412 - val_precision: 0.7518 - val_recall: 0.7280 - val_auc: 0.8687\n",
            "Epoch 31/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.7076 - tp: 88817.0000 - fp: 28986.0000 - tn: 217470.0000 - fn: 34411.0000 - accuracy: 0.7398 - precision: 0.7539 - recall: 0.7208 - auc: 0.8683 - val_loss: 0.7073 - val_tp: 22417.0000 - val_fp: 7397.0000 - val_tn: 54217.0000 - val_fn: 8390.0000 - val_accuracy: 0.7412 - val_precision: 0.7519 - val_recall: 0.7277 - val_auc: 0.8688\n",
            "Epoch 32/200\n",
            "241/241 [==============================] - 17s 73ms/step - loss: 0.7074 - tp: 88798.0000 - fp: 28959.0000 - tn: 217497.0000 - fn: 34430.0000 - accuracy: 0.7399 - precision: 0.7541 - recall: 0.7206 - auc: 0.8684 - val_loss: 0.7071 - val_tp: 22419.0000 - val_fp: 7388.0000 - val_tn: 54226.0000 - val_fn: 8388.0000 - val_accuracy: 0.7412 - val_precision: 0.7521 - val_recall: 0.7277 - val_auc: 0.8688\n",
            "Epoch 33/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7072 - tp: 88785.0000 - fp: 28944.0000 - tn: 217512.0000 - fn: 34443.0000 - accuracy: 0.7399 - precision: 0.7541 - recall: 0.7205 - auc: 0.8685 - val_loss: 0.7069 - val_tp: 22419.0000 - val_fp: 7388.0000 - val_tn: 54226.0000 - val_fn: 8388.0000 - val_accuracy: 0.7412 - val_precision: 0.7521 - val_recall: 0.7277 - val_auc: 0.8689\n",
            "Epoch 34/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7070 - tp: 88779.0000 - fp: 28926.0000 - tn: 217530.0000 - fn: 34449.0000 - accuracy: 0.7398 - precision: 0.7543 - recall: 0.7204 - auc: 0.8687 - val_loss: 0.7067 - val_tp: 22418.0000 - val_fp: 7378.0000 - val_tn: 54236.0000 - val_fn: 8389.0000 - val_accuracy: 0.7412 - val_precision: 0.7524 - val_recall: 0.7277 - val_auc: 0.8690\n",
            "Epoch 35/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.7068 - tp: 88775.0000 - fp: 28904.0000 - tn: 217552.0000 - fn: 34453.0000 - accuracy: 0.7400 - precision: 0.7544 - recall: 0.7204 - auc: 0.8688 - val_loss: 0.7064 - val_tp: 22421.0000 - val_fp: 7378.0000 - val_tn: 54236.0000 - val_fn: 8386.0000 - val_accuracy: 0.7412 - val_precision: 0.7524 - val_recall: 0.7278 - val_auc: 0.8691\n",
            "Epoch 36/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7065 - tp: 88763.0000 - fp: 28884.0000 - tn: 217572.0000 - fn: 34465.0000 - accuracy: 0.7400 - precision: 0.7545 - recall: 0.7203 - auc: 0.8688 - val_loss: 0.7062 - val_tp: 22410.0000 - val_fp: 7365.0000 - val_tn: 54249.0000 - val_fn: 8397.0000 - val_accuracy: 0.7413 - val_precision: 0.7526 - val_recall: 0.7274 - val_auc: 0.8692\n",
            "Epoch 37/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7063 - tp: 88757.0000 - fp: 28857.0000 - tn: 217599.0000 - fn: 34471.0000 - accuracy: 0.7401 - precision: 0.7546 - recall: 0.7203 - auc: 0.8689 - val_loss: 0.7060 - val_tp: 22411.0000 - val_fp: 7363.0000 - val_tn: 54251.0000 - val_fn: 8396.0000 - val_accuracy: 0.7414 - val_precision: 0.7527 - val_recall: 0.7275 - val_auc: 0.8693\n",
            "Epoch 38/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.7061 - tp: 88750.0000 - fp: 28841.0000 - tn: 217615.0000 - fn: 34478.0000 - accuracy: 0.7401 - precision: 0.7547 - recall: 0.7202 - auc: 0.8690 - val_loss: 0.7058 - val_tp: 22407.0000 - val_fp: 7361.0000 - val_tn: 54253.0000 - val_fn: 8400.0000 - val_accuracy: 0.7415 - val_precision: 0.7527 - val_recall: 0.7273 - val_auc: 0.8694\n",
            "Epoch 39/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.7059 - tp: 88744.0000 - fp: 28826.0000 - tn: 217630.0000 - fn: 34484.0000 - accuracy: 0.7402 - precision: 0.7548 - recall: 0.7202 - auc: 0.8691 - val_loss: 0.7057 - val_tp: 22414.0000 - val_fp: 7368.0000 - val_tn: 54246.0000 - val_fn: 8393.0000 - val_accuracy: 0.7414 - val_precision: 0.7526 - val_recall: 0.7276 - val_auc: 0.8695\n",
            "Epoch 40/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.7057 - tp: 88755.0000 - fp: 28817.0000 - tn: 217639.0000 - fn: 34473.0000 - accuracy: 0.7402 - precision: 0.7549 - recall: 0.7203 - auc: 0.8692 - val_loss: 0.7055 - val_tp: 22417.0000 - val_fp: 7366.0000 - val_tn: 54248.0000 - val_fn: 8390.0000 - val_accuracy: 0.7415 - val_precision: 0.7527 - val_recall: 0.7277 - val_auc: 0.8696\n",
            "Epoch 41/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.7055 - tp: 88751.0000 - fp: 28817.0000 - tn: 217639.0000 - fn: 34477.0000 - accuracy: 0.7402 - precision: 0.7549 - recall: 0.7202 - auc: 0.8693 - val_loss: 0.7052 - val_tp: 22407.0000 - val_fp: 7356.0000 - val_tn: 54258.0000 - val_fn: 8400.0000 - val_accuracy: 0.7414 - val_precision: 0.7528 - val_recall: 0.7273 - val_auc: 0.8697\n",
            "Epoch 42/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.7053 - tp: 88739.0000 - fp: 28812.0000 - tn: 217644.0000 - fn: 34489.0000 - accuracy: 0.7403 - precision: 0.7549 - recall: 0.7201 - auc: 0.8694 - val_loss: 0.7050 - val_tp: 22405.0000 - val_fp: 7351.0000 - val_tn: 54263.0000 - val_fn: 8402.0000 - val_accuracy: 0.7414 - val_precision: 0.7530 - val_recall: 0.7273 - val_auc: 0.8698\n",
            "Epoch 43/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.7051 - tp: 88745.0000 - fp: 28794.0000 - tn: 217662.0000 - fn: 34483.0000 - accuracy: 0.7403 - precision: 0.7550 - recall: 0.7202 - auc: 0.8695 - val_loss: 0.7049 - val_tp: 22416.0000 - val_fp: 7360.0000 - val_tn: 54254.0000 - val_fn: 8391.0000 - val_accuracy: 0.7414 - val_precision: 0.7528 - val_recall: 0.7276 - val_auc: 0.8699\n",
            "Epoch 44/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.7049 - tp: 88754.0000 - fp: 28786.0000 - tn: 217670.0000 - fn: 34474.0000 - accuracy: 0.7404 - precision: 0.7551 - recall: 0.7202 - auc: 0.8696 - val_loss: 0.7047 - val_tp: 22415.0000 - val_fp: 7356.0000 - val_tn: 54258.0000 - val_fn: 8392.0000 - val_accuracy: 0.7414 - val_precision: 0.7529 - val_recall: 0.7276 - val_auc: 0.8700\n",
            "Epoch 45/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.7048 - tp: 88749.0000 - fp: 28774.0000 - tn: 217682.0000 - fn: 34479.0000 - accuracy: 0.7404 - precision: 0.7552 - recall: 0.7202 - auc: 0.8697 - val_loss: 0.7044 - val_tp: 22414.0000 - val_fp: 7353.0000 - val_tn: 54261.0000 - val_fn: 8393.0000 - val_accuracy: 0.7414 - val_precision: 0.7530 - val_recall: 0.7276 - val_auc: 0.8701\n",
            "Epoch 46/200\n",
            "241/241 [==============================] - 17s 73ms/step - loss: 0.7045 - tp: 88753.0000 - fp: 28765.0000 - tn: 217691.0000 - fn: 34475.0000 - accuracy: 0.7404 - precision: 0.7552 - recall: 0.7202 - auc: 0.8698 - val_loss: 0.7042 - val_tp: 22414.0000 - val_fp: 7355.0000 - val_tn: 54259.0000 - val_fn: 8393.0000 - val_accuracy: 0.7415 - val_precision: 0.7529 - val_recall: 0.7276 - val_auc: 0.8703\n",
            "Epoch 47/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7044 - tp: 88764.0000 - fp: 28756.0000 - tn: 217700.0000 - fn: 34464.0000 - accuracy: 0.7405 - precision: 0.7553 - recall: 0.7203 - auc: 0.8699 - val_loss: 0.7041 - val_tp: 22413.0000 - val_fp: 7351.0000 - val_tn: 54263.0000 - val_fn: 8394.0000 - val_accuracy: 0.7415 - val_precision: 0.7530 - val_recall: 0.7275 - val_auc: 0.8703\n",
            "Epoch 48/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.7042 - tp: 88761.0000 - fp: 28741.0000 - tn: 217715.0000 - fn: 34467.0000 - accuracy: 0.7405 - precision: 0.7554 - recall: 0.7203 - auc: 0.8700 - val_loss: 0.7039 - val_tp: 22413.0000 - val_fp: 7350.0000 - val_tn: 54264.0000 - val_fn: 8394.0000 - val_accuracy: 0.7415 - val_precision: 0.7530 - val_recall: 0.7275 - val_auc: 0.8704\n",
            "Epoch 49/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7040 - tp: 88769.0000 - fp: 28731.0000 - tn: 217725.0000 - fn: 34459.0000 - accuracy: 0.7405 - precision: 0.7555 - recall: 0.7204 - auc: 0.8700 - val_loss: 0.7037 - val_tp: 22416.0000 - val_fp: 7353.0000 - val_tn: 54261.0000 - val_fn: 8391.0000 - val_accuracy: 0.7416 - val_precision: 0.7530 - val_recall: 0.7276 - val_auc: 0.8705\n",
            "Epoch 50/200\n",
            "241/241 [==============================] - 17s 73ms/step - loss: 0.7038 - tp: 88767.0000 - fp: 28723.0000 - tn: 217733.0000 - fn: 34461.0000 - accuracy: 0.7407 - precision: 0.7555 - recall: 0.7203 - auc: 0.8701 - val_loss: 0.7036 - val_tp: 22413.0000 - val_fp: 7348.0000 - val_tn: 54266.0000 - val_fn: 8394.0000 - val_accuracy: 0.7416 - val_precision: 0.7531 - val_recall: 0.7275 - val_auc: 0.8706\n",
            "Epoch 51/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.7036 - tp: 88762.0000 - fp: 28711.0000 - tn: 217745.0000 - fn: 34466.0000 - accuracy: 0.7407 - precision: 0.7556 - recall: 0.7203 - auc: 0.8702 - val_loss: 0.7034 - val_tp: 22415.0000 - val_fp: 7347.0000 - val_tn: 54267.0000 - val_fn: 8392.0000 - val_accuracy: 0.7416 - val_precision: 0.7531 - val_recall: 0.7276 - val_auc: 0.8707\n",
            "Epoch 52/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7034 - tp: 88764.0000 - fp: 28720.0000 - tn: 217736.0000 - fn: 34464.0000 - accuracy: 0.7409 - precision: 0.7555 - recall: 0.7203 - auc: 0.8703 - val_loss: 0.7031 - val_tp: 22407.0000 - val_fp: 7343.0000 - val_tn: 54271.0000 - val_fn: 8400.0000 - val_accuracy: 0.7417 - val_precision: 0.7532 - val_recall: 0.7273 - val_auc: 0.8708\n",
            "Epoch 53/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7032 - tp: 88761.0000 - fp: 28698.0000 - tn: 217758.0000 - fn: 34467.0000 - accuracy: 0.7410 - precision: 0.7557 - recall: 0.7203 - auc: 0.8704 - val_loss: 0.7029 - val_tp: 22417.0000 - val_fp: 7344.0000 - val_tn: 54270.0000 - val_fn: 8390.0000 - val_accuracy: 0.7417 - val_precision: 0.7532 - val_recall: 0.7277 - val_auc: 0.8709\n",
            "Epoch 54/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7030 - tp: 88752.0000 - fp: 28699.0000 - tn: 217757.0000 - fn: 34476.0000 - accuracy: 0.7409 - precision: 0.7557 - recall: 0.7202 - auc: 0.8706 - val_loss: 0.7027 - val_tp: 22409.0000 - val_fp: 7336.0000 - val_tn: 54278.0000 - val_fn: 8398.0000 - val_accuracy: 0.7418 - val_precision: 0.7534 - val_recall: 0.7274 - val_auc: 0.8710\n",
            "Epoch 55/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7028 - tp: 88739.0000 - fp: 28677.0000 - tn: 217779.0000 - fn: 34489.0000 - accuracy: 0.7409 - precision: 0.7558 - recall: 0.7201 - auc: 0.8706 - val_loss: 0.7025 - val_tp: 22408.0000 - val_fp: 7333.0000 - val_tn: 54281.0000 - val_fn: 8399.0000 - val_accuracy: 0.7419 - val_precision: 0.7534 - val_recall: 0.7274 - val_auc: 0.8711\n",
            "Epoch 56/200\n",
            "241/241 [==============================] - 17s 73ms/step - loss: 0.7026 - tp: 88742.0000 - fp: 28661.0000 - tn: 217795.0000 - fn: 34486.0000 - accuracy: 0.7410 - precision: 0.7559 - recall: 0.7201 - auc: 0.8708 - val_loss: 0.7024 - val_tp: 22405.0000 - val_fp: 7332.0000 - val_tn: 54282.0000 - val_fn: 8402.0000 - val_accuracy: 0.7419 - val_precision: 0.7534 - val_recall: 0.7273 - val_auc: 0.8712\n",
            "Epoch 57/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.7024 - tp: 88749.0000 - fp: 28664.0000 - tn: 217792.0000 - fn: 34479.0000 - accuracy: 0.7410 - precision: 0.7559 - recall: 0.7202 - auc: 0.8709 - val_loss: 0.7022 - val_tp: 22409.0000 - val_fp: 7332.0000 - val_tn: 54282.0000 - val_fn: 8398.0000 - val_accuracy: 0.7419 - val_precision: 0.7535 - val_recall: 0.7274 - val_auc: 0.8713\n",
            "Epoch 58/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7022 - tp: 88735.0000 - fp: 28642.0000 - tn: 217814.0000 - fn: 34493.0000 - accuracy: 0.7410 - precision: 0.7560 - recall: 0.7201 - auc: 0.8710 - val_loss: 0.7020 - val_tp: 22400.0000 - val_fp: 7324.0000 - val_tn: 54290.0000 - val_fn: 8407.0000 - val_accuracy: 0.7419 - val_precision: 0.7536 - val_recall: 0.7271 - val_auc: 0.8714\n",
            "Epoch 59/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7020 - tp: 88738.0000 - fp: 28641.0000 - tn: 217815.0000 - fn: 34490.0000 - accuracy: 0.7410 - precision: 0.7560 - recall: 0.7201 - auc: 0.8711 - val_loss: 0.7018 - val_tp: 22400.0000 - val_fp: 7322.0000 - val_tn: 54292.0000 - val_fn: 8407.0000 - val_accuracy: 0.7420 - val_precision: 0.7537 - val_recall: 0.7271 - val_auc: 0.8715\n",
            "Epoch 60/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.7018 - tp: 88750.0000 - fp: 28623.0000 - tn: 217833.0000 - fn: 34478.0000 - accuracy: 0.7411 - precision: 0.7561 - recall: 0.7202 - auc: 0.8712 - val_loss: 0.7016 - val_tp: 22402.0000 - val_fp: 7328.0000 - val_tn: 54286.0000 - val_fn: 8405.0000 - val_accuracy: 0.7421 - val_precision: 0.7535 - val_recall: 0.7272 - val_auc: 0.8716\n",
            "Epoch 61/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.7016 - tp: 88757.0000 - fp: 28613.0000 - tn: 217843.0000 - fn: 34471.0000 - accuracy: 0.7411 - precision: 0.7562 - recall: 0.7203 - auc: 0.8713 - val_loss: 0.7014 - val_tp: 22397.0000 - val_fp: 7311.0000 - val_tn: 54303.0000 - val_fn: 8410.0000 - val_accuracy: 0.7421 - val_precision: 0.7539 - val_recall: 0.7270 - val_auc: 0.8717\n",
            "Epoch 62/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7014 - tp: 88753.0000 - fp: 28600.0000 - tn: 217856.0000 - fn: 34475.0000 - accuracy: 0.7412 - precision: 0.7563 - recall: 0.7202 - auc: 0.8713 - val_loss: 0.7012 - val_tp: 22403.0000 - val_fp: 7321.0000 - val_tn: 54293.0000 - val_fn: 8404.0000 - val_accuracy: 0.7420 - val_precision: 0.7537 - val_recall: 0.7272 - val_auc: 0.8719\n",
            "Epoch 63/200\n",
            "241/241 [==============================] - 18s 74ms/step - loss: 0.7013 - tp: 88744.0000 - fp: 28572.0000 - tn: 217884.0000 - fn: 34484.0000 - accuracy: 0.7412 - precision: 0.7565 - recall: 0.7202 - auc: 0.8714 - val_loss: 0.7010 - val_tp: 22410.0000 - val_fp: 7331.0000 - val_tn: 54283.0000 - val_fn: 8397.0000 - val_accuracy: 0.7422 - val_precision: 0.7535 - val_recall: 0.7274 - val_auc: 0.8719\n",
            "Epoch 64/200\n",
            "241/241 [==============================] - 18s 74ms/step - loss: 0.7011 - tp: 88740.0000 - fp: 28565.0000 - tn: 217891.0000 - fn: 34488.0000 - accuracy: 0.7412 - precision: 0.7565 - recall: 0.7201 - auc: 0.8715 - val_loss: 0.7009 - val_tp: 22398.0000 - val_fp: 7313.0000 - val_tn: 54301.0000 - val_fn: 8409.0000 - val_accuracy: 0.7423 - val_precision: 0.7539 - val_recall: 0.7270 - val_auc: 0.8720\n",
            "Epoch 65/200\n",
            "241/241 [==============================] - 18s 74ms/step - loss: 0.7009 - tp: 88738.0000 - fp: 28550.0000 - tn: 217906.0000 - fn: 34490.0000 - accuracy: 0.7412 - precision: 0.7566 - recall: 0.7201 - auc: 0.8716 - val_loss: 0.7007 - val_tp: 22416.0000 - val_fp: 7326.0000 - val_tn: 54288.0000 - val_fn: 8391.0000 - val_accuracy: 0.7422 - val_precision: 0.7537 - val_recall: 0.7276 - val_auc: 0.8721\n",
            "Epoch 66/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.7007 - tp: 88745.0000 - fp: 28551.0000 - tn: 217905.0000 - fn: 34483.0000 - accuracy: 0.7413 - precision: 0.7566 - recall: 0.7202 - auc: 0.8717 - val_loss: 0.7005 - val_tp: 22403.0000 - val_fp: 7316.0000 - val_tn: 54298.0000 - val_fn: 8404.0000 - val_accuracy: 0.7424 - val_precision: 0.7538 - val_recall: 0.7272 - val_auc: 0.8722\n",
            "Epoch 67/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.7005 - tp: 88758.0000 - fp: 28554.0000 - tn: 217902.0000 - fn: 34470.0000 - accuracy: 0.7413 - precision: 0.7566 - recall: 0.7203 - auc: 0.8718 - val_loss: 0.7003 - val_tp: 22407.0000 - val_fp: 7316.0000 - val_tn: 54298.0000 - val_fn: 8400.0000 - val_accuracy: 0.7426 - val_precision: 0.7539 - val_recall: 0.7273 - val_auc: 0.8723\n",
            "Epoch 68/200\n",
            "241/241 [==============================] - 18s 74ms/step - loss: 0.7004 - tp: 88773.0000 - fp: 28558.0000 - tn: 217898.0000 - fn: 34455.0000 - accuracy: 0.7414 - precision: 0.7566 - recall: 0.7204 - auc: 0.8719 - val_loss: 0.7001 - val_tp: 22411.0000 - val_fp: 7311.0000 - val_tn: 54303.0000 - val_fn: 8396.0000 - val_accuracy: 0.7426 - val_precision: 0.7540 - val_recall: 0.7275 - val_auc: 0.8724\n",
            "Epoch 69/200\n",
            "241/241 [==============================] - 18s 75ms/step - loss: 0.7002 - tp: 88793.0000 - fp: 28547.0000 - tn: 217909.0000 - fn: 34435.0000 - accuracy: 0.7414 - precision: 0.7567 - recall: 0.7206 - auc: 0.8720 - val_loss: 0.6999 - val_tp: 22412.0000 - val_fp: 7313.0000 - val_tn: 54301.0000 - val_fn: 8395.0000 - val_accuracy: 0.7425 - val_precision: 0.7540 - val_recall: 0.7275 - val_auc: 0.8725\n",
            "Epoch 70/200\n",
            "241/241 [==============================] - 18s 74ms/step - loss: 0.7000 - tp: 88801.0000 - fp: 28550.0000 - tn: 217906.0000 - fn: 34427.0000 - accuracy: 0.7416 - precision: 0.7567 - recall: 0.7206 - auc: 0.8721 - val_loss: 0.6997 - val_tp: 22410.0000 - val_fp: 7301.0000 - val_tn: 54313.0000 - val_fn: 8397.0000 - val_accuracy: 0.7427 - val_precision: 0.7543 - val_recall: 0.7274 - val_auc: 0.8726\n",
            "Epoch 71/200\n",
            "241/241 [==============================] - 18s 74ms/step - loss: 0.6998 - tp: 88818.0000 - fp: 28530.0000 - tn: 217926.0000 - fn: 34410.0000 - accuracy: 0.7416 - precision: 0.7569 - recall: 0.7208 - auc: 0.8722 - val_loss: 0.6996 - val_tp: 22414.0000 - val_fp: 7307.0000 - val_tn: 54307.0000 - val_fn: 8393.0000 - val_accuracy: 0.7427 - val_precision: 0.7541 - val_recall: 0.7276 - val_auc: 0.8727\n",
            "Epoch 72/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.6996 - tp: 88807.0000 - fp: 28516.0000 - tn: 217940.0000 - fn: 34421.0000 - accuracy: 0.7417 - precision: 0.7569 - recall: 0.7207 - auc: 0.8723 - val_loss: 0.6994 - val_tp: 22407.0000 - val_fp: 7287.0000 - val_tn: 54327.0000 - val_fn: 8400.0000 - val_accuracy: 0.7428 - val_precision: 0.7546 - val_recall: 0.7273 - val_auc: 0.8728\n",
            "Epoch 73/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6994 - tp: 88818.0000 - fp: 28503.0000 - tn: 217953.0000 - fn: 34410.0000 - accuracy: 0.7418 - precision: 0.7571 - recall: 0.7208 - auc: 0.8724 - val_loss: 0.6992 - val_tp: 22411.0000 - val_fp: 7293.0000 - val_tn: 54321.0000 - val_fn: 8396.0000 - val_accuracy: 0.7428 - val_precision: 0.7545 - val_recall: 0.7275 - val_auc: 0.8729\n",
            "Epoch 74/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6993 - tp: 88815.0000 - fp: 28499.0000 - tn: 217957.0000 - fn: 34413.0000 - accuracy: 0.7418 - precision: 0.7571 - recall: 0.7207 - auc: 0.8725 - val_loss: 0.6990 - val_tp: 22401.0000 - val_fp: 7274.0000 - val_tn: 54340.0000 - val_fn: 8406.0000 - val_accuracy: 0.7429 - val_precision: 0.7549 - val_recall: 0.7271 - val_auc: 0.8730\n",
            "Epoch 75/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.6991 - tp: 88806.0000 - fp: 28483.0000 - tn: 217973.0000 - fn: 34422.0000 - accuracy: 0.7419 - precision: 0.7572 - recall: 0.7207 - auc: 0.8726 - val_loss: 0.6988 - val_tp: 22407.0000 - val_fp: 7279.0000 - val_tn: 54335.0000 - val_fn: 8400.0000 - val_accuracy: 0.7429 - val_precision: 0.7548 - val_recall: 0.7273 - val_auc: 0.8731\n",
            "Epoch 76/200\n",
            "241/241 [==============================] - 17s 69ms/step - loss: 0.6989 - tp: 88818.0000 - fp: 28479.0000 - tn: 217977.0000 - fn: 34410.0000 - accuracy: 0.7419 - precision: 0.7572 - recall: 0.7208 - auc: 0.8727 - val_loss: 0.6987 - val_tp: 22408.0000 - val_fp: 7259.0000 - val_tn: 54355.0000 - val_fn: 8399.0000 - val_accuracy: 0.7429 - val_precision: 0.7553 - val_recall: 0.7274 - val_auc: 0.8733\n",
            "Epoch 77/200\n",
            "241/241 [==============================] - 17s 69ms/step - loss: 0.6987 - tp: 88820.0000 - fp: 28460.0000 - tn: 217996.0000 - fn: 34408.0000 - accuracy: 0.7419 - precision: 0.7573 - recall: 0.7208 - auc: 0.8728 - val_loss: 0.6985 - val_tp: 22411.0000 - val_fp: 7266.0000 - val_tn: 54348.0000 - val_fn: 8396.0000 - val_accuracy: 0.7429 - val_precision: 0.7552 - val_recall: 0.7275 - val_auc: 0.8733\n",
            "Epoch 78/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6985 - tp: 88831.0000 - fp: 28453.0000 - tn: 218003.0000 - fn: 34397.0000 - accuracy: 0.7420 - precision: 0.7574 - recall: 0.7209 - auc: 0.8729 - val_loss: 0.6983 - val_tp: 22418.0000 - val_fp: 7261.0000 - val_tn: 54353.0000 - val_fn: 8389.0000 - val_accuracy: 0.7430 - val_precision: 0.7553 - val_recall: 0.7277 - val_auc: 0.8734\n",
            "Epoch 79/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6983 - tp: 88827.0000 - fp: 28446.0000 - tn: 218010.0000 - fn: 34401.0000 - accuracy: 0.7421 - precision: 0.7574 - recall: 0.7208 - auc: 0.8730 - val_loss: 0.6981 - val_tp: 22415.0000 - val_fp: 7254.0000 - val_tn: 54360.0000 - val_fn: 8392.0000 - val_accuracy: 0.7430 - val_precision: 0.7555 - val_recall: 0.7276 - val_auc: 0.8735\n",
            "Epoch 80/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6981 - tp: 88818.0000 - fp: 28435.0000 - tn: 218021.0000 - fn: 34410.0000 - accuracy: 0.7422 - precision: 0.7575 - recall: 0.7208 - auc: 0.8731 - val_loss: 0.6980 - val_tp: 22424.0000 - val_fp: 7269.0000 - val_tn: 54345.0000 - val_fn: 8383.0000 - val_accuracy: 0.7431 - val_precision: 0.7552 - val_recall: 0.7279 - val_auc: 0.8736\n",
            "Epoch 81/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6980 - tp: 88788.0000 - fp: 28396.0000 - tn: 218060.0000 - fn: 34440.0000 - accuracy: 0.7423 - precision: 0.7577 - recall: 0.7205 - auc: 0.8732 - val_loss: 0.6978 - val_tp: 22425.0000 - val_fp: 7264.0000 - val_tn: 54350.0000 - val_fn: 8382.0000 - val_accuracy: 0.7432 - val_precision: 0.7553 - val_recall: 0.7279 - val_auc: 0.8737\n",
            "Epoch 82/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6978 - tp: 88781.0000 - fp: 28377.0000 - tn: 218079.0000 - fn: 34447.0000 - accuracy: 0.7424 - precision: 0.7578 - recall: 0.7205 - auc: 0.8733 - val_loss: 0.6976 - val_tp: 22423.0000 - val_fp: 7254.0000 - val_tn: 54360.0000 - val_fn: 8384.0000 - val_accuracy: 0.7433 - val_precision: 0.7556 - val_recall: 0.7279 - val_auc: 0.8738\n",
            "Epoch 83/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6976 - tp: 88801.0000 - fp: 28368.0000 - tn: 218088.0000 - fn: 34427.0000 - accuracy: 0.7425 - precision: 0.7579 - recall: 0.7206 - auc: 0.8734 - val_loss: 0.6974 - val_tp: 22422.0000 - val_fp: 7255.0000 - val_tn: 54359.0000 - val_fn: 8385.0000 - val_accuracy: 0.7433 - val_precision: 0.7555 - val_recall: 0.7278 - val_auc: 0.8739\n",
            "Epoch 84/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6974 - tp: 88808.0000 - fp: 28346.0000 - tn: 218110.0000 - fn: 34420.0000 - accuracy: 0.7426 - precision: 0.7580 - recall: 0.7207 - auc: 0.8735 - val_loss: 0.6973 - val_tp: 22441.0000 - val_fp: 7270.0000 - val_tn: 54344.0000 - val_fn: 8366.0000 - val_accuracy: 0.7434 - val_precision: 0.7553 - val_recall: 0.7284 - val_auc: 0.8740\n",
            "Epoch 85/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6972 - tp: 88821.0000 - fp: 28350.0000 - tn: 218106.0000 - fn: 34407.0000 - accuracy: 0.7426 - precision: 0.7580 - recall: 0.7208 - auc: 0.8736 - val_loss: 0.6971 - val_tp: 22417.0000 - val_fp: 7236.0000 - val_tn: 54378.0000 - val_fn: 8390.0000 - val_accuracy: 0.7434 - val_precision: 0.7560 - val_recall: 0.7277 - val_auc: 0.8741\n",
            "Epoch 86/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6971 - tp: 88834.0000 - fp: 28365.0000 - tn: 218091.0000 - fn: 34394.0000 - accuracy: 0.7427 - precision: 0.7580 - recall: 0.7209 - auc: 0.8737 - val_loss: 0.6970 - val_tp: 22438.0000 - val_fp: 7262.0000 - val_tn: 54352.0000 - val_fn: 8369.0000 - val_accuracy: 0.7434 - val_precision: 0.7555 - val_recall: 0.7283 - val_auc: 0.8742\n",
            "Epoch 87/200\n",
            "241/241 [==============================] - 17s 73ms/step - loss: 0.6969 - tp: 88834.0000 - fp: 28328.0000 - tn: 218128.0000 - fn: 34394.0000 - accuracy: 0.7427 - precision: 0.7582 - recall: 0.7209 - auc: 0.8738 - val_loss: 0.6968 - val_tp: 22439.0000 - val_fp: 7243.0000 - val_tn: 54371.0000 - val_fn: 8368.0000 - val_accuracy: 0.7434 - val_precision: 0.7560 - val_recall: 0.7284 - val_auc: 0.8743\n",
            "Epoch 88/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6967 - tp: 88836.0000 - fp: 28328.0000 - tn: 218128.0000 - fn: 34392.0000 - accuracy: 0.7428 - precision: 0.7582 - recall: 0.7209 - auc: 0.8739 - val_loss: 0.6966 - val_tp: 22429.0000 - val_fp: 7236.0000 - val_tn: 54378.0000 - val_fn: 8378.0000 - val_accuracy: 0.7435 - val_precision: 0.7561 - val_recall: 0.7280 - val_auc: 0.8744\n",
            "Epoch 89/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6965 - tp: 88843.0000 - fp: 28324.0000 - tn: 218132.0000 - fn: 34385.0000 - accuracy: 0.7429 - precision: 0.7583 - recall: 0.7210 - auc: 0.8740 - val_loss: 0.6964 - val_tp: 22431.0000 - val_fp: 7229.0000 - val_tn: 54385.0000 - val_fn: 8376.0000 - val_accuracy: 0.7438 - val_precision: 0.7563 - val_recall: 0.7281 - val_auc: 0.8745\n",
            "Epoch 90/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6963 - tp: 88839.0000 - fp: 28307.0000 - tn: 218149.0000 - fn: 34389.0000 - accuracy: 0.7429 - precision: 0.7584 - recall: 0.7209 - auc: 0.8741 - val_loss: 0.6962 - val_tp: 22428.0000 - val_fp: 7226.0000 - val_tn: 54388.0000 - val_fn: 8379.0000 - val_accuracy: 0.7438 - val_precision: 0.7563 - val_recall: 0.7280 - val_auc: 0.8746\n",
            "Epoch 91/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6961 - tp: 88849.0000 - fp: 28283.0000 - tn: 218173.0000 - fn: 34379.0000 - accuracy: 0.7431 - precision: 0.7585 - recall: 0.7210 - auc: 0.8742 - val_loss: 0.6961 - val_tp: 22438.0000 - val_fp: 7223.0000 - val_tn: 54391.0000 - val_fn: 8369.0000 - val_accuracy: 0.7438 - val_precision: 0.7565 - val_recall: 0.7283 - val_auc: 0.8747\n",
            "Epoch 92/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.6960 - tp: 88864.0000 - fp: 28268.0000 - tn: 218188.0000 - fn: 34364.0000 - accuracy: 0.7432 - precision: 0.7587 - recall: 0.7211 - auc: 0.8743 - val_loss: 0.6959 - val_tp: 22441.0000 - val_fp: 7223.0000 - val_tn: 54391.0000 - val_fn: 8366.0000 - val_accuracy: 0.7438 - val_precision: 0.7565 - val_recall: 0.7284 - val_auc: 0.8748\n",
            "Epoch 93/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.6958 - tp: 88859.0000 - fp: 28258.0000 - tn: 218198.0000 - fn: 34369.0000 - accuracy: 0.7433 - precision: 0.7587 - recall: 0.7211 - auc: 0.8744 - val_loss: 0.6957 - val_tp: 22434.0000 - val_fp: 7217.0000 - val_tn: 54397.0000 - val_fn: 8373.0000 - val_accuracy: 0.7438 - val_precision: 0.7566 - val_recall: 0.7282 - val_auc: 0.8749\n",
            "Epoch 94/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6956 - tp: 88858.0000 - fp: 28246.0000 - tn: 218210.0000 - fn: 34370.0000 - accuracy: 0.7433 - precision: 0.7588 - recall: 0.7211 - auc: 0.8745 - val_loss: 0.6956 - val_tp: 22446.0000 - val_fp: 7226.0000 - val_tn: 54388.0000 - val_fn: 8361.0000 - val_accuracy: 0.7439 - val_precision: 0.7565 - val_recall: 0.7286 - val_auc: 0.8750\n",
            "Epoch 95/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6954 - tp: 88856.0000 - fp: 28238.0000 - tn: 218218.0000 - fn: 34372.0000 - accuracy: 0.7435 - precision: 0.7588 - recall: 0.7211 - auc: 0.8746 - val_loss: 0.6954 - val_tp: 22451.0000 - val_fp: 7232.0000 - val_tn: 54382.0000 - val_fn: 8356.0000 - val_accuracy: 0.7438 - val_precision: 0.7564 - val_recall: 0.7288 - val_auc: 0.8751\n",
            "Epoch 96/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.6952 - tp: 88874.0000 - fp: 28254.0000 - tn: 218202.0000 - fn: 34354.0000 - accuracy: 0.7435 - precision: 0.7588 - recall: 0.7212 - auc: 0.8747 - val_loss: 0.6952 - val_tp: 22449.0000 - val_fp: 7227.0000 - val_tn: 54387.0000 - val_fn: 8358.0000 - val_accuracy: 0.7439 - val_precision: 0.7565 - val_recall: 0.7287 - val_auc: 0.8752\n",
            "Epoch 97/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.6950 - tp: 88875.0000 - fp: 28251.0000 - tn: 218205.0000 - fn: 34353.0000 - accuracy: 0.7435 - precision: 0.7588 - recall: 0.7212 - auc: 0.8748 - val_loss: 0.6950 - val_tp: 22448.0000 - val_fp: 7228.0000 - val_tn: 54386.0000 - val_fn: 8359.0000 - val_accuracy: 0.7439 - val_precision: 0.7564 - val_recall: 0.7287 - val_auc: 0.8753\n",
            "Epoch 98/200\n",
            "241/241 [==============================] - 18s 74ms/step - loss: 0.6948 - tp: 88881.0000 - fp: 28233.0000 - tn: 218223.0000 - fn: 34347.0000 - accuracy: 0.7436 - precision: 0.7589 - recall: 0.7213 - auc: 0.8749 - val_loss: 0.6948 - val_tp: 22443.0000 - val_fp: 7226.0000 - val_tn: 54388.0000 - val_fn: 8364.0000 - val_accuracy: 0.7440 - val_precision: 0.7564 - val_recall: 0.7285 - val_auc: 0.8754\n",
            "Epoch 99/200\n",
            "241/241 [==============================] - 18s 74ms/step - loss: 0.6947 - tp: 88903.0000 - fp: 28222.0000 - tn: 218234.0000 - fn: 34325.0000 - accuracy: 0.7437 - precision: 0.7590 - recall: 0.7215 - auc: 0.8750 - val_loss: 0.6947 - val_tp: 22445.0000 - val_fp: 7221.0000 - val_tn: 54393.0000 - val_fn: 8362.0000 - val_accuracy: 0.7441 - val_precision: 0.7566 - val_recall: 0.7286 - val_auc: 0.8756\n",
            "Epoch 100/200\n",
            "241/241 [==============================] - 18s 74ms/step - loss: 0.6945 - tp: 88901.0000 - fp: 28213.0000 - tn: 218243.0000 - fn: 34327.0000 - accuracy: 0.7437 - precision: 0.7591 - recall: 0.7214 - auc: 0.8752 - val_loss: 0.6945 - val_tp: 22452.0000 - val_fp: 7224.0000 - val_tn: 54390.0000 - val_fn: 8355.0000 - val_accuracy: 0.7441 - val_precision: 0.7566 - val_recall: 0.7288 - val_auc: 0.8756\n",
            "Epoch 101/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6943 - tp: 88888.0000 - fp: 28200.0000 - tn: 218256.0000 - fn: 34340.0000 - accuracy: 0.7439 - precision: 0.7592 - recall: 0.7213 - auc: 0.8752 - val_loss: 0.6944 - val_tp: 22469.0000 - val_fp: 7227.0000 - val_tn: 54387.0000 - val_fn: 8338.0000 - val_accuracy: 0.7441 - val_precision: 0.7566 - val_recall: 0.7293 - val_auc: 0.8757\n",
            "Epoch 102/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.6941 - tp: 88906.0000 - fp: 28192.0000 - tn: 218264.0000 - fn: 34322.0000 - accuracy: 0.7440 - precision: 0.7592 - recall: 0.7215 - auc: 0.8754 - val_loss: 0.6942 - val_tp: 22457.0000 - val_fp: 7223.0000 - val_tn: 54391.0000 - val_fn: 8350.0000 - val_accuracy: 0.7443 - val_precision: 0.7566 - val_recall: 0.7290 - val_auc: 0.8758\n",
            "Epoch 103/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6939 - tp: 88907.0000 - fp: 28176.0000 - tn: 218280.0000 - fn: 34321.0000 - accuracy: 0.7441 - precision: 0.7594 - recall: 0.7215 - auc: 0.8755 - val_loss: 0.6940 - val_tp: 22461.0000 - val_fp: 7225.0000 - val_tn: 54389.0000 - val_fn: 8346.0000 - val_accuracy: 0.7444 - val_precision: 0.7566 - val_recall: 0.7291 - val_auc: 0.8759\n",
            "Epoch 104/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.6937 - tp: 88923.0000 - fp: 28164.0000 - tn: 218292.0000 - fn: 34305.0000 - accuracy: 0.7440 - precision: 0.7595 - recall: 0.7216 - auc: 0.8756 - val_loss: 0.6938 - val_tp: 22463.0000 - val_fp: 7225.0000 - val_tn: 54389.0000 - val_fn: 8344.0000 - val_accuracy: 0.7444 - val_precision: 0.7566 - val_recall: 0.7292 - val_auc: 0.8760\n",
            "Epoch 105/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.6935 - tp: 88939.0000 - fp: 28154.0000 - tn: 218302.0000 - fn: 34289.0000 - accuracy: 0.7441 - precision: 0.7596 - recall: 0.7217 - auc: 0.8757 - val_loss: 0.6937 - val_tp: 22472.0000 - val_fp: 7228.0000 - val_tn: 54386.0000 - val_fn: 8335.0000 - val_accuracy: 0.7444 - val_precision: 0.7566 - val_recall: 0.7294 - val_auc: 0.8761\n",
            "Epoch 106/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.6934 - tp: 88954.0000 - fp: 28157.0000 - tn: 218299.0000 - fn: 34274.0000 - accuracy: 0.7441 - precision: 0.7596 - recall: 0.7219 - auc: 0.8758 - val_loss: 0.6935 - val_tp: 22484.0000 - val_fp: 7231.0000 - val_tn: 54383.0000 - val_fn: 8323.0000 - val_accuracy: 0.7445 - val_precision: 0.7567 - val_recall: 0.7298 - val_auc: 0.8762\n",
            "Epoch 107/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6932 - tp: 88956.0000 - fp: 28147.0000 - tn: 218309.0000 - fn: 34272.0000 - accuracy: 0.7442 - precision: 0.7596 - recall: 0.7219 - auc: 0.8759 - val_loss: 0.6933 - val_tp: 22479.0000 - val_fp: 7223.0000 - val_tn: 54391.0000 - val_fn: 8328.0000 - val_accuracy: 0.7445 - val_precision: 0.7568 - val_recall: 0.7297 - val_auc: 0.8763\n",
            "Epoch 108/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6930 - tp: 88966.0000 - fp: 28138.0000 - tn: 218318.0000 - fn: 34262.0000 - accuracy: 0.7442 - precision: 0.7597 - recall: 0.7220 - auc: 0.8760 - val_loss: 0.6932 - val_tp: 22498.0000 - val_fp: 7243.0000 - val_tn: 54371.0000 - val_fn: 8309.0000 - val_accuracy: 0.7444 - val_precision: 0.7565 - val_recall: 0.7303 - val_auc: 0.8764\n",
            "Epoch 109/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6928 - tp: 88972.0000 - fp: 28132.0000 - tn: 218324.0000 - fn: 34256.0000 - accuracy: 0.7443 - precision: 0.7598 - recall: 0.7220 - auc: 0.8761 - val_loss: 0.6930 - val_tp: 22496.0000 - val_fp: 7236.0000 - val_tn: 54378.0000 - val_fn: 8311.0000 - val_accuracy: 0.7445 - val_precision: 0.7566 - val_recall: 0.7302 - val_auc: 0.8765\n",
            "Epoch 110/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6926 - tp: 88982.0000 - fp: 28135.0000 - tn: 218321.0000 - fn: 34246.0000 - accuracy: 0.7443 - precision: 0.7598 - recall: 0.7221 - auc: 0.8762 - val_loss: 0.6928 - val_tp: 22511.0000 - val_fp: 7254.0000 - val_tn: 54360.0000 - val_fn: 8296.0000 - val_accuracy: 0.7447 - val_precision: 0.7563 - val_recall: 0.7307 - val_auc: 0.8766\n",
            "Epoch 111/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6924 - tp: 89003.0000 - fp: 28125.0000 - tn: 218331.0000 - fn: 34225.0000 - accuracy: 0.7444 - precision: 0.7599 - recall: 0.7223 - auc: 0.8763 - val_loss: 0.6926 - val_tp: 22500.0000 - val_fp: 7242.0000 - val_tn: 54372.0000 - val_fn: 8307.0000 - val_accuracy: 0.7446 - val_precision: 0.7565 - val_recall: 0.7304 - val_auc: 0.8767\n",
            "Epoch 112/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6923 - tp: 89022.0000 - fp: 28140.0000 - tn: 218316.0000 - fn: 34206.0000 - accuracy: 0.7445 - precision: 0.7598 - recall: 0.7224 - auc: 0.8764 - val_loss: 0.6924 - val_tp: 22504.0000 - val_fp: 7244.0000 - val_tn: 54370.0000 - val_fn: 8303.0000 - val_accuracy: 0.7445 - val_precision: 0.7565 - val_recall: 0.7305 - val_auc: 0.8768\n",
            "Epoch 113/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6921 - tp: 89033.0000 - fp: 28136.0000 - tn: 218320.0000 - fn: 34195.0000 - accuracy: 0.7445 - precision: 0.7599 - recall: 0.7225 - auc: 0.8765 - val_loss: 0.6922 - val_tp: 22502.0000 - val_fp: 7242.0000 - val_tn: 54372.0000 - val_fn: 8305.0000 - val_accuracy: 0.7446 - val_precision: 0.7565 - val_recall: 0.7304 - val_auc: 0.8769\n",
            "Epoch 114/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6919 - tp: 89044.0000 - fp: 28126.0000 - tn: 218330.0000 - fn: 34184.0000 - accuracy: 0.7446 - precision: 0.7600 - recall: 0.7226 - auc: 0.8766 - val_loss: 0.6921 - val_tp: 22490.0000 - val_fp: 7231.0000 - val_tn: 54383.0000 - val_fn: 8317.0000 - val_accuracy: 0.7447 - val_precision: 0.7567 - val_recall: 0.7300 - val_auc: 0.8770\n",
            "Epoch 115/200\n",
            "241/241 [==============================] - 17s 73ms/step - loss: 0.6917 - tp: 89048.0000 - fp: 28116.0000 - tn: 218340.0000 - fn: 34180.0000 - accuracy: 0.7447 - precision: 0.7600 - recall: 0.7226 - auc: 0.8767 - val_loss: 0.6919 - val_tp: 22509.0000 - val_fp: 7247.0000 - val_tn: 54367.0000 - val_fn: 8298.0000 - val_accuracy: 0.7448 - val_precision: 0.7565 - val_recall: 0.7306 - val_auc: 0.8771\n",
            "Epoch 116/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.6915 - tp: 89048.0000 - fp: 28090.0000 - tn: 218366.0000 - fn: 34180.0000 - accuracy: 0.7448 - precision: 0.7602 - recall: 0.7226 - auc: 0.8768 - val_loss: 0.6917 - val_tp: 22492.0000 - val_fp: 7231.0000 - val_tn: 54383.0000 - val_fn: 8315.0000 - val_accuracy: 0.7449 - val_precision: 0.7567 - val_recall: 0.7301 - val_auc: 0.8772\n",
            "Epoch 117/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6913 - tp: 89045.0000 - fp: 28095.0000 - tn: 218361.0000 - fn: 34183.0000 - accuracy: 0.7448 - precision: 0.7602 - recall: 0.7226 - auc: 0.8769 - val_loss: 0.6916 - val_tp: 22493.0000 - val_fp: 7225.0000 - val_tn: 54389.0000 - val_fn: 8314.0000 - val_accuracy: 0.7448 - val_precision: 0.7569 - val_recall: 0.7301 - val_auc: 0.8773\n",
            "Epoch 118/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.6911 - tp: 89048.0000 - fp: 28070.0000 - tn: 218386.0000 - fn: 34180.0000 - accuracy: 0.7449 - precision: 0.7603 - recall: 0.7226 - auc: 0.8770 - val_loss: 0.6914 - val_tp: 22495.0000 - val_fp: 7232.0000 - val_tn: 54382.0000 - val_fn: 8312.0000 - val_accuracy: 0.7450 - val_precision: 0.7567 - val_recall: 0.7302 - val_auc: 0.8774\n",
            "Epoch 119/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.6910 - tp: 89064.0000 - fp: 28055.0000 - tn: 218401.0000 - fn: 34164.0000 - accuracy: 0.7451 - precision: 0.7605 - recall: 0.7228 - auc: 0.8771 - val_loss: 0.6912 - val_tp: 22499.0000 - val_fp: 7231.0000 - val_tn: 54383.0000 - val_fn: 8308.0000 - val_accuracy: 0.7449 - val_precision: 0.7568 - val_recall: 0.7303 - val_auc: 0.8775\n",
            "Epoch 120/200\n",
            "241/241 [==============================] - 18s 74ms/step - loss: 0.6908 - tp: 89076.0000 - fp: 28044.0000 - tn: 218412.0000 - fn: 34152.0000 - accuracy: 0.7451 - precision: 0.7606 - recall: 0.7229 - auc: 0.8772 - val_loss: 0.6910 - val_tp: 22504.0000 - val_fp: 7229.0000 - val_tn: 54385.0000 - val_fn: 8303.0000 - val_accuracy: 0.7450 - val_precision: 0.7569 - val_recall: 0.7305 - val_auc: 0.8776\n",
            "Epoch 121/200\n",
            "241/241 [==============================] - 18s 74ms/step - loss: 0.6906 - tp: 89085.0000 - fp: 28044.0000 - tn: 218412.0000 - fn: 34143.0000 - accuracy: 0.7451 - precision: 0.7606 - recall: 0.7229 - auc: 0.8773 - val_loss: 0.6908 - val_tp: 22522.0000 - val_fp: 7245.0000 - val_tn: 54369.0000 - val_fn: 8285.0000 - val_accuracy: 0.7452 - val_precision: 0.7566 - val_recall: 0.7311 - val_auc: 0.8777\n",
            "Epoch 122/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.6904 - tp: 89104.0000 - fp: 28042.0000 - tn: 218414.0000 - fn: 34124.0000 - accuracy: 0.7452 - precision: 0.7606 - recall: 0.7231 - auc: 0.8774 - val_loss: 0.6907 - val_tp: 22523.0000 - val_fp: 7251.0000 - val_tn: 54363.0000 - val_fn: 8284.0000 - val_accuracy: 0.7452 - val_precision: 0.7565 - val_recall: 0.7311 - val_auc: 0.8778\n",
            "Epoch 123/200\n",
            "241/241 [==============================] - 17s 73ms/step - loss: 0.6902 - tp: 89102.0000 - fp: 28027.0000 - tn: 218429.0000 - fn: 34126.0000 - accuracy: 0.7453 - precision: 0.7607 - recall: 0.7231 - auc: 0.8775 - val_loss: 0.6905 - val_tp: 22522.0000 - val_fp: 7249.0000 - val_tn: 54365.0000 - val_fn: 8285.0000 - val_accuracy: 0.7451 - val_precision: 0.7565 - val_recall: 0.7311 - val_auc: 0.8779\n",
            "Epoch 124/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6901 - tp: 89113.0000 - fp: 28037.0000 - tn: 218419.0000 - fn: 34115.0000 - accuracy: 0.7454 - precision: 0.7607 - recall: 0.7232 - auc: 0.8776 - val_loss: 0.6904 - val_tp: 22512.0000 - val_fp: 7247.0000 - val_tn: 54367.0000 - val_fn: 8295.0000 - val_accuracy: 0.7452 - val_precision: 0.7565 - val_recall: 0.7307 - val_auc: 0.8780\n",
            "Epoch 125/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6899 - tp: 89124.0000 - fp: 28028.0000 - tn: 218428.0000 - fn: 34104.0000 - accuracy: 0.7455 - precision: 0.7608 - recall: 0.7232 - auc: 0.8777 - val_loss: 0.6902 - val_tp: 22518.0000 - val_fp: 7244.0000 - val_tn: 54370.0000 - val_fn: 8289.0000 - val_accuracy: 0.7453 - val_precision: 0.7566 - val_recall: 0.7309 - val_auc: 0.8781\n",
            "Epoch 126/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6897 - tp: 89138.0000 - fp: 28026.0000 - tn: 218430.0000 - fn: 34090.0000 - accuracy: 0.7456 - precision: 0.7608 - recall: 0.7234 - auc: 0.8778 - val_loss: 0.6901 - val_tp: 22525.0000 - val_fp: 7249.0000 - val_tn: 54365.0000 - val_fn: 8282.0000 - val_accuracy: 0.7453 - val_precision: 0.7565 - val_recall: 0.7312 - val_auc: 0.8781\n",
            "Epoch 127/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6895 - tp: 89149.0000 - fp: 28003.0000 - tn: 218453.0000 - fn: 34079.0000 - accuracy: 0.7456 - precision: 0.7610 - recall: 0.7234 - auc: 0.8779 - val_loss: 0.6899 - val_tp: 22521.0000 - val_fp: 7248.0000 - val_tn: 54366.0000 - val_fn: 8286.0000 - val_accuracy: 0.7453 - val_precision: 0.7565 - val_recall: 0.7310 - val_auc: 0.8782\n",
            "Epoch 128/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6893 - tp: 89146.0000 - fp: 27987.0000 - tn: 218469.0000 - fn: 34082.0000 - accuracy: 0.7456 - precision: 0.7611 - recall: 0.7234 - auc: 0.8780 - val_loss: 0.6898 - val_tp: 22519.0000 - val_fp: 7244.0000 - val_tn: 54370.0000 - val_fn: 8288.0000 - val_accuracy: 0.7454 - val_precision: 0.7566 - val_recall: 0.7310 - val_auc: 0.8784\n",
            "Epoch 129/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6892 - tp: 89158.0000 - fp: 27956.0000 - tn: 218500.0000 - fn: 34070.0000 - accuracy: 0.7457 - precision: 0.7613 - recall: 0.7235 - auc: 0.8780 - val_loss: 0.6896 - val_tp: 22522.0000 - val_fp: 7249.0000 - val_tn: 54365.0000 - val_fn: 8285.0000 - val_accuracy: 0.7455 - val_precision: 0.7565 - val_recall: 0.7311 - val_auc: 0.8784\n",
            "Epoch 130/200\n",
            "241/241 [==============================] - 18s 74ms/step - loss: 0.6890 - tp: 89164.0000 - fp: 27959.0000 - tn: 218497.0000 - fn: 34064.0000 - accuracy: 0.7456 - precision: 0.7613 - recall: 0.7236 - auc: 0.8781 - val_loss: 0.6895 - val_tp: 22524.0000 - val_fp: 7252.0000 - val_tn: 54362.0000 - val_fn: 8283.0000 - val_accuracy: 0.7455 - val_precision: 0.7564 - val_recall: 0.7311 - val_auc: 0.8785\n",
            "Epoch 131/200\n",
            "241/241 [==============================] - 18s 73ms/step - loss: 0.6888 - tp: 89174.0000 - fp: 27946.0000 - tn: 218510.0000 - fn: 34054.0000 - accuracy: 0.7456 - precision: 0.7614 - recall: 0.7237 - auc: 0.8782 - val_loss: 0.6895 - val_tp: 22532.0000 - val_fp: 7271.0000 - val_tn: 54343.0000 - val_fn: 8275.0000 - val_accuracy: 0.7456 - val_precision: 0.7560 - val_recall: 0.7314 - val_auc: 0.8785\n",
            "Epoch 132/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6887 - tp: 89182.0000 - fp: 27943.0000 - tn: 218513.0000 - fn: 34046.0000 - accuracy: 0.7457 - precision: 0.7614 - recall: 0.7237 - auc: 0.8783 - val_loss: 0.6892 - val_tp: 22529.0000 - val_fp: 7262.0000 - val_tn: 54352.0000 - val_fn: 8278.0000 - val_accuracy: 0.7457 - val_precision: 0.7562 - val_recall: 0.7313 - val_auc: 0.8786\n",
            "Epoch 133/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6885 - tp: 89182.0000 - fp: 27928.0000 - tn: 218528.0000 - fn: 34046.0000 - accuracy: 0.7457 - precision: 0.7615 - recall: 0.7237 - auc: 0.8784 - val_loss: 0.6890 - val_tp: 22526.0000 - val_fp: 7259.0000 - val_tn: 54355.0000 - val_fn: 8281.0000 - val_accuracy: 0.7458 - val_precision: 0.7563 - val_recall: 0.7312 - val_auc: 0.8788\n",
            "Epoch 134/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6883 - tp: 89186.0000 - fp: 27906.0000 - tn: 218550.0000 - fn: 34042.0000 - accuracy: 0.7456 - precision: 0.7617 - recall: 0.7237 - auc: 0.8785 - val_loss: 0.6889 - val_tp: 22526.0000 - val_fp: 7258.0000 - val_tn: 54356.0000 - val_fn: 8281.0000 - val_accuracy: 0.7459 - val_precision: 0.7563 - val_recall: 0.7312 - val_auc: 0.8789\n",
            "Epoch 135/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6881 - tp: 89190.0000 - fp: 27899.0000 - tn: 218557.0000 - fn: 34038.0000 - accuracy: 0.7457 - precision: 0.7617 - recall: 0.7238 - auc: 0.8786 - val_loss: 0.6887 - val_tp: 22533.0000 - val_fp: 7257.0000 - val_tn: 54357.0000 - val_fn: 8274.0000 - val_accuracy: 0.7459 - val_precision: 0.7564 - val_recall: 0.7314 - val_auc: 0.8789\n",
            "Epoch 136/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6880 - tp: 89198.0000 - fp: 27893.0000 - tn: 218563.0000 - fn: 34030.0000 - accuracy: 0.7458 - precision: 0.7618 - recall: 0.7238 - auc: 0.8787 - val_loss: 0.6885 - val_tp: 22538.0000 - val_fp: 7259.0000 - val_tn: 54355.0000 - val_fn: 8269.0000 - val_accuracy: 0.7460 - val_precision: 0.7564 - val_recall: 0.7316 - val_auc: 0.8791\n",
            "Epoch 137/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6878 - tp: 89200.0000 - fp: 27876.0000 - tn: 218580.0000 - fn: 34028.0000 - accuracy: 0.7460 - precision: 0.7619 - recall: 0.7239 - auc: 0.8788 - val_loss: 0.6884 - val_tp: 22531.0000 - val_fp: 7246.0000 - val_tn: 54368.0000 - val_fn: 8276.0000 - val_accuracy: 0.7460 - val_precision: 0.7567 - val_recall: 0.7314 - val_auc: 0.8791\n",
            "Epoch 138/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6876 - tp: 89209.0000 - fp: 27883.0000 - tn: 218573.0000 - fn: 34019.0000 - accuracy: 0.7460 - precision: 0.7619 - recall: 0.7239 - auc: 0.8789 - val_loss: 0.6883 - val_tp: 22536.0000 - val_fp: 7246.0000 - val_tn: 54368.0000 - val_fn: 8271.0000 - val_accuracy: 0.7462 - val_precision: 0.7567 - val_recall: 0.7315 - val_auc: 0.8791\n",
            "Epoch 139/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6874 - tp: 89226.0000 - fp: 27887.0000 - tn: 218569.0000 - fn: 34002.0000 - accuracy: 0.7462 - precision: 0.7619 - recall: 0.7241 - auc: 0.8790 - val_loss: 0.6881 - val_tp: 22535.0000 - val_fp: 7240.0000 - val_tn: 54374.0000 - val_fn: 8272.0000 - val_accuracy: 0.7461 - val_precision: 0.7568 - val_recall: 0.7315 - val_auc: 0.8792\n",
            "Epoch 140/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6873 - tp: 89246.0000 - fp: 27877.0000 - tn: 218579.0000 - fn: 33982.0000 - accuracy: 0.7462 - precision: 0.7620 - recall: 0.7242 - auc: 0.8790 - val_loss: 0.6880 - val_tp: 22532.0000 - val_fp: 7234.0000 - val_tn: 54380.0000 - val_fn: 8275.0000 - val_accuracy: 0.7462 - val_precision: 0.7570 - val_recall: 0.7314 - val_auc: 0.8793\n",
            "Epoch 141/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6871 - tp: 89248.0000 - fp: 27859.0000 - tn: 218597.0000 - fn: 33980.0000 - accuracy: 0.7463 - precision: 0.7621 - recall: 0.7243 - auc: 0.8791 - val_loss: 0.6877 - val_tp: 22533.0000 - val_fp: 7232.0000 - val_tn: 54382.0000 - val_fn: 8274.0000 - val_accuracy: 0.7460 - val_precision: 0.7570 - val_recall: 0.7314 - val_auc: 0.8795\n",
            "Epoch 142/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6870 - tp: 89252.0000 - fp: 27844.0000 - tn: 218612.0000 - fn: 33976.0000 - accuracy: 0.7464 - precision: 0.7622 - recall: 0.7243 - auc: 0.8792 - val_loss: 0.6876 - val_tp: 22532.0000 - val_fp: 7225.0000 - val_tn: 54389.0000 - val_fn: 8275.0000 - val_accuracy: 0.7461 - val_precision: 0.7572 - val_recall: 0.7314 - val_auc: 0.8795\n",
            "Epoch 143/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.6867 - tp: 89265.0000 - fp: 27842.0000 - tn: 218614.0000 - fn: 33963.0000 - accuracy: 0.7464 - precision: 0.7623 - recall: 0.7244 - auc: 0.8793 - val_loss: 0.6876 - val_tp: 22539.0000 - val_fp: 7235.0000 - val_tn: 54379.0000 - val_fn: 8268.0000 - val_accuracy: 0.7461 - val_precision: 0.7570 - val_recall: 0.7316 - val_auc: 0.8795\n",
            "Epoch 144/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.6866 - tp: 89285.0000 - fp: 27841.0000 - tn: 218615.0000 - fn: 33943.0000 - accuracy: 0.7465 - precision: 0.7623 - recall: 0.7246 - auc: 0.8794 - val_loss: 0.6876 - val_tp: 22532.0000 - val_fp: 7228.0000 - val_tn: 54386.0000 - val_fn: 8275.0000 - val_accuracy: 0.7461 - val_precision: 0.7571 - val_recall: 0.7314 - val_auc: 0.8795\n",
            "Epoch 145/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.6864 - tp: 89267.0000 - fp: 27826.0000 - tn: 218630.0000 - fn: 33961.0000 - accuracy: 0.7465 - precision: 0.7624 - recall: 0.7244 - auc: 0.8795 - val_loss: 0.6873 - val_tp: 22545.0000 - val_fp: 7234.0000 - val_tn: 54380.0000 - val_fn: 8262.0000 - val_accuracy: 0.7461 - val_precision: 0.7571 - val_recall: 0.7318 - val_auc: 0.8797\n",
            "Epoch 146/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.6862 - tp: 89296.0000 - fp: 27814.0000 - tn: 218642.0000 - fn: 33932.0000 - accuracy: 0.7465 - precision: 0.7625 - recall: 0.7246 - auc: 0.8796 - val_loss: 0.6872 - val_tp: 22544.0000 - val_fp: 7233.0000 - val_tn: 54381.0000 - val_fn: 8263.0000 - val_accuracy: 0.7460 - val_precision: 0.7571 - val_recall: 0.7318 - val_auc: 0.8798\n",
            "Epoch 147/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6861 - tp: 89301.0000 - fp: 27808.0000 - tn: 218648.0000 - fn: 33927.0000 - accuracy: 0.7465 - precision: 0.7625 - recall: 0.7247 - auc: 0.8797 - val_loss: 0.6870 - val_tp: 22543.0000 - val_fp: 7227.0000 - val_tn: 54387.0000 - val_fn: 8264.0000 - val_accuracy: 0.7460 - val_precision: 0.7572 - val_recall: 0.7317 - val_auc: 0.8799\n",
            "Epoch 148/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6859 - tp: 89303.0000 - fp: 27781.0000 - tn: 218675.0000 - fn: 33925.0000 - accuracy: 0.7466 - precision: 0.7627 - recall: 0.7247 - auc: 0.8797 - val_loss: 0.6870 - val_tp: 22533.0000 - val_fp: 7227.0000 - val_tn: 54387.0000 - val_fn: 8274.0000 - val_accuracy: 0.7462 - val_precision: 0.7572 - val_recall: 0.7314 - val_auc: 0.8799\n",
            "Epoch 149/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6857 - tp: 89317.0000 - fp: 27772.0000 - tn: 218684.0000 - fn: 33911.0000 - accuracy: 0.7468 - precision: 0.7628 - recall: 0.7248 - auc: 0.8798 - val_loss: 0.6870 - val_tp: 22543.0000 - val_fp: 7231.0000 - val_tn: 54383.0000 - val_fn: 8264.0000 - val_accuracy: 0.7463 - val_precision: 0.7571 - val_recall: 0.7317 - val_auc: 0.8799\n",
            "Epoch 150/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6855 - tp: 89318.0000 - fp: 27768.0000 - tn: 218688.0000 - fn: 33910.0000 - accuracy: 0.7468 - precision: 0.7628 - recall: 0.7248 - auc: 0.8799 - val_loss: 0.6868 - val_tp: 22547.0000 - val_fp: 7233.0000 - val_tn: 54381.0000 - val_fn: 8260.0000 - val_accuracy: 0.7463 - val_precision: 0.7571 - val_recall: 0.7319 - val_auc: 0.8800\n",
            "Epoch 151/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6854 - tp: 89343.0000 - fp: 27756.0000 - tn: 218700.0000 - fn: 33885.0000 - accuracy: 0.7469 - precision: 0.7630 - recall: 0.7250 - auc: 0.8800 - val_loss: 0.6868 - val_tp: 22549.0000 - val_fp: 7234.0000 - val_tn: 54380.0000 - val_fn: 8258.0000 - val_accuracy: 0.7464 - val_precision: 0.7571 - val_recall: 0.7319 - val_auc: 0.8800\n",
            "Epoch 152/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6852 - tp: 89346.0000 - fp: 27762.0000 - tn: 218694.0000 - fn: 33882.0000 - accuracy: 0.7469 - precision: 0.7629 - recall: 0.7250 - auc: 0.8801 - val_loss: 0.6866 - val_tp: 22549.0000 - val_fp: 7226.0000 - val_tn: 54388.0000 - val_fn: 8258.0000 - val_accuracy: 0.7464 - val_precision: 0.7573 - val_recall: 0.7319 - val_auc: 0.8801\n",
            "Epoch 153/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6851 - tp: 89357.0000 - fp: 27744.0000 - tn: 218712.0000 - fn: 33871.0000 - accuracy: 0.7470 - precision: 0.7631 - recall: 0.7251 - auc: 0.8802 - val_loss: 0.6866 - val_tp: 22553.0000 - val_fp: 7230.0000 - val_tn: 54384.0000 - val_fn: 8254.0000 - val_accuracy: 0.7465 - val_precision: 0.7572 - val_recall: 0.7321 - val_auc: 0.8801\n",
            "Epoch 154/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6849 - tp: 89360.0000 - fp: 27737.0000 - tn: 218719.0000 - fn: 33868.0000 - accuracy: 0.7470 - precision: 0.7631 - recall: 0.7252 - auc: 0.8803 - val_loss: 0.6864 - val_tp: 22552.0000 - val_fp: 7226.0000 - val_tn: 54388.0000 - val_fn: 8255.0000 - val_accuracy: 0.7466 - val_precision: 0.7573 - val_recall: 0.7320 - val_auc: 0.8803\n",
            "Epoch 155/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6847 - tp: 89368.0000 - fp: 27733.0000 - tn: 218723.0000 - fn: 33860.0000 - accuracy: 0.7471 - precision: 0.7632 - recall: 0.7252 - auc: 0.8803 - val_loss: 0.6864 - val_tp: 22560.0000 - val_fp: 7229.0000 - val_tn: 54385.0000 - val_fn: 8247.0000 - val_accuracy: 0.7467 - val_precision: 0.7573 - val_recall: 0.7323 - val_auc: 0.8803\n",
            "Epoch 156/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6846 - tp: 89365.0000 - fp: 27731.0000 - tn: 218725.0000 - fn: 33863.0000 - accuracy: 0.7471 - precision: 0.7632 - recall: 0.7252 - auc: 0.8804 - val_loss: 0.6862 - val_tp: 22550.0000 - val_fp: 7208.0000 - val_tn: 54406.0000 - val_fn: 8257.0000 - val_accuracy: 0.7466 - val_precision: 0.7578 - val_recall: 0.7320 - val_auc: 0.8803\n",
            "Epoch 157/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6844 - tp: 89379.0000 - fp: 27727.0000 - tn: 218729.0000 - fn: 33849.0000 - accuracy: 0.7473 - precision: 0.7632 - recall: 0.7253 - auc: 0.8805 - val_loss: 0.6861 - val_tp: 22554.0000 - val_fp: 7212.0000 - val_tn: 54402.0000 - val_fn: 8253.0000 - val_accuracy: 0.7467 - val_precision: 0.7577 - val_recall: 0.7321 - val_auc: 0.8804\n",
            "Epoch 158/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6842 - tp: 89381.0000 - fp: 27722.0000 - tn: 218734.0000 - fn: 33847.0000 - accuracy: 0.7473 - precision: 0.7633 - recall: 0.7253 - auc: 0.8806 - val_loss: 0.6856 - val_tp: 22556.0000 - val_fp: 7206.0000 - val_tn: 54408.0000 - val_fn: 8251.0000 - val_accuracy: 0.7467 - val_precision: 0.7579 - val_recall: 0.7322 - val_auc: 0.8806\n",
            "Epoch 159/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6841 - tp: 89380.0000 - fp: 27700.0000 - tn: 218756.0000 - fn: 33848.0000 - accuracy: 0.7473 - precision: 0.7634 - recall: 0.7253 - auc: 0.8807 - val_loss: 0.6856 - val_tp: 22552.0000 - val_fp: 7203.0000 - val_tn: 54411.0000 - val_fn: 8255.0000 - val_accuracy: 0.7467 - val_precision: 0.7579 - val_recall: 0.7320 - val_auc: 0.8807\n",
            "Epoch 160/200\n",
            "241/241 [==============================] - 17s 69ms/step - loss: 0.6839 - tp: 89388.0000 - fp: 27693.0000 - tn: 218763.0000 - fn: 33840.0000 - accuracy: 0.7474 - precision: 0.7635 - recall: 0.7254 - auc: 0.8807 - val_loss: 0.6854 - val_tp: 22554.0000 - val_fp: 7205.0000 - val_tn: 54409.0000 - val_fn: 8253.0000 - val_accuracy: 0.7466 - val_precision: 0.7579 - val_recall: 0.7321 - val_auc: 0.8808\n",
            "Epoch 161/200\n",
            "241/241 [==============================] - 17s 69ms/step - loss: 0.6838 - tp: 89385.0000 - fp: 27690.0000 - tn: 218766.0000 - fn: 33843.0000 - accuracy: 0.7475 - precision: 0.7635 - recall: 0.7254 - auc: 0.8808 - val_loss: 0.6854 - val_tp: 22555.0000 - val_fp: 7208.0000 - val_tn: 54406.0000 - val_fn: 8252.0000 - val_accuracy: 0.7467 - val_precision: 0.7578 - val_recall: 0.7321 - val_auc: 0.8808\n",
            "Epoch 162/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.6836 - tp: 89387.0000 - fp: 27684.0000 - tn: 218772.0000 - fn: 33841.0000 - accuracy: 0.7475 - precision: 0.7635 - recall: 0.7254 - auc: 0.8809 - val_loss: 0.6853 - val_tp: 22550.0000 - val_fp: 7200.0000 - val_tn: 54414.0000 - val_fn: 8257.0000 - val_accuracy: 0.7469 - val_precision: 0.7580 - val_recall: 0.7320 - val_auc: 0.8808\n",
            "Epoch 163/200\n",
            "241/241 [==============================] - 17s 69ms/step - loss: 0.6834 - tp: 89397.0000 - fp: 27675.0000 - tn: 218781.0000 - fn: 33831.0000 - accuracy: 0.7477 - precision: 0.7636 - recall: 0.7255 - auc: 0.8810 - val_loss: 0.6852 - val_tp: 22557.0000 - val_fp: 7203.0000 - val_tn: 54411.0000 - val_fn: 8250.0000 - val_accuracy: 0.7470 - val_precision: 0.7580 - val_recall: 0.7322 - val_auc: 0.8809\n",
            "Epoch 164/200\n",
            "241/241 [==============================] - 16s 68ms/step - loss: 0.6833 - tp: 89407.0000 - fp: 27683.0000 - tn: 218773.0000 - fn: 33821.0000 - accuracy: 0.7477 - precision: 0.7636 - recall: 0.7255 - auc: 0.8811 - val_loss: 0.6850 - val_tp: 22556.0000 - val_fp: 7202.0000 - val_tn: 54412.0000 - val_fn: 8251.0000 - val_accuracy: 0.7470 - val_precision: 0.7580 - val_recall: 0.7322 - val_auc: 0.8810\n",
            "Epoch 165/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6831 - tp: 89406.0000 - fp: 27682.0000 - tn: 218774.0000 - fn: 33822.0000 - accuracy: 0.7479 - precision: 0.7636 - recall: 0.7255 - auc: 0.8812 - val_loss: 0.6849 - val_tp: 22559.0000 - val_fp: 7205.0000 - val_tn: 54409.0000 - val_fn: 8248.0000 - val_accuracy: 0.7470 - val_precision: 0.7579 - val_recall: 0.7323 - val_auc: 0.8810\n",
            "Epoch 166/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6830 - tp: 89419.0000 - fp: 27668.0000 - tn: 218788.0000 - fn: 33809.0000 - accuracy: 0.7479 - precision: 0.7637 - recall: 0.7256 - auc: 0.8812 - val_loss: 0.6849 - val_tp: 22558.0000 - val_fp: 7199.0000 - val_tn: 54415.0000 - val_fn: 8249.0000 - val_accuracy: 0.7471 - val_precision: 0.7581 - val_recall: 0.7322 - val_auc: 0.8811\n",
            "Epoch 167/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6828 - tp: 89437.0000 - fp: 27660.0000 - tn: 218796.0000 - fn: 33791.0000 - accuracy: 0.7479 - precision: 0.7638 - recall: 0.7258 - auc: 0.8813 - val_loss: 0.6846 - val_tp: 22567.0000 - val_fp: 7202.0000 - val_tn: 54412.0000 - val_fn: 8240.0000 - val_accuracy: 0.7472 - val_precision: 0.7581 - val_recall: 0.7325 - val_auc: 0.8812\n",
            "Epoch 168/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6825 - tp: 89460.0000 - fp: 27635.0000 - tn: 218821.0000 - fn: 33768.0000 - accuracy: 0.7480 - precision: 0.7640 - recall: 0.7260 - auc: 0.8814 - val_loss: 0.6839 - val_tp: 22576.0000 - val_fp: 7185.0000 - val_tn: 54429.0000 - val_fn: 8231.0000 - val_accuracy: 0.7472 - val_precision: 0.7586 - val_recall: 0.7328 - val_auc: 0.8814\n",
            "Epoch 169/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6823 - tp: 89470.0000 - fp: 27620.0000 - tn: 218836.0000 - fn: 33758.0000 - accuracy: 0.7483 - precision: 0.7641 - recall: 0.7261 - auc: 0.8815 - val_loss: 0.6840 - val_tp: 22574.0000 - val_fp: 7178.0000 - val_tn: 54436.0000 - val_fn: 8233.0000 - val_accuracy: 0.7473 - val_precision: 0.7587 - val_recall: 0.7328 - val_auc: 0.8814\n",
            "Epoch 170/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6821 - tp: 89476.0000 - fp: 27613.0000 - tn: 218843.0000 - fn: 33752.0000 - accuracy: 0.7484 - precision: 0.7642 - recall: 0.7261 - auc: 0.8816 - val_loss: 0.6838 - val_tp: 22573.0000 - val_fp: 7177.0000 - val_tn: 54437.0000 - val_fn: 8234.0000 - val_accuracy: 0.7472 - val_precision: 0.7588 - val_recall: 0.7327 - val_auc: 0.8815\n",
            "Epoch 171/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.6820 - tp: 89483.0000 - fp: 27612.0000 - tn: 218844.0000 - fn: 33745.0000 - accuracy: 0.7484 - precision: 0.7642 - recall: 0.7262 - auc: 0.8817 - val_loss: 0.6837 - val_tp: 22580.0000 - val_fp: 7188.0000 - val_tn: 54426.0000 - val_fn: 8227.0000 - val_accuracy: 0.7473 - val_precision: 0.7585 - val_recall: 0.7330 - val_auc: 0.8816\n",
            "Epoch 172/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6818 - tp: 89492.0000 - fp: 27591.0000 - tn: 218865.0000 - fn: 33736.0000 - accuracy: 0.7485 - precision: 0.7643 - recall: 0.7262 - auc: 0.8817 - val_loss: 0.6835 - val_tp: 22581.0000 - val_fp: 7194.0000 - val_tn: 54420.0000 - val_fn: 8226.0000 - val_accuracy: 0.7474 - val_precision: 0.7584 - val_recall: 0.7330 - val_auc: 0.8817\n",
            "Epoch 173/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6817 - tp: 89509.0000 - fp: 27585.0000 - tn: 218871.0000 - fn: 33719.0000 - accuracy: 0.7486 - precision: 0.7644 - recall: 0.7264 - auc: 0.8818 - val_loss: 0.6835 - val_tp: 22583.0000 - val_fp: 7190.0000 - val_tn: 54424.0000 - val_fn: 8224.0000 - val_accuracy: 0.7473 - val_precision: 0.7585 - val_recall: 0.7330 - val_auc: 0.8817\n",
            "Epoch 174/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6815 - tp: 89515.0000 - fp: 27578.0000 - tn: 218878.0000 - fn: 33713.0000 - accuracy: 0.7484 - precision: 0.7645 - recall: 0.7264 - auc: 0.8819 - val_loss: 0.6832 - val_tp: 22581.0000 - val_fp: 7195.0000 - val_tn: 54419.0000 - val_fn: 8226.0000 - val_accuracy: 0.7474 - val_precision: 0.7584 - val_recall: 0.7330 - val_auc: 0.8819\n",
            "Epoch 175/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6813 - tp: 89513.0000 - fp: 27562.0000 - tn: 218894.0000 - fn: 33715.0000 - accuracy: 0.7486 - precision: 0.7646 - recall: 0.7264 - auc: 0.8820 - val_loss: 0.6832 - val_tp: 22582.0000 - val_fp: 7184.0000 - val_tn: 54430.0000 - val_fn: 8225.0000 - val_accuracy: 0.7473 - val_precision: 0.7587 - val_recall: 0.7330 - val_auc: 0.8819\n",
            "Epoch 176/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6811 - tp: 89527.0000 - fp: 27550.0000 - tn: 218906.0000 - fn: 33701.0000 - accuracy: 0.7488 - precision: 0.7647 - recall: 0.7265 - auc: 0.8821 - val_loss: 0.6828 - val_tp: 22581.0000 - val_fp: 7191.0000 - val_tn: 54423.0000 - val_fn: 8226.0000 - val_accuracy: 0.7472 - val_precision: 0.7585 - val_recall: 0.7330 - val_auc: 0.8821\n",
            "Epoch 177/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6810 - tp: 89504.0000 - fp: 27552.0000 - tn: 218904.0000 - fn: 33724.0000 - accuracy: 0.7488 - precision: 0.7646 - recall: 0.7263 - auc: 0.8822 - val_loss: 0.6828 - val_tp: 22586.0000 - val_fp: 7196.0000 - val_tn: 54418.0000 - val_fn: 8221.0000 - val_accuracy: 0.7473 - val_precision: 0.7584 - val_recall: 0.7331 - val_auc: 0.8822\n",
            "Epoch 178/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.6808 - tp: 89517.0000 - fp: 27562.0000 - tn: 218894.0000 - fn: 33711.0000 - accuracy: 0.7489 - precision: 0.7646 - recall: 0.7264 - auc: 0.8822 - val_loss: 0.6830 - val_tp: 22573.0000 - val_fp: 7176.0000 - val_tn: 54438.0000 - val_fn: 8234.0000 - val_accuracy: 0.7472 - val_precision: 0.7588 - val_recall: 0.7327 - val_auc: 0.8821\n",
            "Epoch 179/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.6806 - tp: 89543.0000 - fp: 27550.0000 - tn: 218906.0000 - fn: 33685.0000 - accuracy: 0.7489 - precision: 0.7647 - recall: 0.7266 - auc: 0.8823 - val_loss: 0.6826 - val_tp: 22593.0000 - val_fp: 7179.0000 - val_tn: 54435.0000 - val_fn: 8214.0000 - val_accuracy: 0.7473 - val_precision: 0.7589 - val_recall: 0.7334 - val_auc: 0.8822\n",
            "Epoch 180/200\n",
            "241/241 [==============================] - 17s 69ms/step - loss: 0.6804 - tp: 89577.0000 - fp: 27549.0000 - tn: 218907.0000 - fn: 33651.0000 - accuracy: 0.7489 - precision: 0.7648 - recall: 0.7269 - auc: 0.8824 - val_loss: 0.6828 - val_tp: 22595.0000 - val_fp: 7182.0000 - val_tn: 54432.0000 - val_fn: 8212.0000 - val_accuracy: 0.7472 - val_precision: 0.7588 - val_recall: 0.7334 - val_auc: 0.8822\n",
            "Epoch 181/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.6802 - tp: 89588.0000 - fp: 27537.0000 - tn: 218919.0000 - fn: 33640.0000 - accuracy: 0.7490 - precision: 0.7649 - recall: 0.7270 - auc: 0.8825 - val_loss: 0.6827 - val_tp: 22595.0000 - val_fp: 7180.0000 - val_tn: 54434.0000 - val_fn: 8212.0000 - val_accuracy: 0.7472 - val_precision: 0.7589 - val_recall: 0.7334 - val_auc: 0.8823\n",
            "Epoch 182/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6799 - tp: 89576.0000 - fp: 27507.0000 - tn: 218949.0000 - fn: 33652.0000 - accuracy: 0.7489 - precision: 0.7651 - recall: 0.7269 - auc: 0.8826 - val_loss: 0.6823 - val_tp: 22582.0000 - val_fp: 7152.0000 - val_tn: 54462.0000 - val_fn: 8225.0000 - val_accuracy: 0.7475 - val_precision: 0.7595 - val_recall: 0.7330 - val_auc: 0.8824\n",
            "Epoch 183/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6797 - tp: 89593.0000 - fp: 27482.0000 - tn: 218974.0000 - fn: 33635.0000 - accuracy: 0.7493 - precision: 0.7653 - recall: 0.7271 - auc: 0.8827 - val_loss: 0.6829 - val_tp: 22569.0000 - val_fp: 7131.0000 - val_tn: 54483.0000 - val_fn: 8238.0000 - val_accuracy: 0.7476 - val_precision: 0.7599 - val_recall: 0.7326 - val_auc: 0.8821\n",
            "Epoch 184/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6795 - tp: 89590.0000 - fp: 27477.0000 - tn: 218979.0000 - fn: 33638.0000 - accuracy: 0.7493 - precision: 0.7653 - recall: 0.7270 - auc: 0.8828 - val_loss: 0.6829 - val_tp: 22569.0000 - val_fp: 7121.0000 - val_tn: 54493.0000 - val_fn: 8238.0000 - val_accuracy: 0.7478 - val_precision: 0.7602 - val_recall: 0.7326 - val_auc: 0.8821\n",
            "Epoch 185/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6793 - tp: 89605.0000 - fp: 27486.0000 - tn: 218970.0000 - fn: 33623.0000 - accuracy: 0.7492 - precision: 0.7653 - recall: 0.7271 - auc: 0.8829 - val_loss: 0.6824 - val_tp: 22577.0000 - val_fp: 7125.0000 - val_tn: 54489.0000 - val_fn: 8230.0000 - val_accuracy: 0.7479 - val_precision: 0.7601 - val_recall: 0.7329 - val_auc: 0.8823\n",
            "Epoch 186/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6790 - tp: 89601.0000 - fp: 27456.0000 - tn: 219000.0000 - fn: 33627.0000 - accuracy: 0.7495 - precision: 0.7654 - recall: 0.7271 - auc: 0.8830 - val_loss: 0.6823 - val_tp: 22572.0000 - val_fp: 7117.0000 - val_tn: 54497.0000 - val_fn: 8235.0000 - val_accuracy: 0.7480 - val_precision: 0.7603 - val_recall: 0.7327 - val_auc: 0.8824\n",
            "Epoch 187/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6788 - tp: 89618.0000 - fp: 27441.0000 - tn: 219015.0000 - fn: 33610.0000 - accuracy: 0.7495 - precision: 0.7656 - recall: 0.7273 - auc: 0.8831 - val_loss: 0.6824 - val_tp: 22572.0000 - val_fp: 7099.0000 - val_tn: 54515.0000 - val_fn: 8235.0000 - val_accuracy: 0.7481 - val_precision: 0.7607 - val_recall: 0.7327 - val_auc: 0.8823\n",
            "Epoch 188/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6786 - tp: 89620.0000 - fp: 27446.0000 - tn: 219010.0000 - fn: 33608.0000 - accuracy: 0.7494 - precision: 0.7656 - recall: 0.7273 - auc: 0.8832 - val_loss: 0.6825 - val_tp: 22580.0000 - val_fp: 7101.0000 - val_tn: 54513.0000 - val_fn: 8227.0000 - val_accuracy: 0.7481 - val_precision: 0.7608 - val_recall: 0.7330 - val_auc: 0.8822\n",
            "Epoch 189/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6784 - tp: 89646.0000 - fp: 27422.0000 - tn: 219034.0000 - fn: 33582.0000 - accuracy: 0.7493 - precision: 0.7658 - recall: 0.7275 - auc: 0.8833 - val_loss: 0.6825 - val_tp: 22570.0000 - val_fp: 7082.0000 - val_tn: 54532.0000 - val_fn: 8237.0000 - val_accuracy: 0.7482 - val_precision: 0.7612 - val_recall: 0.7326 - val_auc: 0.8822\n",
            "Epoch 190/200\n",
            "241/241 [==============================] - 17s 72ms/step - loss: 0.6782 - tp: 89643.0000 - fp: 27441.0000 - tn: 219015.0000 - fn: 33585.0000 - accuracy: 0.7494 - precision: 0.7656 - recall: 0.7275 - auc: 0.8834 - val_loss: 0.6827 - val_tp: 22575.0000 - val_fp: 7095.0000 - val_tn: 54519.0000 - val_fn: 8232.0000 - val_accuracy: 0.7482 - val_precision: 0.7609 - val_recall: 0.7328 - val_auc: 0.8822\n",
            "Epoch 191/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6780 - tp: 89656.0000 - fp: 27443.0000 - tn: 219013.0000 - fn: 33572.0000 - accuracy: 0.7495 - precision: 0.7656 - recall: 0.7276 - auc: 0.8835 - val_loss: 0.6822 - val_tp: 22581.0000 - val_fp: 7089.0000 - val_tn: 54525.0000 - val_fn: 8226.0000 - val_accuracy: 0.7483 - val_precision: 0.7611 - val_recall: 0.7330 - val_auc: 0.8824\n",
            "Epoch 192/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6778 - tp: 89672.0000 - fp: 27437.0000 - tn: 219019.0000 - fn: 33556.0000 - accuracy: 0.7496 - precision: 0.7657 - recall: 0.7277 - auc: 0.8836 - val_loss: 0.6822 - val_tp: 22572.0000 - val_fp: 7081.0000 - val_tn: 54533.0000 - val_fn: 8235.0000 - val_accuracy: 0.7484 - val_precision: 0.7612 - val_recall: 0.7327 - val_auc: 0.8823\n",
            "Epoch 193/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6776 - tp: 89670.0000 - fp: 27400.0000 - tn: 219056.0000 - fn: 33558.0000 - accuracy: 0.7496 - precision: 0.7660 - recall: 0.7277 - auc: 0.8837 - val_loss: 0.6816 - val_tp: 22577.0000 - val_fp: 7088.0000 - val_tn: 54526.0000 - val_fn: 8230.0000 - val_accuracy: 0.7485 - val_precision: 0.7611 - val_recall: 0.7329 - val_auc: 0.8827\n",
            "Epoch 194/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6775 - tp: 89686.0000 - fp: 27393.0000 - tn: 219063.0000 - fn: 33542.0000 - accuracy: 0.7497 - precision: 0.7660 - recall: 0.7278 - auc: 0.8838 - val_loss: 0.6813 - val_tp: 22579.0000 - val_fp: 7092.0000 - val_tn: 54522.0000 - val_fn: 8228.0000 - val_accuracy: 0.7484 - val_precision: 0.7610 - val_recall: 0.7329 - val_auc: 0.8828\n",
            "Epoch 195/200\n",
            "241/241 [==============================] - 17s 71ms/step - loss: 0.6773 - tp: 89703.0000 - fp: 27373.0000 - tn: 219083.0000 - fn: 33525.0000 - accuracy: 0.7498 - precision: 0.7662 - recall: 0.7279 - auc: 0.8839 - val_loss: 0.6811 - val_tp: 22582.0000 - val_fp: 7092.0000 - val_tn: 54522.0000 - val_fn: 8225.0000 - val_accuracy: 0.7484 - val_precision: 0.7610 - val_recall: 0.7330 - val_auc: 0.8829\n",
            "Epoch 196/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.6771 - tp: 89701.0000 - fp: 27380.0000 - tn: 219076.0000 - fn: 33527.0000 - accuracy: 0.7499 - precision: 0.7661 - recall: 0.7279 - auc: 0.8840 - val_loss: 0.6807 - val_tp: 22577.0000 - val_fp: 7087.0000 - val_tn: 54527.0000 - val_fn: 8230.0000 - val_accuracy: 0.7486 - val_precision: 0.7611 - val_recall: 0.7329 - val_auc: 0.8831\n",
            "Epoch 197/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.6768 - tp: 89714.0000 - fp: 27344.0000 - tn: 219112.0000 - fn: 33514.0000 - accuracy: 0.7501 - precision: 0.7664 - recall: 0.7280 - auc: 0.8841 - val_loss: 0.6805 - val_tp: 22584.0000 - val_fp: 7090.0000 - val_tn: 54524.0000 - val_fn: 8223.0000 - val_accuracy: 0.7485 - val_precision: 0.7611 - val_recall: 0.7331 - val_auc: 0.8832\n",
            "Epoch 198/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.6767 - tp: 89724.0000 - fp: 27343.0000 - tn: 219113.0000 - fn: 33504.0000 - accuracy: 0.7501 - precision: 0.7664 - recall: 0.7281 - auc: 0.8842 - val_loss: 0.6803 - val_tp: 22581.0000 - val_fp: 7080.0000 - val_tn: 54534.0000 - val_fn: 8226.0000 - val_accuracy: 0.7485 - val_precision: 0.7613 - val_recall: 0.7330 - val_auc: 0.8833\n",
            "Epoch 199/200\n",
            "241/241 [==============================] - 17s 70ms/step - loss: 0.6765 - tp: 89725.0000 - fp: 27349.0000 - tn: 219107.0000 - fn: 33503.0000 - accuracy: 0.7500 - precision: 0.7664 - recall: 0.7281 - auc: 0.8843 - val_loss: 0.6807 - val_tp: 22583.0000 - val_fp: 7086.0000 - val_tn: 54528.0000 - val_fn: 8224.0000 - val_accuracy: 0.7485 - val_precision: 0.7612 - val_recall: 0.7330 - val_auc: 0.8831\n",
            "Epoch 200/200\n",
            "241/241 [==============================] - 18s 74ms/step - loss: 0.6764 - tp: 89732.0000 - fp: 27323.0000 - tn: 219133.0000 - fn: 33496.0000 - accuracy: 0.7503 - precision: 0.7666 - recall: 0.7282 - auc: 0.8843 - val_loss: 0.6804 - val_tp: 22586.0000 - val_fp: 7089.0000 - val_tn: 54525.0000 - val_fn: 8221.0000 - val_accuracy: 0.7487 - val_precision: 0.7611 - val_recall: 0.7331 - val_auc: 0.8833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQPoErO0_XJJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "08a6d02d-e853-484f-9e2e-5542486270bb"
      },
      "source": [
        "#using matplotlib to find the accuracy relation between training and test\n",
        "from matplotlib import pyplot\n",
        "\n",
        "\n",
        "\n",
        "pyplot.plot(history.history['accuracy'],label = 'train')\n",
        "pyplot.plot(history.history['val_accuracy'],label = 'val')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCGUBwBhjIpQFAGOMiVAWAIwxJkL9f4Ou0UcMAc76AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJzPXygV_phg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "38a58385-21c6-4d62-90f1-28591a8d526d"
      },
      "source": [
        "pyplot.plot(history.history['loss'],label = 'train')\n",
        "pyplot.plot(history.history['val_loss'],label = 'val')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU9CLiCQ5Bb2ISJJT0IuIJLn/H5Y7anlebssuAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCnkwlOf_tdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "d9b09117-c3c7-4a7c-f46b-de76a4968ee6"
      },
      "source": [
        "#predict the test data from the trained model\n",
        "for x, y in test_ds.take(1):\n",
        "  print(model.predict(x))\n",
        "  print(y)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.82833475 0.08935418 0.08231111]\n",
            " [0.62438744 0.2568756  0.118737  ]\n",
            " [0.38426247 0.48006815 0.13566943]\n",
            " ...\n",
            " [0.8591848  0.12874027 0.01207489]\n",
            " [0.6825333  0.21529703 0.10216963]\n",
            " [0.6286182  0.16816902 0.20321275]]\n",
            "tf.Tensor(\n",
            "[[1 0 0]\n",
            " [0 1 0]\n",
            " [0 1 0]\n",
            " ...\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 0]], shape=(512, 3), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvZsflH3_w8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "901c94fd-0ee1-4fb2-b9db-060e3af3cf81"
      },
      "source": [
        "#find accuracy of the test data.\n",
        "loss, tp, fp ,tn, fn, accuracy, precision, recall, auc = model.evaluate(test_ds)\n",
        "print(\"Accuracy\", accuracy)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76/76 [==============================] - 3s 43ms/step - loss: 0.6779 - tp: 28161.0000 - fp: 8846.0000 - tn: 68172.0000 - fn: 10348.0000 - accuracy: 0.7479 - precision: 0.7610 - recall: 0.7313 - auc: 0.8848\n",
            "Accuracy 0.74792904\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}